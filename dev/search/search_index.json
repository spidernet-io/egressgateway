{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"egressgateway","text":""},{"location":"#about","title":"About","text":"<p>In a Kubernetes (k8s) cluster, when Pods access external services, their Egress IP addresses are not fixed. In the Overlay network, the Egress IP address is determined by the node where the Pod resides. While in the Underlay network, Pods directly use their own IP addresses for external communication. Consequently, when Pods are rescheduled, regardless of the network mode, their IP addresses for external communication change. This instability poses a challenge for system administrators in managing IP addresses, especially as the cluster scales and during network fault diagnostics. Controlling egress traffic based on a Pod's original egress IP outside the cluster becomes difficult.</p> <p>To solve this problem, EgressGateway has been introduced into the k8s cluster. It is an open-source EgressGateway designed to resolve egress egress IP address issues across various CNI network modes, such as Calico, Flannel, Weave, and Spiderpool. Through flexible configuration and management of egress policies, EgressGateway allows setting egress IP addresses for tenant-level or cluster-level workloads. When Pods need to access the external network, the system consistently uses the configured Egress IP as the egress address, providing a stable solution for egress traffic management.</p>"},{"location":"#architecture","title":"Architecture","text":""},{"location":"#why-egressgateway","title":"Why EgressGateway","text":""},{"location":"#support-a-range-of-features-and-advantages","title":"Support a range of features and advantages","text":"<ul> <li>Solve IPv4 IPv6 dual-stack connectivity,ensuring seamless communication across different protocol stacks.</li> <li>Solve the high availability of Egress Nodes, ensuring network connectivity remains unaffected by single-point failures.</li> <li>Support finer-grained policy control, allowing flexible filtering of Pods' Egress policies, including Destination CIDR.</li> <li>Support application-level control, allowing EgressGateway to filter Egress applications (Pods) for precise management of specific application outbound traffic.</li> <li>Support multiple egress gateways instance,capable of handling communication between multiple network partitions or clusters.</li> <li>Support namespaced egress IP.</li> <li>Support automatic detection of cluster traffic for egress gateways policies.</li> <li>Support namespace default egress instances.</li> <li>Can be used in low kernel version, making EgressGateway suitable for various Kubernetes deployment environments.</li> </ul>"},{"location":"#compatible-with-the-following-network-solutions","title":"Compatible with the following network solutions","text":"<ul> <li>Calico</li> <li>Flannel</li> <li>Weave</li> <li>Spiderpool</li> </ul>"},{"location":"#getting-started-using-egressgateway","title":"Getting started using EgressGateway","text":"<p>Please refer to the installation guide.</p>"},{"location":"#join-the-egressgateway-community","title":"Join the EgressGateway Community","text":"<p>We welcome contributions in any kind. If you have any questions about contributions, please consult the contribution documentation.</p>"},{"location":"#license","title":"License","text":"<p>EgressGateway is licensed under the Apache License, Version 2.0. See LICENSE for the full license text.</p>"},{"location":"Troubleshooting/","title":"Troubleshooting","text":""},{"location":"Troubleshooting/#vxlan-speed","title":"VXLAN Speed","text":"<p>EgressGateway uses the vxlan tunnel, and testing shows that vxlan loss is around 10%. If you find that the speed of EgressGateway does not meet the standard, you can follow these steps to check:</p> <ol> <li>Confirm that the speed of the host-to-node matches the expected speed;<ol> <li>The offload setting of the network card used by vxlan on the host will have a small impact on the speed of the vxlan interface (there will only be a difference of 0.5 Gbits/sec in the 10G network card test), you can run <code>ethtool --offload host-interface-name rx on tx on</code> to turn on offload;</li> </ol> </li> <li>The offload setting of the vxlan network card can significantly impact the speed of the vxlan interface. In 10G network card tests, the speed is 2.5 Gbits/sec without offload enabled, and 8.9 Gbits/sec with offload enabled. You can run <code>ethtool -k egress.vxlan</code> to check whether checksum offload is turned off, and you can enable offload by setting the <code>feature.vxlan.disableChecksumOffload</code> configuration in helm values to <code>false</code>.</li> </ol>"},{"location":"Troubleshooting/#benchmark","title":"Benchmark","text":""},{"location":"Troubleshooting/#bare-metal-server","title":"Bare metal server","text":"<p>The following are the data from our stress tests using bare metal servers.</p> Name CPU MEM Interface Node 1 Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz 128G 10G Mellanox Node 2 Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz 128G 10G Mellanox Node Target Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz 128G 10G Mellanox Case Item Detail case1 node -&gt; node <code>9.44 Gbits/sec sender - 9.41 Gbits/sec receiver</code> case2 egress vxlan -&gt; egress vxlan <code>9.11 Gbits/sec sender - 9.09 Gbits/sec receiver</code> case3 pod -&gt; egress node -&gt; target <code>9.01 Gbits/sec sender - 8.98 Gbits/sec receiver</code> <p></p>"},{"location":"Troubleshooting/#virtual-machine","title":"Virtual machine","text":"<p>The following is a virtual machine using VMWare, which limits the data measured with Node specification of 4C8G.</p> Name CPU MEM Interface Node 1 Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz 4C 8G VMXNET3 Node 2 Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz 4C 8G VMXNET3 Node Target Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz 4C 8G VMXNET3 Case Item Detail case1 node -&gt; node <code>2.99 Gbits/sec sender - 2.99 Gbits/sec receiver</code> case2 egress vxlan -&gt; egress vxlan <code>1.73 Gbits/sec sender - 1.71 Gbits/sec receiver</code> case3 pod -&gt; egress node -&gt; target <code>1.23 Gbits/sec sender - 1.22 Gbits/sec receiver</code>"},{"location":"backends/","title":"egressgateway","text":""},{"location":"backends/#background","title":"Background","text":"<p>Starting with 2021, we received some feedback as follows.</p> <p>There are two clusters A and B. Cluster A is VMWare-based and runs mainly Database workloads, and Cluster B is a Kubernetes cluster. Some applications in Cluster B need to access the database in Cluster A, and the network administrator wants the cluster Pods to be managed through an egress gateway.</p>"},{"location":"concepts/Architecture/","title":"Architecture","text":"<p>EgressGateway consists of two parts: the control plane and the data plane. The control plane is composed of four control loops, and the data plane is composed of three. The control plane is deployed as a Deployment, supporting multiple replicas for high availability, and the data plane is deployed as a DaemonSet. The control loops are as follows in the diagram below:</p> <p></p>"},{"location":"concepts/Architecture/#controller","title":"Controller","text":""},{"location":"concepts/Architecture/#egresstunnel-reconcile-loop-a","title":"EgressTunnel Reconcile Loop (a)","text":""},{"location":"concepts/Architecture/#initialization","title":"Initialization","text":"<ol> <li>Obtain the dual-stack open condition and the corresponding tunnel CIDR from the ConfigMap configuration file</li> <li>Generate a unique label value by node name according to the algorithm.</li> <li>Check if the node has a corresponding EgressTunnel, if not, create a corresponding EgressTunnel and set the status to <code>Pending</code>. If there is a tunnel IP, it will check if the IP is legal before binding the IP to the node.  If not, it will set the status to <code>Pending</code>.</li> </ol>"},{"location":"concepts/Architecture/#egresstunnel-event","title":"EgressTunnel Event","text":"<ul> <li>Del: release the tunnel IP first, and then delete it. If the node corresponding to EgressTunnel still exists, recreate EgressTunnel.</li> <li>Other:</li> <li>EgressTunnel Other. = <code>Init</code> || phase ! = <code>Ready</code>: the IP is allocated and the status is set to <code>Init</code> for successful allocation and <code>Failed</code> for failed allocation. This is the only place globally where the tunnel IP will be assigned.</li> <li>mark ! = algorithm(NodeName): this field is forbidden to be modified, and will be returned as an error.</li> </ul>"},{"location":"concepts/Architecture/#node-event","title":"Node Event","text":"<ul> <li>Del: delete the corresponding EgressTunnel.</li> <li>Other:</li> <li>If the corresponding EgressTunnel does not exist, create an EgressTunnel.</li> <li>No tunnel IP, set phase to <code>Pending</code>.</li> <li>If there is a tunnel IP, verify if the tunnel is legal. If not, set phase to <code>Pending</code>.</li> <li>If the tunnel IP is legal, check if the IP is assigned to this node. If not, set phase to <code>Pending</code>.</li> <li>If the tunnel IP is assigned to this node and the phase state is not <code>Ready</code>, set phase to <code>Init</code>.</li> </ul>"},{"location":"concepts/Architecture/#egressgateway-reconcile-loop-b","title":"EgressGateway Reconcile Loop (b)","text":""},{"location":"concepts/Architecture/#egressgateway-event","title":"EgressGateway Event","text":"<ul> <li>Del:</li> <li>The Webhook determines if the Policy is still referenced by other Policies, and if so, deletion is not allowed.</li> <li> <p>Passing the Webhook's check indicates there is no references and all rules have been cleaned up, so deletion is allowed.</p> </li> <li> <p>Other:</p> </li> <li>If the number of EIPs decreases and EIP is referenced, modification is prohibited. When allocating IPV4 and IPV6, it is required that the number of IPV4 and IPV6 correspond to each other, so the number of IPV4 and IPV6 should be the same.</li> <li>If the nodeSelector is modified, get the old Node information from status and compare it with the latest Node. Reallocate the EIP from the deleted node to the new Node. Update the EIP information in the corresponding EgressTunnel.</li> </ul>"},{"location":"concepts/Architecture/#egresspolicy-event","title":"EgressPolicy Event","text":"<ul> <li>Del: list out the EgressPolicy, and find the referenced EgressGateway, and then unbind the EgressPolicy to the EgressGateway. To perform unbinding, we need to find the corresponding EIP information. If the EIP is used, then determine whether the EIP should be reclaimed; if the EIP is no longer used by the policy, then reclaim the EIP and update itself the EIP information of the EgressTunnel.</li> <li>Other:</li> <li>EgressPolicy cannot modify the bound EgressGateway. If it is allowed to do so, list out the EgressGateway, and then find the original bound EgressGateway and unbind it. Then, bind it to the new EgressGateway.</li> <li>If you add a new EgressPolicy, then bind the EgressPolicy to the EgressGateway, and in the process of binding, determine if you need to assign an EIP.</li> </ul>"},{"location":"concepts/Architecture/#node-event_1","title":"Node Event","text":"<ul> <li>Del: list out the EgressGateway to pick out the EIPs that are active on this node and reassign those EIPs to the new node. Update the EgressGateway's eip.policy.</li> <li>Other:</li> <li>The NoReady event is equivalent to triggering a deletion event.</li> <li>For label modifications, iterate through all EgressGateway information to check if it involves nodeSelector. If the old labels do not involve any EgressPolicies, no action is taken. If they are involved, it is equivalent to triggering a deletion event. If the new labels meet the conditions for the EgressGateway, update the status information of the corresponding EgressGateway.</li> </ul>"},{"location":"concepts/Architecture/#gateway-node-selection-egresspolicy-and-eip-assignment-logic","title":"Gateway Node Selection EgressPolicy and EIP Assignment Logic","text":"<p>An EgressPolicy selects a node as a gateway node according to the gateway node selection policy. The decision to assign an EIP is based on whether or not the EIP is used, and the assigned EIP is bound to the selected gateway node.</p> <p>The allocation logic applies to individual EgressGateways rather than all EgressGateways.</p>"},{"location":"concepts/Architecture/#egresspolicy-gateway-node-selection-modes","title":"EgressPolicy Gateway Node Selection Modes","text":"<ul> <li>Average selection: when a gateway node needs to be selected, select the node with the least number of nodes as gateway nodes.</li> <li>Minimum node selection: try to select the same node as a gateway node.</li> <li>Limit selection: a node can only serve as a gateway for up to a certain number of EgressPolicies. This limit can be set and defaults to 5. If a node hasn't reached the limit, it is preferred. Once the limit is reached, other nodes are chosen first. If all nodes have reached their limits, a random selection is made.</li> </ul>"},{"location":"concepts/Architecture/#eip-allocation-logic","title":"EIP Allocation Logic","text":"<ul> <li>Random allocation: randomly select an EIP from all available EIPs, regardless of whether it has been assigned</li> <li>Preferred use of unallocated EIPs: use unallocated EIPs first, and then randomly allocate a used EIP if they are all used.</li> <li>Limit selection: an EIP can be used by a maximum number of EgressPolicies, which can be set with a default value of 5. Until the limit is reached, the EIP is preferred for allocation. Once the limit is reached, other EIPs are selected. If all EIPs have reached their limits, a random selection is made.</li> </ul>"},{"location":"concepts/Architecture/#eip-recycle-logic","title":"EIP Recycle Logic","text":"<p>When an EIP is not used, it will be reclaimed, which means deleting the EIP field in <code>eips</code>.</p>"},{"location":"concepts/Architecture/#egressclusterinfo-reconcile-loop-d","title":"EgressClusterInfo Reconcile Loop (d)","text":""},{"location":"concepts/Architecture/#node-event_2","title":"Node Event","text":"<ul> <li>Create: node IP is automatically added to egressclusterinfos CR <code>status.egressIgnoreCIDR.nodeIP</code> when node is created.</li> <li>Update: when the node IP is updated, the node's IP is automatically updated to egressclusterinfos CR <code>status.egressIgnoreCIDR.nodeIP</code>.</li> <li>Delete: remove the node's IP from egressclusterinfos CR <code>status.egressIgnoreCIDR.nodeIP</code> when the node is deleted.</li> </ul>"},{"location":"concepts/Architecture/#calico-ippool-event","title":"Calico IPPool Event","text":"<p>Listen for Calico's IPPool Event when the <code>egressIgnoreCIDR.autoDetect.podCIDR</code> of the egressgateway profile is \"calico\".</p> <ul> <li>Create: automatically add the IPPool CIDR to the EgressClusterInfo CR <code>status.egressIgnoreCIDR.podCIDR</code> when the Calico IPPool is created.</li> <li>Update: when calico IPPool has an update, automatically update the IPPool CIDR into EgressClusterInfo CR <code>status.egressIgnoreCIDR.podCIDR</code>.</li> <li>Delete: remove the IPPool CIDR from EgressClusterInfo CR <code>status.egressIgnoreCIDR.podCIDR</code> when the calico IPPool is deleted.</li> </ul>"},{"location":"concepts/Architecture/#configuration-file","title":"Configuration File","text":"<p>Modify the configuration file to add the following configuration:</p> <pre><code>feature.\negressIgnoreCIDR.\nautoDetect.\npodCIDR: \"\" # (1)\nclusterIP: true # (2)\nnodeIP: true # (3)\ncustom.\n- \"10.6.1.0/24\"\n</code></pre> <ol> <li><code>podCIDR</code>, currently support <code>calico</code> and <code>k8s</code>. The default is <code>k8s</code>.</li> <li><code>clusterIP</code>, support setting to Service CIDR auto-detection.</li> <li><code>nodeIP</code>, support setting to Node IP auto-detection.</li> </ol>"},{"location":"concepts/Datapath/","title":"Datapath","text":"<p>Rules that need to take effect are categorized into three categories: all nodes, \"gateway nodes\" relative to the EgressGatewayPolicy, and \"non-gateway nodes\". The rules on a node will only take effect when the Pod is scheduled to a \"Non-Gateway Node.\"</p>"},{"location":"concepts/Datapath/#all-nodes","title":"All nodes","text":"<ol> <li>Detailed tunnel requirements between nodes are not listed.</li> <li> <p>Traffic matching the policy is retagged. This update occurs when a node becomes a gateway node for the first time or during node join, but it is not updated thereafter.</p> <pre><code>iptables -t mangle -N EGRESSGATEWAY-RESET-MARK\niptables -t mangle -I FORWARD 1 -j EGRESSGATEWAY-RESET-MARK -m comment --comment \"egress gateway: mark egress packet\"\niptables -t mangle -A EGRESSGATEWAY-RESET-MARK \\\n-m mark --mark $NODE_MARK/0x26000000 \\\n-j MARK --set-mark 0x12000000 \\\n-m comment --comment \"egress gateway: change mark\"\n\\ -m -comment \"egress gateway: change mark\n</code></pre> </li> <li> <p>Preserve the labels for traffic matching the policy. Create them once without requiring updates.</p> <pre><code>iptables -t filter -I FORWARD 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t filter -I OUTPUT 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t mangle -I POSTROUTING 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\n</code></pre> </li> <li> <p>Aggregate chains for tagging policy-matched traffic. Create them once without needing updates.</p> <pre><code>iptables -t mangle -N EGRESSGATEWAY-MARK-REQUEST\n\niptables -t mangle -I PREROUTING 1 -j EGRESSGATEWAY-MARK-REQUEST -m comment --comment \"egress gateway: mark egress packet\"\n</code></pre> </li> <li> <p>Aggregate chains that do not need to do SNAT rules. It is created directly once and does not need to be updated;</p> <pre><code>iptables -t nat -N EGRESSGATEWAY-NO-SNAT\n\niptables -t nat -I POSTROUTING 1 -j EGRESSGATEWAY-NO-SNAT -m comment --comment \"egress gateway: no snat\"\niptables -t nat -A EGRESSGATEWAY-NO-SNAT -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: no snat\"\n</code></pre> </li> <li> <p>Aggregate chains that need to do SNAT rules. It is created directly once and does not need to be updated.</p> <pre><code>iptables -t nat -N EGRESSGATEWAY-SNAT-EIP\n\n# Need to insert after rules that don't require SNAT to keep the chain at the top\niptables -t nat -I POSTROUTING 1 -j EGRESSGATEWAY-SNAT-EIP -m comment --comment \"egress gateway: snat EIP\"\n</code></pre> </li> <li> <p>egress-ingore-cidr When the <code>destSubnet</code> field of the EgressGatewayPolicy is empty, the data plane will automatically match traffic outside the CIDR in the EgressClusterStatus CR and forward it to the Egress gateway.</p> <pre><code>IPSET_RULE_DEST_NAME=egress-ingore-cidr\n\nipset x $IPSET_RULE_DEST_NAME\nipset create $IPSET_RULE_DEST_NAME hash:net\n\nipset add $IPSET_RULE_DEST_NAME 10.6.105.150/32\n</code></pre> </li> </ol>"},{"location":"concepts/Datapath/#non-egress-gateway-node-relative-to-eip","title":"Non-Egress Gateway node Relative to EIP","text":"<ol> <li> <p>ipsets for policy-matched source and destination IPs.</p> <pre><code>IPSET_RULE_DEST_NAME=egress-dest-uuid\n\nipset x $IPSET_RULE_DEST_NAME\nipset create $IPSET_RULE_DEST_NAME hash:net\n\nipset add $IPSET_RULE_DEST_NAME 10.6.105.150/32\n\nIPSET_RULE_SRC_NAME=egress-src-uuid\n\nipset x $IPSET_RULE_SRC_NAME\nipset create $IPSET_RULE_SRC_NAME hash:net\n\nipset add $IPSET_RULE_SRC_NAME 172.29.234.173/32\n</code></pre> </li> <li> <p>Tag policy-matched traffic to ensure it goes through the tunnel. The NODE_MARK value depends on the node where the corresponding EIP resides.</p> <pre><code>iptables -A EGRESSGATEWAY-MARK-REQUEST -t mangle -m conntrack --ctdir ORIGINAL \\\n-m set --match-set $IPSET_RULE_DEST_NAME dst \\\n-m set --match-set $IPSET_RULE_SRC_NAME src \\\n-j MARK --set-mark $NODE_MARK -m comment --comment \"rule uuid: mark request packet\"\n</code></pre> </li> <li> <p>Policy routing rules</p> <pre><code>ip rule add fwmark $NODE_MARK table $TABLE_NUM\n</code></pre> </li> <li> <p>Adapt Weave to avoiding SNAT into IPs for Egress tunnels. Make a switch</p> <pre><code>iptables -t nat -A EGRESSGATEWAY-NO-SNAT \\ \\\n-m set --match-set $IPSET_RULE_DEST_NAME dst \\\n-m set --match-set $IPSET_RULE_SRC_NAME src \\\n-j ACCEPT -m comment --comment \"egress gateway: weave does not do SNAT\"\n</code></pre> </li> </ol>"},{"location":"concepts/Datapath/#egress-gateway-node-relative-to-eip","title":"Egress Gateway Node Relative to EIP","text":"<ol> <li> <p>ipsets for policy-matched source and destination IPs.</p> <pre><code>IPSET_RULE_DEST_NAME=egress-dest-uuid\n\nipset x $IPSET_RULE_DEST_NAME\nipset create $IPSET_RULE_DEST_NAME hash:net\n\nipset add $IPSET_RULE_DEST_NAME 10.6.105.150/32\n\nIPSET_RULE_SRC_NAME=egress-src-uuid\n\nipset x $IPSET_RULE_SRC_NAME\nipset create $IPSET_RULE_SRC_NAME hash:net\n\nipset add $IPSET_RULE_SRC_NAME 172.29.234.173/32\n</code></pre> </li> <li> <p>Apply SNAT to policy-matched traffic during egress. Keep this rule updated in real-time.</p> <pre><code>iptables -t nat -A EGRESSGATEWAY-SNAT-EIP \\\n-m set --match-set $IPSET_RULE_SRC_NAME src \\\n-m set --match-set $IPSET_RULE_DST_NAME dst \\\n-j SNAT --to-source $EIP\n\u00f0\u0178\u00f1'\u00f0\u0178\u00f1'\u00f0\u0178\u00f1'\u00f0\u0178\u00f1'\u00f0\u0178\u00f1'\u00f1\n</code></pre> </li> </ol>"},{"location":"concepts/Datapath/#others","title":"Others","text":"<ol> <li> <p>NODE_MARK: each node corresponds to a globally unique label. The label is generated by combining a prefix and a unique identifier. The format of the label is as follows: <code>NODE_MARK = 0x26 + value + 0000</code>, where <code>value</code> is a 16-bit number. The total number of supported nodes is <code>2^16</code>.</p> </li> <li> <p>TABLE_NUM:</p> <ul> <li>Since each host can have [0, 255] routing tables (where 0, 253, 254, and 255 are already used by the system), exceeding the maximum number of tables will result in the inability to calculate routes for nodes, leading to node disconnection. Additionally, table names must match the table ID, and if there is no match, the kernel will assign a random name. To be on the safe side, the number of controlled tables (represented by variable n with a default value of 100) is limited, which also serves as the upper limit for gateway nodes.</li> <li>TABLE_NUM algorithm: users can set a starting value (represented by variable s with a default value of 3000), and the range of table names will be [s, (s+n)]. Users need to ensure that the table names within this range are not occupied. Start with a randomly selected value from [s, (s+n)] and increment it circularly until an unused table name for the current node is obtained. If none is found, an error is reported.</li> </ul> </li> </ol>"},{"location":"develop/Contribute/","title":"How to contribute","text":"<p>First of all, thank you for your interest in contributing to our project! We appreciate all the help and support from the community. This document outlines the process for contributing to our Kubernetes operator project. Please read through the guidelines carefully before submitting any changes.</p>"},{"location":"develop/Contribute/#code-of-conduct","title":"Code of conduct","text":"<p>To ensure a positive and supportive environment for all contributors, please adhere to our Code of Conduct. By participating in this project, you agree to abide by its terms.</p>"},{"location":"develop/Contribute/#getting-started","title":"Getting started","text":"<p>Fork the Repository: To contribute, start by forking the repository to your own GitHub account. This will create a copy of the project that you can modify as needed.</p> <p>Clone the Fork: After forking the repository, clone your fork to your local machine using Git. This will allow you to work on the project locally.</p> <pre><code>git clone https://github.com/your-username/your-project-name.git\n</code></pre> <p>Create a Branch: Before starting to work on your changes, create a new branch for each feature or bugfix. This helps to keep your changes separated and organized. Use a descriptive name for your branch.</p> <pre><code>git checkout -b your-new-branch-name\n</code></pre>"},{"location":"develop/Contribute/#making-changes","title":"Making changes","text":"<p>Update Your Fork: Before making any changes, make sure your fork is up to date with the upstream repository.</p> <pre><code>git remote add upstream https://github.com/original-owner/your-project-name.git\ngit fetch upstream\ngit merge upstream/main\n</code></pre> <p>Test Your Changes: After making changes, ensure that they do not break the project by running tests. Be sure to test your changes in a Kubernetes environment if possible.</p> <p>Commit Your Changes: When you're satisfied with your changes, commit them using a clear and concise commit message. This helps the maintainers understand the purpose of your changes.</p> <pre><code>git add .\ngit commit -m \"Your commit message\"\n</code></pre> <p>Push Your Changes: After committing your changes, push them to your fork on GitHub.</p> <pre><code>git push origin your-new-branch-name\n</code></pre>"},{"location":"develop/Contribute/#submitting-a-pull-request","title":"Submitting a pull request","text":"<p>Create a Pull Request: Once your changes are pushed, create a pull request from your fork to the upstream repository. Make sure the base branch is set to main and the head branch is your feature or bugfix branch.</p> <p>Describe Your Changes: In the pull request description, provide a clear and concise description of the changes you made. Include any relevant issue numbers and explain how your changes address the issue or add a new feature.</p> <p>Wait for a Review: After submitting your pull request, wait for a project maintainer to review your changes. They may request changes or provide feedback on your work. Be sure to address any feedback and update your pull request as needed.</p> <p>Merge: Once your changes have been reviewed and approved, a project maintainer will merge your pull request. Congratulations, you've successfully contributed to the project!</p>"},{"location":"develop/Develop/","title":"Develop","text":""},{"location":"develop/Develop/#quick-start","title":"Quick Start","text":"<ol> <li> <p>build local CI image </p> <pre><code>make build_local_image\n</code></pre> </li> <li> <p>setup cluster</p> <pre><code># setup the cluster\nmake e2e_init\n\n# for china developer, use china image registry, use HTTP_PROXY to pull chart \nmake e2e_init -e E2E_CHINA_IMAGE_REGISTRY=true -e HTTP_PROXY=http://10.0.0.1:7890\n\n# show the cluster\nexport KUBECONFIG=$(pwd)/test/runtime/kubeconfig_egressgateway.config\nkubectl get node\n</code></pre> </li> <li> <p>run the E2E test </p> <pre><code>make e2e_run\n</code></pre> </li> <li> <p>check proscope, browser visits http://nodeIP:4040</p> </li> </ol>"},{"location":"develop/Develop/#go-package-structure-design","title":"Go Package (Structure) Design","text":"<pre><code>.\n\u251c\u2500\u2500 api\n\u251c\u2500\u2500 charts\n\u251c\u2500\u2500 cmd\n\u251c\u2500\u2500 docs\n\u251c\u2500\u2500 images\n\u251c\u2500\u2500 output\n\u251c\u2500\u2500 pkg\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 agent\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 coalescing\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 config\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 constant\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 controller\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 egressgateway\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ethtool\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ipset\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 iptables\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 k8s\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 layer2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lock\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 logger\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 markallocator\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 profiling\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 schema\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 types\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 utils\n\u251c\u2500\u2500 test\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 doc\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 e2e\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 kindconfig\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 scripts\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 yaml\n\u251c\u2500\u2500 tools\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 golang\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 images\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 scripts\n\u2514\u2500\u2500 vendor\n</code></pre>"},{"location":"develop/Release/","title":"Release Workflow","text":""},{"location":"develop/Release/#pre-steps","title":"Pre-steps","text":"<ul> <li>Update <code>version</code> and <code>appVersion</code> fields in <code>charts/*/Chart.yaml</code></li> <li>Update version in <code>/VERSION</code></li> <li>Set a version tag on the correct branch. The version should follow the pattern:<ul> <li>v0.1.0-rc0</li> <li>v0.1.0-rc1</li> <li>v0.1.0</li> <li>v0.1.1</li> <li>v0.1.2</li> <li>v0.2.0-rc0</li> <li>v0.2.0</li> </ul> </li> </ul>"},{"location":"develop/Release/#push-a-version-tag","title":"Push a Version Tag","text":"<p>When a tag vx.x.x is pushed, the following steps will automatically run:</p> <ol> <li>Verify that the tag name matches the <code>/VERSION</code></li> <li>Create a branch named <code>release-vx.x.x</code></li> <li>Build the images with the pushed tag and push them to the ghcr registry</li> <li>Generate the changelog based on historical PRs labeled as <code>release/*</code><ul> <li>Submit the changelog file to the <code>changelogs</code> directory of the <code>github_pages</code> branch, with PR labeled as <code>pr/release/robot_update_githubpage</code></li> <li>Changelogs are generated based on historical PR labels:<ul> <li>Label <code>release/feature</code> will be classified as \"Changed Features\"</li> <li>Label <code>release/bug</code> will be classified as \"Fixes\"</li> </ul> </li> </ul> </li> <li>Build the chart package with the pushed tag and submit a PR to the <code>github_pages</code> branch<ul> <li>Retrieve the chart with the command <code>helm repo add $REPO_NAME https://spidernet-io.github.io/$REPO_NAME</code></li> </ul> </li> <li>Submit <code>/docs</code> to the <code>/docs</code> directory of the <code>github_pages</code> branch</li> <li>Create a GitHub Release with the chart package and changelog attached</li> <li>Manually approve the chart PR labeled as <code>pr/release/robot_update_githubpage</code> and the changelog PR labeled as <code>pr/release/robot_update_githubpage</code></li> </ol>"},{"location":"develop/Roadmap/","title":"Roadmap","text":"Kind Feature Schedule Status Gateway Support multiple instances of gateway class v0.4.0 Support for namespace Support default gateway class v0.4.0 All data stream could load-balance to all gateway node v0.4.0 When a gateway node breakdown , all data stream could to to healthy gateway node v0.4.0 Could specify the node interface for tunnel, by hand, or auto select a reasonable one v0.4.0 Tunnel protocol VXLAN v0.4.0 Geneve Encryption IPSec WireGuard Destination CIDR Could auto distinguish internal CIDR (calico, flannel etc, or by hand) and outside CIDR v0.4.0 Could specify the outside CIDR by hands v0.4.0 Data protocol TCP v0.4.0 UDP v0.4.0 WebSocket v0.4.0 sctp Multicast Policy Support priority Support cluster scope policy v0.4.0 Support namespace scope policy v0.4.0 Support CNI Calico v0.4.0 Flannel v0.4.0 Weave v0.4.0 macvlan+spiderpool v0.3.0 IP Stack IPv4-only v0.4.0 IPv6-only v0.4.0 Dual stack v0.4.0 Source IP Support EIP for application v0.4.0 Support EIP for namespace v0.4.0 Use node IP v0.4.0 Datapath Iptables with low and high version v0.4.0 ebpf Performance Big cluster, with lots of gateway nodes Big cluster, with lots of  nodes Big cluster, with lots of  pods When gateway node down, the whole cluster could change to healthy gateway node within 2s After apply or modify lots of policy, it could quick take effect in a big cluster After apply or modify gateway node, it could quick take effect in a big cluster Forward throughput of each gateway node CPU and memory usage under pressure HA All component pods could recovery quickly and serve after breakdown v0.4.0 All pods could run for one week without failure v0.4.0 Insight Metrics v0.4.0 Log v0.4.0 Architecture AMD, ARM v0.4.0"},{"location":"develop/release/","title":"Workflow for release","text":""},{"location":"develop/release/#prerequisite-steps","title":"Prerequisite Steps","text":"<ul> <li> <p>Update the <code>version</code> and <code>appVersion</code> fields in the <code>Chart.yaml</code> files located under the <code>charts/*</code> directories.</p> </li> <li> <p>Update the version in the <code>/VERSION</code> file.</p> </li> <li> <p>Ensure to set a version tag on the appropriate branch. The version should follow the below format:</p> </li> <li> <p>v0.1.0-rc0 (Release Candidate 0)</p> </li> <li>v0.1.0-rc1 (Release Candidate 1)</li> <li>v0.1.0 (Initial Release)</li> <li>v0.2.0-rc0 (Second Version's Release Candidate 0)</li> <li>v0.2.0 (Second Version's Initial Release)</li> </ul>"},{"location":"develop/release/#tagging-a-version","title":"Tagging a Version","text":"<p>When a version tag, denoted as <code>vx.x.x</code>, is pushed, the subsequent automated process initiates:</p> <ol> <li>The tag name is verified to match with <code>/VERSION</code>.</li> <li>A branch named <code>release-vx.x.x</code> is created.</li> <li>Docker images are built, tagged with the pushed tag, and then pushed to the GHCR (GitHub Container Registry).</li> <li>A changelog is generated from historical PRs labeled with <code>pr/release/*</code> and added to the <code>changelogs</code> directory in the <code>github_pages</code> branch. This changelog PR should be labeled as <code>pr/release/robot_update_githubpage</code>. The changelog categorizes historical PR labels as follows:<ul> <li>PRs labeled <code>release/feature-new</code> are classified as \"New Features\".</li> <li>PRs labeled <code>release/feature-changed</code> are classified as \"Changed Features\".</li> <li>PRs labeled <code>release/bug</code> are classified as \"Fixes\".</li> </ul> </li> <li>A Helm chart package is built using the pushed tag and a PR is submitted to the <code>github_pages</code> branch. The chart can be retrieved using the command:     <pre><code>helm repo add $REPO_NAME https://kdoctor-io.github.io/$REPO_NAME\n</code></pre></li> <li>Content from the <code>/docs</code> directory is submitted to the <code>/docs</code> directory of the <code>github_pages</code> branch.</li> <li>A GitHub Release is created, which includes the Helm chart package and the changelog attached.</li> <li>Finally, manual approval is required for the Helm chart PR and the changelog PR, both labeled as <code>pr/release/robot_update_githubpage</code>. This process ensures version control, continuous integration, and delivery are maintained effectively.</li> </ol>"},{"location":"proposal/01-egress-gateway/EgressGateway/","title":"EgressGateway","text":""},{"location":"proposal/01-egress-gateway/EgressGateway/#crds","title":"CRDS","text":"<p>The egress gateway model abstracts three Custom Resource Definitions (CRDs): <code>EgressTunnel</code> , <code>EgressTunnel</code> and <code>EgressGatewayPolicy</code>. They are cluster scoped CRDs.</p>"},{"location":"proposal/01-egress-gateway/EgressGateway/#egressgateway_1","title":"EgressGateway","text":"<pre><code>apiVersion: egressgateway.spidernet.io/v1\nkind: EgressGateway\nmetadata:\nname: \"egressgateway\"\nspec:\nnodeSelector:\nmatchLabels:\negress: \"true\"\nstatus:\nforwardMethod: \"active-passive\"\nnodeList: - node1:\nstatus: \"ready\"\nactive: true\ninterfaces:\n- eth0:\nipv4: [\"10.6.0.10/16\"]\nipv6: [\"fd::10/64\"]\n</code></pre> <ul> <li>spec<ul> <li><code>nodeSelector</code> field matching against node labels.</li> </ul> </li> <li>status<ul> <li><code>forwardMethod</code> field sync form <code>ConfigMap</code> configuration.</li> <li><code>nodeList</code> field is the list of nodes matched by <code>nodeSelector</code><ul> <li><code>status</code> field represents the node status, which may be <code>Ready</code>, <code>NotReady</code> or <code>Unknown</code>.<ul> <li>Only nodes in the <code>Ready</code> state can participate in the election of egress gateway nodes.</li> </ul> </li> <li><code>avtive</code> field represents that the non-egress gateway is reconcile or reconcile completes accessing the destination CIDR(e.g. Cluster A CIDR in picture 1) with this node.</li> <li><code>interfaces</code> is physical network interface list. It is updated by the Agent.<ul> <li><code>ipv4</code> address list.</li> <li><code>ipv6</code> address list.</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"proposal/01-egress-gateway/EgressGateway/#egresstunnel","title":"EgressTunnel","text":"<pre><code>apiVersion: egressgateway.spidernet.io/v1\nkind: EgressTunnel\nmetadata:\nname: \"node1\"\nspec:\nstatus:\nphase: \"Ready\"\nvxlanIPv4IP: \"172.31.0.10/16\"\nvxlanIPv6IP: \"fe80::/64\"\ntunnelMac: \"xx:xx:xx:xx:xx\"\nphysicalInterface: \"eth1\"\nphysicalInterfaceIPv4: \"\"\nphysicalInterfaceIPv6: \"\"\n</code></pre> <p>The <code>EgressTunnel</code> CRD stores vxlan tunnel information, which is generated by the Controller from the Node CR.</p> <ul> <li>status<ul> <li><code>phase</code> indicates the status of EgressTunnel. If 'Ready' has been assigned and the tunnel has been built, 'Pending' is waiting for IP assignment, 'Init' succeeds in assigning the tunnel IP address, and 'Failed' fails to assign the tunnel IP address.</li> <li><code>vxlanIPv4IP</code> field represents the IPv4 address of VXLAN tunnel.</li> <li><code>vxlanIPv6IP</code> field represents the IPv6 address of VXLAN tunnel.</li> <li><code>tunnelMac</code> field represents the MAC address of IPv4 VXLAN tunnel Interface.</li> <li><code>physicalInterface</code> is parent name of VXLAN tunnel interface.</li> <li><code>physicalInterfaceIPv4</code> is parent IPv4 Address of VXLAN tunnel interface.</li> <li><code>physicalInterfaceIPv6</code> is parent IPv6 Address of VXLAN tunnel interface.</li> </ul> </li> </ul>"},{"location":"proposal/01-egress-gateway/EgressGateway/#egressgatewaypolicy","title":"EgressGatewayPolicy","text":"<pre><code>apiVersion: egressgateway.spidernet.io/v1\nkind: EgressGatewayPolicy\nmetadata:\nname: \"policy\"\nspec:\nappliedTo:\npodSelector:\nmatchLabels:\napp: \"shopping\"\nipv6PodSubnet: \"10.0.0.0/16\"\nipv4PodSubnet: \"10.0.0.0/16\"\ndestCIDR: - \"10.6.1.0/24\"\n</code></pre> <ul> <li>spec<ul> <li><code>podSelector</code> filed selects the grouping of pods to which the policy applies.</li> <li><code>podSubnet</code> field specifies the pod CIDR affected by the egress policy. It conflicts with the <code>podSelector</code> field.</li> <li><code>destCIDR</code> destination CIDR block list.</li> </ul> </li> </ul>"},{"location":"proposal/01-egress-gateway/EgressGateway/#datapath","title":"Datapath","text":"<p>A combination of vxlan tunnel, ipset, iptables, route is required to complete policy control.</p>"},{"location":"proposal/01-egress-gateway/EgressGateway/#non-egress-node","title":"Non Egress Node","text":""},{"location":"proposal/01-egress-gateway/EgressGateway/#vxlan","title":"VXLAN","text":"<p>Build a VXLAN tunnel on cluster nodes. There are 2 tunnel NICs named <code>egress-vxlan-v4</code> and <code>egress-vxlan-v6</code>.</p>"},{"location":"proposal/01-egress-gateway/EgressGateway/#ipset","title":"IPSet","text":"<pre><code>sudo ipset create egress-dst-policy-name\nsudo ipset add egress-dest-policy-name 172.16.1.1/32\n</code></pre>"},{"location":"proposal/01-egress-gateway/EgressGateway/#iptables","title":"IPTables","text":"<pre><code>iptables -t mangle -F EGRESSGATEWAY-MARK-REQUEST-POLICY-NAME\niptables -t mangle -X EGRESSGATEWAY-MARK-REQUEST-POLICY-NAME\niptables -t mangle -N EGRESSGATEWAY-MARK-REQUEST-POLICY-NAME\n\niptables -A EGRESSGATEWAY-MARK-REQUEST-POLICY-NAME \\\n-t mangle \\\n-m conntrack --ctdir ORIGINAL \\\n-m set --match-set egress-dst-policy-name dst \\\n-m set --match-set egress-src-policy-name src \\\n-j MARK --set-mark 0x11000000 \\\n-m comment --comment \"rule uuid: mark request packet\"\n</code></pre>"},{"location":"proposal/01-egress-gateway/EgressGateway/#route","title":"Route","text":"<p>Normal.</p> <pre><code>ip rule add fwmark 0x11000000 table 100\nip route f table 100\nip route add default via 20.0.0.85 dev egress-vxlan-v4 onlink table 100\n</code></pre> <p>Equal-cost multi-path routing.</p> <pre><code>sysctl -w net.ipv4.fib_multipath_hash_policy=1\n</code></pre> <pre><code>ip rule add fwmark 0x11000000 table 100\nip route f table 100\nip route add table 100 default \\\nnexthop via 20.0.0.85 dev egress-vxlan onlink \\\nnexthop via 20.0.0.90 dev egress-vxlan onlink\n</code></pre>"},{"location":"proposal/01-egress-gateway/EgressGateway/#egress-node","title":"Egress Node","text":"<pre><code>iptables -t mangle -I FORWARD 1 -m mark --mark 0x11000000 -j MARK --set-mark 0x12000000 -m comment --comment \"egress gateway: change mark\"\niptables -t filter -I FORWARD 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t filter -I OUTPUT 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t mangle -I POSTROUTING 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t nat -I POSTROUTING 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: no snat\"\n</code></pre>"},{"location":"proposal/01-egress-gateway/EgressGateway/#implementation","title":"Implementation","text":""},{"location":"proposal/01-egress-gateway/EgressGateway/#controller","title":"Controller","text":"<p>Controller consists of Webhook Validator and Reconcile Flow.</p> <p></p> <p>Controller has 2 control processes, the first Watch cluster nodes, generate tunnel IP address and MAC address for Node, then <code>Create</code> or <code>Update</code> EgressTunnel CR Status. The second control flow watch <code>EgressTunnel</code> and <code>Egressgateway</code>, sync match node list from <code>labelSelector</code>, election egress gateway node.</p>"},{"location":"proposal/01-egress-gateway/EgressGateway/#agent","title":"Agent","text":"<p>Agent has two control processes, the first Watch <code>EgressTunnel</code> CR, which manages node tunnel, and node tunnel is a pluggable interface that can be replaced by Geneve. The second control process manages datapath policy, which watches <code>EgressTunnel</code>, <code>EgressGateway</code> and <code>Egresspolicy</code>, and sends them to the host through the police interface. It is currently implemented by a combination of ipset, iptables, and route, and it can be replaced by eBPF.</p>"},{"location":"proposal/02-egress-node/EgressTunnel-zh_CN/","title":"EgressTunnel zh CN","text":""},{"location":"proposal/02-egress-node/EgressTunnel-zh_CN/#egresstunnel-crd","title":"EgressTunnel CRD","text":"<pre><code>apiVersion: egressgateway.spidernet.io/v1\nkind: EgressTunnel\nmetadata:\nname: \"node1\"\nspec:\nstatus:\nphase: \"Ready\"\nvxlanIPv4IP: \"172.31.0.10/16\"\nvxlanIPv6IP: \"fe80::/64\"\ntunnelMac: \"xx:xx:xx:xx:xx\"\nphysicalInterface: \"eth1\"\nphysicalInterfaceIPv4: \"\"\nphysicalInterfaceIPv6: \"\"\n</code></pre> <p>\u7528\u4ee5\u5b58\u50a8\u5404\u8282\u70b9\u7684\u96a7\u9053\u7684\u4fe1\u606f\uff0c\u901a\u8fc7\u76d1\u63a7\u8282\u70b9\u6765\u751f\u6210</p> <p>\u5b57\u6bb5\u8bf4\u660e * status     * <code>phase</code> \u8868\u793a EgressTunnel  \u7684\u72b6\u6001\uff0c\u2019Ready\u2019 \u96a7\u9053IP\u5df2\u5206\u914d\uff0c\u4e14\u96a7\u9053\u5df2\u5efa\u6210\uff0c\u2019Pending\u2019 \u7b49\u5f85\u5206\u914dIP\uff0c\u2019Init\u2019 \u5206\u914d\u96a7\u9053 IP \u6210\u529f\uff0c\u2019Failed\u2019 \u96a7\u9053 IP \u5206\u914d\u5931\u8d25     * <code>vxlanIPv4IP</code> \u96a7\u9053 IPV4 \u5730\u5740     * <code>vxlanIPv6IP</code> \u96a7\u9053 IPV6 \u5730\u5740     * <code>tunnelMac</code> \u96a7\u9053 Mac \u5730\u5740     * <code>physicalInterface</code> \u96a7\u9053\u7236\u7f51\u5361     * <code>physicalInterfaceIPv4</code> \u7236\u7f51\u5361 IPV4 \u5730\u5740     * <code>physicalInterfaceIPv6</code> \u7236\u7f51\u5361 IPV6 \u5730\u5740</p>"},{"location":"proposal/02-egress-node/EgressTunnel-zh_CN/#controller","title":"controller \u5b9e\u73b0","text":""},{"location":"proposal/02-egress-node/EgressTunnel-zh_CN/#_1","title":"\u521d\u59cb\u5316","text":"<ol> <li>\u4ece CM\u4e2d\u83b7\u53d6 IPv4\u3001IPv6 \u53ca\u5bf9\u5e94\u7684 CIDR</li> <li>\u4f1a\u68c0\u67e5node \u662f\u5426\u6709\u5bf9\u5e94\u7684 EgressTunnel\uff0c\u6ca1\u6709\u7684\u8bdd\u5c31\u521b\u5efa\u5bf9\u5e94\u7684EgressTunnel\uff0c\u4e14\u72b6\u6001\u8bbe\u7f6e\u4e3a \u201cpending\u201d\u3002\u6709\u96a7\u9053 IP \u5219\u5c06 IP \u4e0e\u8282\u70b9\u7ed1\u5b9a\uff0c\u7ed1\u5b9a\u524d\u4f1a\u68c0\u67e5 IP \u662f\u5426\u5408\u6cd5\uff0c\u4e0d\u5408\u6cd5\u5219\u5c06\u72b6\u6001\u8bbe\u7f6e\u4e3a \u201cPending\u201d</li> </ol>"},{"location":"proposal/02-egress-node/EgressTunnel-zh_CN/#_2","title":"\u8282\u70b9\u4e8b\u4ef6\uff1a","text":"<ul> <li>\u5220\u9664\u4e8b\u4ef6\uff1a\u5220\u9664\u5bf9\u5e94\u7684 EgressTunnel</li> <li>\u5176\u4ed6\u4e8b\u4ef6\uff1a\u5982\u679c\u6ca1\u6709\u5bf9\u5e94\u7684 EgressTunnel\uff0c\u5219\u521b\u5efa EgressTunnel</li> <li> <p>\u5176\u4ed6\u4e8b\u4ef6\uff1a\u5982\u679c\u6709\u5bf9\u5e94\u7684 EgressTunnel\uff0c\u5219\u5bf9EgressTunnel\u8fdb\u884c\u6821\u9a8c\u3002\u6821\u9a8c\u903b\u8f91\u5982\u4e0b\uff1a</p> </li> <li> <ul> <li>\u65e0\u96a7\u9053IP\uff0c\u5c06\u72b6\u6001\u7f6e\u4e3a \u201cPending\u201d         \u5982\u679c\u6709\u96a7\u9053IP\uff0c\u5224\u65ad\u662f\u5426\u5408\u6cd5\uff0c\u4e0d\u5408\u6cd5\uff0c\u5c31\u5c06\u72b6\u6001\u7f6e\u4e3a \u201cPending\u201d         \u5982\u679c\u5408\u6cd5\uff0c\u6821\u9a8c IP \u662f\u5426\u5df2\u5206\u914d\uff0c\u5982\u679c\u5df2\u5206\u914d\uff0c\u4e14\u5206\u914d\u7ed9\u5176\u4ed6\u8282\u70b9\u4e86\uff0c\u5219\u5c06\u72b6\u6001\u7f6e\u4e3a \u201cPending\u201d         \u672a\u5206\u914d\u7ed9\u5176\u4ed6\u8282\u70b9\uff0c\u5c31\u5206\u914d\u7ed9\u672c \u201cEgressTunnel\u201d\uff0c\u5c06\u72b6\u6001\u8bbe\u7f6e\u4e3a \u201cInit\u201d         \u5982\u679c\u5df2\u5206\u914d\uff0c\u4e14\u5c31\u662f\u5206\u914d\u7ed9\u672c\u8282\u70b9\u7684\uff0c\u5219\u5c06\u72b6\u6001\u8bbe\u7f6e\u4e3a \u201cInit\u201d</li> </ul> </li> </ul>"},{"location":"proposal/02-egress-node/EgressTunnel-zh_CN/#egresstunnel","title":"EgressTunnel\u4e8b\u4ef6\uff1a","text":"<ul> <li>\u5220\u9664\u4e8b\u4ef6\uff1a\u5148\u91ca\u653eIP\u3002\u5982\u679c EgressTunnel \u5bf9\u5e94\u7684\u8282\u70b9\u5b58\u5728\uff0c\u5219\u91ca\u653eIP\uff0c\u91cd\u65b0\u521b\u5efa EgressTunnel\u3002</li> <li>\u5176\u4ed6\u4e8b\u4ef6\uff1a\u5982\u679c EgressTunnel \u72b6\u6001\u4e3a \u201cInit\u201d \u6216 \u8005\u201cReady\u201d \u65f6\uff0c\u4e0d\u505a\u4efb\u4f55\u5904\u7406\u3002\u5982\u679c\u4e0d\u662f\uff0c\u5219\u5206\u914d IP\uff0c\u5206\u914d\u6210\u529f\u5c06\u72b6\u6001\u8bbe\u7f6e\u4e3a \u201cInit\u201d\uff0c\u5206\u914d\u5931\u8d25\u5c06\u72b6\u6001\u8bbe\u7f6e\u4e3a \u201cFailed\u201d\u3002\u8fd9\u91cc\u662f\u5168\u5c40\u552f\u4e00\u4f1a\u5206\u914d\u96a7\u9053 IP \u7684\u5730\u65b9</li> </ul>"},{"location":"proposal/02-egress-node/EgressTunnel-zh_CN/#ip","title":"\u5206\u914d\u96a7\u9053 IP","text":"<ul> <li>controller \u542f\u52a8\u65f6\uff0c\u4ece config \u4e2d\u62ff\u5230\u96a7\u9053 IP CRID\uff0c\u5e76\u5728\u5185\u5b58\u4e2d\u7ef4\u62a4\u4e00\u4e2a map \u8bb0\u5f55 IP \u662f\u5426\u88ab\u5206\u914d</li> <li>\u96a7\u9053 IP \u91c7\u7528\u4e2d\u5fc3\u5f0f\uff0c\u6240\u4ee5\u4f7f\u7528\u4e32\u884c\u65b9\u5f0f\u5206\u914dIP\uff0c\u5728\u672a\u5206\u914d\u7684 IP \u4e2d\u968f\u673a\u5206\u914d</li> <li>\u5206\u914d\u524d\uff0c\u68c0\u6d4b\u96a7\u9053 IP \u51b2\u7a81\uff0c\u4e0d\u51b2\u7a81\u518d\u5206\u914d\uff08\u5b9e\u73b0\u65b9\u5f0f\u5f85\u5b9a\uff09</li> </ul>"},{"location":"proposal/02-egress-node/EgressTunnel-zh_CN/#_3","title":"\u5176\u4ed6","text":"<ul> <li>controller \u542f\u52a8\u65f6\uff0c\u5bf9\u6240\u7684 CRD \u7684 IP \u8fdb\u884c\u6821\u9a8c\uff0c\u4e14\u6700\u7ec8\u72b6\u6001\u8bbe\u7f6e\u4e3a \u201cInit\u201d \u6216 \u201cFailed\u201d \uff08\u6b64\u9879\u5f85\u5546\u69b7\uff09</li> <li>agent \u76d1\u6d4b\u5230\u5bf9\u5e94\u7684 CRD \u4e2d phase \u5b57\u6bb5\u4e3a \u201cInit\u201d \u65f6\uff0c\u521b\u5efa\u76f8\u5e94\u7684\u96a7\u9053\u53ca\u8def\u7531\uff0c\u521b\u5efa\u6210\u529f\u66f4\u65b0\u4e3a \u201cReady\u201d \u72b6\u6001\u3002\u5931\u8d25\u5219\u4e0d\u66f4\u65b0</li> <li>Mac\u5730\u5740\u683c\u5f0f\uff1a\u6839\u636e\u8282\u70b9\u540d\u79f0\uff0c\u7ecf\u8fc7 SHA1 \u7b97\u6cd5\u751f\u6210\uff0c\u6240\u4ee5\u6bcf\u4e2a\u8282\u70b9\u7684 Mac \u5730\u5740\u662f\u56fa\u5b9a\u7684</li> </ul>"},{"location":"proposal/02-egress-node/EgressTunnel/","title":"EgressTunnel CRD","text":"<pre><code>apiVersion: egressgateway.spidernet.io/v1\nkind: EgressTunnel\nmetadata:\nname: \"node1\"\nspec:\nstatus:\nphase: \"Ready\"\nvxlanIPv4IP: \"172.31.0.10/16\"\nvxlanIPv6IP: \"fe80::/64\"\ntunnelMac: \"xx:xx:xx:xx:xx\"\nphysicalInterface: \"eth1\"\nphysicalInterfaceIPv4: \"\"\nphysicalInterfaceIPv6: \"\"\n</code></pre> <p>Used to store information about each node's tunnel, generated by monitoring the node.</p> <p>Field Description</p> <ul> <li>status</li> <li><code>phase</code> indicates the status of the EgressTunnel, 'Ready' tunnel IP has been assigned and the tunnel has been built, 'Pending' waiting for IP assignment, 'Init ' Tunnel IP assigned successfully, 'Failed' Tunnel IP failed to be assigned.</li> <li><code>vxlanIPv4IP</code> Tunnel IPV4 address</li> <li><code>vxlanIPv6IP</code> tunnel IPV6 address</li> <li><code>tunnelMac</code> tunnel Mac address</li> <li><code>physicalInterface</code> Tunnel parent NIC</li> <li><code>physicalInterfaceIPv4</code> The IPV4 address of the parent NIC.</li> <li><code>physicalInterfaceIPv6</code> IPV6 address of the parent NIC.</li> </ul>"},{"location":"proposal/02-egress-node/EgressTunnel/#controller-implementation","title":"Controller implementation","text":""},{"location":"proposal/02-egress-node/EgressTunnel/#initialization","title":"Initialization","text":"<ol> <li>Get IPv4, IPv6 and corresponding CIDR from CM. 2.</li> <li>will check if the node has a corresponding EgressTunnel, if not, create a corresponding EgressTunnel with status set to \"pending\". If there is a tunnel IP, then bind the IP to the node, before binding, it will check if the IP is legal, if not, it will set the status to \"Pending\".</li> </ol>"},{"location":"proposal/02-egress-node/EgressTunnel/#node-events","title":"Node events","text":"<ul> <li>Delete event: delete the corresponding EgressTunnel.</li> <li>Other events: create EgressTunnel if there is no corresponding EgressTunnel.</li> <li> <p>Other events: if there is a corresponding EgressTunnel, validate the EgressTunnel. The calibration logic is as follows:</p> </li> <li> <p>If there is no tunnel IP, set the status to \"Pending\"</p> </li> <li>If there is a tunnel IP, determine whether it is legal or not, if not, set the state to \"Pending\"</li> <li>If it is legal, check whether the IP has been allocated, if it has been allocated, and allocated to other nodes, then set the state to \"Pending\"</li> <li>If it has not been allocated to other nodes, it is allocated to this \"EgressTunnel\", set the state to \"Init\"</li> <li>If it has been allocated, and it is the one allocated to this node, set the state to \"Init\"</li> </ul>"},{"location":"proposal/02-egress-node/EgressTunnel/#egresstunnel-events","title":"EgressTunnel events","text":"<ul> <li>Delete event: release IP first. if the node corresponding to EgressTunnel exists, release IP and recreate EgressTunnel.</li> <li>Other events: If the EgressTunnel status is \"Init\" or \"Ready\", do nothing. If not, the IP is allocated and the status is set to \"Init\" for successful allocation and \"Failed\" for failed allocation. This is the only place globally where tunnel IPs are assigned</li> </ul>"},{"location":"proposal/02-egress-node/EgressTunnel/#assign-tunnel-ip","title":"Assign tunnel IP","text":"<ul> <li>When the controller starts up, it gets the tunnel IP CRID from config and maintains a map in memory to record whether the IP has been allocated or not.</li> <li>Tunnel IPs are centered, so they are allocated serially, randomly among the unallocated IPs.</li> <li>Before allocating, detect tunnel IP conflict, allocate again if there is no conflict (implementation to be decided)</li> </ul>"},{"location":"proposal/02-egress-node/EgressTunnel/#other","title":"Other","text":"<ul> <li>When the controller starts up, it checks the IP of the CRD it is associated with, and the final state is set to \"Init\" or \"Failed\" (this is debatable).</li> <li>If the agent detects the phase field of the corresponding CRD is \"Init\", it will create the corresponding tunnel and route, and update to \"Ready\" state if it succeeds in creating the tunnel and route. If it fails, it will not be updated.</li> <li>Mac address format: generated by SHA1 algorithm based on node name, so the Mac address of each node is fixed.</li> </ul>"},{"location":"proposal/03-egress-ip/","title":"Egress IP","text":""},{"location":"proposal/03-egress-ip/#summary","title":"Summary","text":"<p>Updated EgressGateway CRD field to support setting EIP ranges, adjusted EgressGatewayEgressPolicy to tenant level, can select referenced EgressGateway, EgressGateway CRD added field to limit referenced tenants. The above adjustments allow different EgressGatewayPolicy to be assigned to different EIPs, which allows flexible planning of services according to different needs and flexible planning of cluster egress networks, and tenant-level resources allow different roles to carry out egress policy management. Add EgressEndpointSlice CRD to aggregate workloads in cluster policy matching to improve the scalability and performance of EgressGateway.</p>"},{"location":"proposal/03-egress-ip/#motivation","title":"Motivation","text":"<p>The current release of EgressGateway v0.1.0 supports the use of Egress Gateway's node IPs as egress IPs, which fulfills the ability to aggregate traffic for services that need to go out of the cluster. In a cluster, there are usually dozens or even hundreds of non-accessible services, in which many applications need to access different external networks, and a single EIP is overstretched under certain restrictions or rules, such as different EIPs have non-accessible firewall policies, and different EIPs have different access bandwidths. Different EIPs with different access bandwidths can be assigned to different applications or services through EgressGatewayPolicy, which can be managed at a fine-grained level to avoid potential security issues.</p>"},{"location":"proposal/03-egress-ip/#objectives","title":"Objectives","text":"<ul> <li>Support setting Egress IP ranges.</li> <li>Support setting tenant-level EgressGatewayPolicy.</li> <li>Improve the performance and scalability of EgressGateway.</li> <li>Update of configuration parameters involved in the change</li> </ul>"},{"location":"proposal/03-egress-ip/#non-target","title":"Non-target","text":"<ul> <li>Improve data plane forwarding performance</li> <li>Update the project document structure</li> </ul>"},{"location":"proposal/03-egress-ip/#design","title":"Design","text":""},{"location":"proposal/03-egress-ip/#crd","title":"CRD","text":""},{"location":"proposal/03-egress-ip/#egresstunnel","title":"EgressTunnel","text":"<p>Used to record tunnel NIC information for cross-node communication. Cluster-level resource that corresponds one-to-one with the Kubernetes Node resource name.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressTunnel\nmetadata:\nname: \"node1\"\nstatus:\ntunnel:\nipv4: \"192.200.222.157\"  # 1\nipv6: \"fd01::f2\"         # 2        \nmac: \"66:50:85:cb:b2:bf\" # 3\nparent:\nname: \"ens160\"        # 4\nipv4: \"10.6.1.21/16\"  # 5\nipv6: \"fd00::21/112\"  # 6\nphase: \"Ready\"              # 7\nmark: \"0x26000000\"          # 8\n</code></pre> <ol> <li>tunnel IPv4 address</li> <li>tunnel IPv6 address</li> <li>tunnel MAC address</li> <li>tunnel parent NIC</li> <li>the IPv4 address of the tunnel's parent NIC</li> <li>the IPv6 address of the tunnel's parent NIC</li> <li>current tunnel readiness stage</li> <li>mark address, this is a new segment, generated at creation. Each node has a globally unique label. The label is generated by prefix + unique identifier. The format of the tag is <code>NODE_MARK = 0x26 + value + 0000</code>, <code>value</code> is 16 bits and the total number of supported nodes is <code>2^16</code>. The label that is applied when issuing a policy rule depends on the nodes on which the rule's EIP is in effect.</li> </ol>"},{"location":"proposal/03-egress-ip/#egressgateway","title":"EgressGateway","text":"<p>Used to select a set of nodes to be the Egress gateway nodes, the Egress IP can float in this range. Cluster-level resources.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\nname: \"eg1\"\nspec:                            # 1\nranges:\npolicy: \"Random\"              # 2\nipv4:\n- \"\"\nipv6:\n- \"\"\nnodeSelector:                  # 3\nselector: matchLabels:\negress: \"true\"\npolicy: \"AverageSelecton\"    # 4\nstatus:\nnodeList:                 # 5\n- name: node1             # 6\neips:                   - ipv4: \"\"              # 7\nipv6: \"\"\npolicies:             # 8\n- \"\"\n</code></pre> <ol> <li>Set the range of Egress IP;</li> <li>Supports 3 ways to set a single IP <code>10.6.0.1</code>, and segments <code>10.6.0.1-10.6.0.10</code>, CIDR <code>10.6.0.1/26</code>;</li> <li>If the dual-stack requirement is enabled, the number of IPv4 and IPv6 are the same. For this reason, the above CIDRs may not be practical, so the first two are prioritized for implementation;</li> <li>the allocation policy of EIP, for the time being, it only supports <code>Random</code> random allocation.</li> <li>set the node range and policy for EgressGateway IP to float. 4. policy select the nodes of the gateway;</li> <li>policy for selecting nodes, only `AverageSelecton' is supported for the time being.</li> <li>Egress Gateway Controller is used to record and display the nodes matched by nodeSelector, for Node update Label or nodeSelector change will cause this field to change, Agent is the consumer of this field, will set the IP of the node belonging to their own node to the default name of <code>egress. eip</code> NIC. eip` NIC;</li> <li>the node selected by the EgressGatewayPolicy that references this EgressGateway as the gateway;</li> <li>the effective EIP, or null if useNodeIP is <code>true</code> in the EgressGatewayPolicy;</li> <li>the field by which the Agent determines which nodes are gateway and non-gateway nodes for which EgressGatewayPolicy.</li> </ol>"},{"location":"proposal/03-egress-ip/#egressgatewaypolicy","title":"EgressGatewayPolicy","text":"<p>Used to specify which Pods walk the Egress policy and the IP address used by Egress. Tenant-Level Resources.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGatewayPolicy\nmetadata:\nnamespace: \"default\"\nname: \"policy-test\"\nspec:\negressGatewayName: \"eg1\"  # 1\negressIP:                 # 2\nipv4: \"\"                            ipv6: \"\"\nuseNodeIP: false        # 3\nappliedTo:                # 4\npodSelector:            # 4-a \nmatchLabels:    app: \"shopping\"\npodSubnet:              # 4-b\n- \"172.29.16.0/24\"\n- 'fd00:1/126'\ndestSubnet:               # 5\n- \"10.6.1.92/32\"\n- \"fd00::92/128\"\n</code></pre> <ol> <li>select the EgressGateway referenced by the policy;</li> <li>the Egress IP access policy;</li> <li>If an <code>ipv4</code> or <code>ipv6</code> address is defined at the time of creation, an IP address is assigned from the EgressGateway's <code>.ranges</code>. If a user applies the IP addresses <code>10.6.1.21</code> and <code>fd00:1</code> in policy1 and then creates policy2 with the IP addresses <code>10.6.1.21</code> and <code>fd00:2</code>, an error is reported and policy2 fails to be assigned. .1.21<code>and</code>fd00:2`, then an error is reported and policy2 fails to be assigned;</li> <li>If the <code>ipv4</code> or <code>ipv6</code> address is not defined and <code>useNodeIP</code> is true, the IP of the Node in the match of the referenced EgressGateway is used as the Egress address.</li> <li>If an <code>ipv4</code> or <code>ipv6</code> address is not defined at creation and <code>useNodeIP</code> is <code>false</code>.<ul> <li>An IP address is automatically assigned from the EgressGateway's <code>.ranges</code> (when IPv6 is turned on. request an IPv4 and an IPv6 address);</li> </ul> </li> <li>If <code>egressGatewayName</code> is undefined;<ul> <li>Continue to see if the current Namespace label key <code>egressgateway.spidernet.io/default</code> has the default EgressGateway set, and if it does and this tenant is allowed to use it, assign EgressIP from there;</li> <li>Continue to see if there is a name for the <code>default</code> global default EgressGateway, and if there is and this tenant is allowed to use it, assign EgressIP from there.</li> </ul> </li> <li>supports the use of node IPs as Egress IPs (only one selection is allowed);</li> <li>select the Pod to which the Egress Gateway Policy needs to be applied;    a. Select by Label    b. directly specify the network segment of the Pod (a and b cannot be used at the same time)</li> <li>Specify the destination address for accessing Egress. If no destination address is specified, all the policy bits in effect will be forwarded to the Egress node if the destination address is not a CIDR in the cluster.</li> </ol>"},{"location":"proposal/03-egress-ip/#egressendpointslice","title":"EgressEndpointSlice","text":"<p>Aggregates endpoints in an EgressGatewayPolicy match to improve scalability, only supported if the EgressGatewayPolicy matches Pods using the <code>podSelector</code> method. The number of Endpoints in each EgressEndpointSlice does not exceed 100 by default, and the maximum value can be set. It is a dependent resource of EgressGatewayPolicy.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressEndpointSlice\nmetadata:\nname: \"policy-test-dx66t\"     # 1\nnamespace: \"default\"         labels:\negressgateway.spidernet.io/egressgatewaypolicy: \"policy-test\"  # 2\nownerReferences:   # 3\n- apiVersion: egressgateway.spidernet.io/v1beta1\nblockOwnerDeletion: true\ncontroller: true\nkind: EgressGatewayPolicy\nname: \"policy-test\"\nuid: 1b2ec0a8-b929-4528-8f99-499f981d319e\ndata:\nendpoints:                   # 4\n- podName: \"web-app\"         ipv4List:\n- \"172.29.30.123\" ipv6List:\n- \"xxx\"         nodeName: \"node1\"          # 5\nuuid: \"\"\n</code></pre> <ol> <li>the name consists of <code>policy-name-xxxxx</code> followed by 5 randomly generated digits;</li> <li>the name of the EgressGatewayPolicy to which it belongs; 3. the ownerReferences are set synchronously at creation time; and</li> <li>the ownerReferences are set synchronously upon creation; 4. a list of endpoints in the match; and</li> <li>a list of matched endpoints. 5. the node where the Pod is located;</li> <li>the node where the Pod is located.</li> </ol>"},{"location":"proposal/03-egress-ip/#data-plane-rules","title":"Data plane rules","text":"<p>The rules to be validated are categorized into three types: all nodes, gateway nodes relative to the EgressGatewayPolicy, and non-gateway nodes.</p>"},{"location":"proposal/03-egress-ip/#all-nodes","title":"All nodes","text":"<ol> <li>The rules for tunneling between nodes will not be expanded. 2;</li> <li>relabel the traffic that the policy hits. The first time a node becomes a gateway node, it is updated, or it is done once when the node joins, but not later;</li> </ol> <pre><code>iptables -t mangle -N EGRESSGATEWAY-RESET-MARK\niptables -t mangle -I FORWARD 1  -j EGRESSGATEWAY-RESET-MARK -m comment --comment \"egress gateway: mark egress packet\"\niptables -t mangle -A EGRESSGATEWAY-RESET-MARK \\\n-m mark --mark $NODE_MARK/0x26000000 \\\n-j MARK --set-mark 0x12000000 \\\n-m comment --comment \"egress gateway: change mark\"\n</code></pre> <ol> <li>Maintain the labeling of policy hit flows. It is created directly once and does not need to be updated;</li> </ol> <pre><code>iptables -t filter -I FORWARD 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t filter -I OUTPUT 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t mangle -I POSTROUTING 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\n</code></pre> <ol> <li>policy hits the source IP, destination IP of the ipset;</li> </ol> <pre><code>IPSET_RULE_DEST_NAME=egress-dest-uuid\nipset x $IPSET_RULE_DEST_NAME\nipset create $IPSET_RULE_DEST_NAME hash:net\nipset add $IPSET_RULE_DEST_NAME 10.6.105.150/32\n\nIPSET_RULE_SRC_NAME=egress-src-uuid\nipset x $IPSET_RULE_SRC_NAME\nipset create $IPSET_RULE_SRC_NAME hash:net\nipset add $IPSET_RULE_SRC_NAME 172.29.234.173/32\n</code></pre> <ol> <li>Aggregation policy Hits traffic-tagged chains. It is created directly once and does not need to be updated;</li> </ol> <pre><code>iptables -t mangle -N EGRESSGATEWAY-MARK-REQUEST\niptables -t mangle -I PREROUTING 1 -j EGRESSGATEWAY-MARK-REQUEST -m comment --comment \"egress gateway: mark egress packet\"\n</code></pre> <ol> <li>Aggregate chains that do not require SNAT rules. It is created directly once and does not need to be updated;</li> </ol> <pre><code>iptables -t nat -N EGRESSGATEWAY-NO-SNAT\niptables -t nat -I POSTROUTING 1  -j EGRESSGATEWAY-NO-SNAT -m comment --comment \"egress gateway: no snat\"\niptables -t nat -A EGRESSGATEWAY-NO-SNAT -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: no snat\"\n</code></pre> <ol> <li>Aggregate chains that require SNAT rules. It is created directly once and does not need to be updated.</li> </ol> <p><code>`shell    iptables -t nat -N EGRESSGATEWAY-SNAT-EIP    # Need to insert after rules that don't require SNAT to keep the chain at the top    iptables -t nat -I POSTROUTING 1 -j EGRESSGATEWAY-SNAT-EIP -m comment --comment \"egress gateway: snat EIP\"</code></p>"},{"location":"proposal/03-egress-ip/#non-egress-gateway-node-relative-to-eip","title":"Non-Egress Gateway node relative to EIP","text":"<ol> <li>policy hit traffic is labeled to ensure that it can go through the tunnel. where the value of NODE_MARK is determined by the node where the policy corresponds to the EIP.</li> </ol> <pre><code>iptables -A EGRESSGATEWAY-MARK-REQUEST -t mangle -m conntrack --ctdir ORIGINAL \\\n-m set --match-set $IPSET_RULE_DEST_NAME dst  \\\n-m set --match-set $IPSET_RULE_SRC_NAME src  \\\n-j MARK --set-mark $NODE_MARK -m comment --comment \"rule uuid: mark request packet\"\n</code></pre> <ol> <li>Policy routing rules</li> </ol> <pre><code>ip rule add fwmark $NODE_MARK table $TABLE_NUM\n</code></pre> <ol> <li>adapting Weave to avoid doing SNAT into the IP of the Egress tunnel. make the switch</li> </ol> <pre><code>iptables -t nat -A EGRESSGATEWAY-NO-SNAT \\\n-m set --match-set $IPSET_RULE_DEST_NAME dst  \\\n-m set --match-set $IPSET_RULE_SRC_NAME src  \\\n-j ACCEPT -m comment --comment \"egress gateway: weave does not do SNAT\"\n</code></pre>"},{"location":"proposal/03-egress-ip/#egress-gateway-node-relative-to-eip","title":"Egress Gateway node relative to EIP","text":"<ol> <li>policy hit traffic. SNAT is done on the way out of the gateway. real-time updates.</li> </ol> <pre><code>iptables -t nat -A EGRESSGATEWAY-SNAT-EIP \\\n-m set --match-set $IPSET_RULE_SRC_NAME src \\\n-m set --match-set $IPSET_RULE_DST_NAME dst \\\n-j SNAT --to-source $EIP\n</code></pre>"},{"location":"proposal/03-egress-ip/#egressgatewaypolicy-selection-of-gateway-nodes-and-eip-assignment-logic","title":"EgressGatewayPolicy Selection of gateway nodes and EIP assignment logic","text":"<p>A policy selects a node as a gateway node based on a gateway node selection policy. The decision to assign an EIP is then based on whether or not to use it, and the assigned EIP is bound to the selected gateway node.</p> <p>The allocation logic is all for a single EgressGateway, not all EgressGateways.</p>"},{"location":"proposal/03-egress-ip/#policy-mode-of-selecting-gateway-nodes","title":"policy Mode of selecting gateway nodes","text":"<ul> <li>Average selection: when a gateway node needs to be selected, select the node with the least number of nodes as gateway nodes.</li> <li>Minimum node selection: try to select the same node as a gateway node.</li> <li>Limit selection: a node can only be the gateway node of several policies at most, the limit can be set, the default is 5. Before the limit is reached, the node is preferred to be selected, and other nodes are selected when the limit is reached, and if all the limits are reached, the nodes will be selected randomly.</li> </ul>"},{"location":"proposal/03-egress-ip/#eip-allocation-logic","title":"EIP allocation logic","text":"<ul> <li>Random allocation: choose one randomly among all EIPs, no matter whether the EIP has been allocated or not</li> <li>Priority use of unallocated EIPs: use unallocated EIPs first, and then randomly allocate a used EIP if they are all used.</li> <li>Limit selection: an EIP can only be used by several policies at most, the limit can be set, the default is 5, before the limit is reached, the EIP will be assigned first, and if the limit is reached, then other EIPs will be selected; if the limit is reached, then the EIPs will be assigned randomly.</li> </ul>"},{"location":"proposal/03-egress-ip/#eip-recycling-logic","title":"EIP Recycling Logic","text":"<p>When an EIP is not used by a policy, it will be recycled, recycling means delete the EIP field in eips.</p>"},{"location":"proposal/03-egress-ip/#others","title":"Others","text":"<ol> <li>dummy card and EIP: each node has only one dummy card named <code>egress.eip</code>, all EIPs are valid on this node.</li> </ol> <pre><code># Create the dummy NIC\nip link add egress.eip type dummy\nip link set egress.eip up\n\n# Set EIP\nip addr add 10.6.168.100 dev egress.eip\n</code></pre> <ol> <li>Since the EIP is active on the dummy card, you need to configure ARP answering.</li> </ol> <pre><code>sysctl -w net.ipv4.conf.all.arp_ignore=0\n# All physical NICs need to be set up for surrogate answering, not sure what kind of NIC they go out from\nsysctl -w net.ipv4.conf.xxx.arp_ignore=0\n</code></pre> <ol> <li>mangle-FORWARD match Re-tag because <code>NODE_MARK = 0x26 + value + 0000</code>, so just match the first 16 bits.</li> </ol> <pre><code>iptables -t mangle -I FORWARD 1 -m mark --mark 0x26000000/0x26000000 -j MARK --set-mark 0x12000000 -m comment --comment \"egress gateway: change mark\"\n</code></pre> <ol> <li>Update the ipset content, the CRD aggregates the latest IP content, you can create a temporary ipset and then swap it, which greatly simplifies the ipset operation and improves efficiency.</li> </ol> <pre><code>ipset create egress-dst-v4-xxx-tmp ipset add egress-dst-v4-xxx-tmp $NEW_IP_RANGE\nipset swap egress-dst-v4-xxx egress-dst-v4-xxx-tmp </code></pre>"},{"location":"proposal/03-egress-ip/#code-design","title":"Code Design","text":""},{"location":"proposal/03-egress-ip/README_zh-CN/","title":"Egress IP","text":""},{"location":"proposal/03-egress-ip/README_zh-CN/#_1","title":"\u6982\u8981","text":"<p>\u66f4\u65b0 EgressGateway CRD \u5b57\u6bb5\u4ee5\u652f\u6301\u8bbe\u7f6e EIP \u8303\u56f4\uff0c\u8c03\u6574 EgressGatewayEgressPolicy \u4e3a\u79df\u6237\u7ea7\uff0c\u53ef\u4ee5\u9009\u62e9\u5f15\u7528\u7684 EgressGateway\uff0cEgressGateway CRD \u589e\u52a0\u5b57\u6bb5\u9650\u5236\u88ab\u5f15\u7528\u7684\u79df\u6237\u3002\u4ee5\u4e0a\u8c03\u6574\u53ef\u4ee5\u5141\u8bb8\u4e0d\u540c\u7684 EgressGatewayPolicy \u5206\u914d\u5230\u4e0d\u540c\u7684 EIP\uff0c\u53ef\u4ee5\u6839\u636e\u4e0d\u540c\u9700\u6c42\u7075\u6d3b\u89c4\u5212\u670d\u52a1\u7075\u6d3b\u89c4\u5212\u96c6\u7fa4\u51fa\u53e3\u7f51\u7edc\uff0c\u79df\u6237\u7ea7\u7684\u8d44\u6e90\u53ef\u4ee5\u8ba9\u4e0d\u540c\u7684\u89d2\u8272\u8fdb\u884c\u51fa\u53e3\u7b56\u7565\u7ba1\u7406\u3002\u589e\u52a0 EgressEndpointSlice CRD \u805a\u5408\u96c6\u7fa4\u7b56\u7565\u5339\u914d\u4e2d\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u63d0\u5347 EgressGateway \u7684\u6269\u5c55\u6027\u4e0e\u6027\u80fd\u3002</p>"},{"location":"proposal/03-egress-ip/README_zh-CN/#_2","title":"\u52a8\u673a","text":"<p>\u5f53\u524d\u5df2\u7ecf\u53d1\u5e03 EgressGateway v0.1.0 \u652f\u6301\u4f7f\u7528 Egress Gateway \u7684\u8282\u70b9 IP \u4f5c\u4e3a\u51fa\u53e3 IP\uff0c\u5b83\u6ee1\u8db3\u4e86\u5c06\u9700\u8981\u51fa\u96c6\u7fa4\u7684\u670d\u52a1\u7684\u6d41\u91cf\u805a\u5408\u80fd\u529b\u3002\u4e00\u4e2a\u96c6\u7fa4\u4e2d\u901a\u5e38\u5b58\u5728\u6570\u5341\u7ec4\u751a\u81f3\u6570\u767e\u7ec4\u4e0d\u901a\u7684\u670d\u52a1\uff0c\u5176\u4e2d\u591a\u7ec4\u5e94\u7528\u9700\u8981\u8bbf\u95ee\u4e0d\u540c\u5916\u90e8\u7f51\u7edc\uff0c\u5355\u4e2a EIP \u5728\u7279\u5b9a\u7684\u9650\u5236\u6216\u89c4\u5219\u4e0b\u663e\u5f97\u6349\u895f\u89c1\u8098\uff0c\u6bd4\u5982\u4e0d\u540c EIP \u7684\u5177\u6709\u4e0d\u901a\u7684\u9632\u706b\u5899\u7b56\u7565\uff0c\u4e0d\u540cEIP \u5177\u6709\u4e0d\u540c\u7684\u8bbf\u95ee\u5e26\u5bbd\u3002\u901a\u8fc7 EgressGatewayPolicy \u4e3a\u4e0d\u540c\u7684\u5e94\u7528\u6216\u670d\u52a1\u5206\u914d\u4e0d\u540c\u7684 EIP \u4e5f\u53ef\u4ee5\uff0c\u53ef\u4ee5\u7ec6\u7c92\u5ea6\u7ba1\u7406\uff0c\u80fd\u907f\u514d\u6f5c\u5728\u7684\u5b89\u5168\u95ee\u9898\u3002</p>"},{"location":"proposal/03-egress-ip/README_zh-CN/#_3","title":"\u76ee\u6807","text":"<ul> <li>\u652f\u6301\u8bbe\u7f6e Egress IP \u8303\u56f4</li> <li>\u652f\u6301\u8bbe\u7f6e\u79df\u6237\u7ea7 EgressGatewayPolicy</li> <li>\u63d0\u5347 EgressGateway \u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027</li> <li>\u66f4\u6539\u6d89\u53ca\u7684\u914d\u7f6e\u53c2\u6570\u66f4\u65b0</li> </ul>"},{"location":"proposal/03-egress-ip/README_zh-CN/#_4","title":"\u975e\u76ee\u6807","text":"<ul> <li>\u63d0\u5347\u6570\u636e\u9762\u8f6c\u53d1\u6027\u80fd</li> <li>\u66f4\u65b0\u9879\u76ee\u6587\u6863\u7ed3\u6784</li> </ul>"},{"location":"proposal/03-egress-ip/README_zh-CN/#_5","title":"\u8bbe\u8ba1","text":""},{"location":"proposal/03-egress-ip/README_zh-CN/#crd","title":"CRD","text":""},{"location":"proposal/03-egress-ip/README_zh-CN/#egresstunnel","title":"EgressTunnel","text":"<p>\u7528\u4e8e\u8bb0\u5f55\u8de8\u8282\u70b9\u901a\u4fe1\u7684\u96a7\u9053\u7f51\u5361\u4fe1\u606f\u3002\u96c6\u7fa4\u7ea7\u8d44\u6e90\uff0c\u4e0e Kubernetes Node \u8d44\u6e90\u540d\u79f0\u4e00\u4e00\u5bf9\u5e94\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressTunnel\nmetadata:\nname: \"node1\"\nstatus:\ntunnel:\nipv4: \"192.200.222.157\"  # 1\nipv6: \"fd01::f2\"         # 2        \nmac: \"66:50:85:cb:b2:bf\" # 3\nparent:\nname: \"ens160\"        # 4\nipv4: \"10.6.1.21/16\"  # 5\nipv6: \"fd00::21/112\"  # 6\nphase: \"Ready\"              # 7\nmark: \"0x26000000\"          # 8\n</code></pre> <ol> <li>\u96a7\u9053 IPv4 \u5730\u5740</li> <li>\u96a7\u9053 IPv6 \u5730\u5740</li> <li>\u96a7\u9053 MAC \u5730\u5740</li> <li>\u96a7\u9053\u7236\u7f51\u5361</li> <li>\u96a7\u9053\u7236\u7f51\u5361 IPv4 \u5730\u5740 </li> <li>\u96a7\u9053\u7236\u7f51\u5361 IPv6 \u5730\u5740 </li> <li>\u5f53\u524d\u96a7\u9053\u5c31\u7eea\u9636\u6bb5</li> <li>mark \u5730\u5740\uff0c\u6b64\u4e3a\u65b0\u589e\u6b64\u6bb5\uff0c\u521b\u5efa\u65f6\u751f\u6210\u3002\u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u4e00\u4e2a\uff0c\u5168\u5c40\u552f\u4e00\u7684\u6807\u7b7e\u3002\u6807\u7b7e\u7531\u524d\u7f00 + \u552f\u4e00\u6807\u8bc6\u7b26\u751f\u6210\u3002\u6807\u7b7e\u683c\u5f0f\u5982\u4e0b <code>NODE_MARK = 0x26 + value + 0000</code>\uff0c<code>value</code> \u4e3a 16 \u4f4d\uff0c\u652f\u6301\u7684\u8282\u70b9\u603b\u6570\u4e3a <code>2^16</code>\u3002\u5728\u4e0b\u53d1 policy \u89c4\u5219\u65f6\u6240\u6253\u7684\u6807\u7b7e\uff0c\u53d6\u51b3\u4e8e\u8be5\u89c4\u5219\u7684 EIP \u6240\u751f\u6548\u7684\u8282\u70b9\u3002</li> </ol>"},{"location":"proposal/03-egress-ip/README_zh-CN/#egressgateway","title":"EgressGateway","text":"<p>\u7528\u4e8e\u9009\u62e9\u4e00\u7ec4\u8282\u70b9\u4f5c\u4e3a Egress \u7f51\u5173\u8282\u70b9\uff0cEgress IP \u53ef\u4ee5\u5728\u8be5\u8303\u56f4\u6d6e\u52a8\u3002\u96c6\u7fa4\u7ea7\u8d44\u6e90\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\nname: \"eg1\"\nspec:                            # 1\nranges:\npolicy: \"Random\"              # 2\nipv4:\n- \"\"\nipv6:\n- \"\"\nnodeSelector:                  # 3\nselector: matchLabels:\negress: \"true\"\npolicy: \"AverageSelecton\"    # 4\nstatus:\nnodeList:                 # 5\n- name: node1             # 6\neips:                   - ipv4: \"\"              # 7\nipv6: \"\"\npolicies:             # 8\n- \"\"\n</code></pre> <ol> <li>\u8bbe\u7f6e Egress IP \u7684\u8303\u56f4\uff1b</li> <li>\u652f\u6301\u8bbe\u7f6e\u5355\u4e2a IP <code>10.6.0.1</code> \uff0c\u548c\u6bb5 <code>10.6.0.1-10.6.0.10</code> \uff0c CIDR <code>10.6.0.1/26</code>  \u7684\u65b9\u5f0f 3 \u79cd\u65b9\u5f0f\uff1b</li> <li>\u5982\u679c\u5f00\u542f\u53cc\u6808\u8981\u6c42\uff0cIPv4 \u7684\u6570\u91cf\u548c IPv6 \u7684\u6570\u91cf\u65f6\u4e00\u81f4\u7684\u3002\u7531\u4e8e\u6b64\u539f\u56e0\uff0c\u4f1a\u5bfc\u81f4\u4e0a\u9762 CIDR \u53ef\u80fd\u5e76\u4e0d\u5b9e\u7528\uff0c\u56e0\u6b64\u4f18\u5148\u7ea7\u4f18\u5148\u5b9e\u73b0\u524d 2 \u79cd\uff1b</li> <li>EIP \u7684\u5206\u914d\u7b56\u7565\uff0c\u6682\u65f6\u53ea\u652f\u6301 <code>Random</code> \u968f\u673a\u5206\u914d</li> <li>\u8bbe\u7f6e EgressGateway IP \u53ef\u6d6e\u52a8\u7684\u8282\u70b9\u8303\u56f4\u53ca\u7b56\u7565\uff1b</li> <li>policy \u9009\u7f51\u5173\u8282\u70b9\u7684\u7b56\u7565\uff0c\u6682\u65f6\u53ea\u652f\u6301 <code>AverageSelecton</code> \u5e73\u5747\u5206\u914d</li> <li>Egress Gateway Controller \u7528\u4e8e\u8bb0\u5f55\u663e\u793a nodeSelector \u5339\u914d\u4e2d\u7684\u8282\u70b9\uff0c\u5bf9\u4e8e Node \u66f4\u65b0 Label \u6216 nodeSelector \u53d8\u52a8\u90fd\u4f1a\u5f15\u8d77\u6b64\u5b57\u6bb5\u53d8\u52a8\uff0cAgent \u662f\u6b64\u5b57\u6bb5\u7684\u6d88\u8d39\u8005\uff0c\u4f1a\u5c06\u5c5e\u4e8e\u81ea\u5df1\u8282\u70b9\u7684 IP \u8bbe\u7f6e\u5230\u9ed8\u8ba4\u540d\u4e3a <code>egress.eip</code> \u7f51\u5361\uff1b</li> <li>\u88ab\u5f15\u7528\u8be5 EgressGateway \u7684 EgressGatewayPolicy \u9009\u4e2d\uff0c\u4f5c\u4e3a\u7f51\u5173\u7684\u8282\u70b9\uff1b</li> <li>\u751f\u6548\u7684 EIP\uff0c\u5982\u679c EgressGatewayPolicy \u4e2d useNodeIP \u4e3a <code>true</code> \u65f6\uff0c\u5219\u8be5\u5b57\u6bb5\u4e3a\u7a7a;</li> <li>Agent \u901a\u8fc7\u8be5\u5b57\u6bb5\u5224\u65ad\u54ea\u4e9b\u8282\u70b9\u662f\u54ea\u4e9b EgressGatewayPolicy \u7684\u7f51\u5173\u8282\u70b9\u53ca\u975e\u7f51\u5173\u8282\u70b9\uff1b</li> </ol>"},{"location":"proposal/03-egress-ip/README_zh-CN/#egressgatewaypolicy","title":"EgressGatewayPolicy","text":"<p>\u7528\u4e8e\u6307\u5b9a\u54ea\u4e9b Pod \u8d70 Egress \u7b56\u7565\uff0c\u4ee5\u53ca Egress \u6240\u4f7f\u7528\u7684 IP \u5730\u5740\u3002\u79df\u6237\u7ea7\u8d44\u6e90\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGatewayPolicy\nmetadata:\nnamespace: \"default\"\nname: \"policy-test\"\nspec:\negressGatewayName: \"eg1\"  # 1\negressIP:                 # 2\nipv4: \"\"                            ipv6: \"\"\nuseNodeIP: false        # 3\nappliedTo:                # 4\npodSelector:            # 4-a \nmatchLabels:    app: \"shopping\"\npodSubnet:              # 4-b\n- \"172.29.16.0/24\"\n- 'fd00:1/126'\ndestSubnet:               # 5\n- \"10.6.1.92/32\"\n- \"fd00::92/128\"\n</code></pre> <ol> <li>\u9009\u62e9\u7b56\u7565\u5f15\u7528\u7684 EgressGateway\uff1b</li> <li>Egress IP \u51c6\u5165\u7b56\u7565\uff1b</li> <li>\u82e5\u5728\u521b\u5efa\u65f6\u5b9a\u4e49\u4e86 <code>ipv4</code> \u6216 <code>ipv6</code> \u5730\u5740\uff0c\u5219\u4ece EgressGateway \u7684 <code>.ranges</code> \u4e2d\u5206\u914d\u4e00\u4e2a IP \u5730\u5740\uff0c\u82e5\u7528\u6237\u5728 policy1 \u4e2d\uff0c\u7533\u8bf7\u4f7f\u7528\u4e86 IP \u5730\u5740 <code>10.6.1.21</code> \u548c <code>fd00:1</code> \uff0c\u7136\u540e\u521b\u5efa policy2 \u4e2d\uff0c\u7533\u8bf7\u4f7f\u7528\u4e86 IP \u5730\u5740 <code>10.6.1.21</code> \u548c <code>fd00:2</code> \uff0c\u5219\u4f1a\u62a5\u9519\uff0c\u6b64\u65f6 policy2 \u4f1a\u5206\u914d\u5931\u8d25\uff1b</li> <li>\u82e5\u672a\u5b9a\u4e49 <code>ipv4</code> \u6216 <code>ipv6</code> \u5730\u5740\uff0c\u4e14 <code>useNodeIP</code> \u4e3a true \u65f6\uff0c\u5219\u4f7f\u7528\u6240\u5f15\u7528 EgressGateway \u7684\u5339\u914d\u4e2d\u7684 Node \u7684 IP \u4f5c\u4e3a Egress \u5730\u5740\u3002</li> <li>\u82e5\u672a\u5728\u521b\u5efa\u65f6\u5b9a\u4e49 <code>ipv4</code> \u6216 <code>ipv6</code> \u5730\u5740\uff0c\u4e14 <code>useNodeIP</code> \u4e3a <code>false</code> \u65f6\u3002<ul> <li>\u5219\u81ea\u52a8\u4ece EgressGateway \u7684 <code>.ranges</code> \u4e2d\u5206\u914d\u4e00\u4e2a IP \u5730\u5740\uff08\u5f00\u542f IPv6 \u65f6\uff0c\u8bf7\u6c42\u5206\u914d\u4e00\u4e2a IPv4 \u548c \u4e00\u4e2a IPv6 \u5730\u5740\uff09\uff1b</li> </ul> </li> <li>\u82e5 <code>egressGatewayName</code> \u672a\u5b9a\u4e49\uff1b<ul> <li>\u7ee7\u7eed\u5219\u67e5\u770b\u662f\u5f53\u524d Namespace \u7684 label \u952e <code>egressgateway.spidernet.io/default</code> \u662f\u5426\u8bbe\u7f6e\u9ed8\u8ba4\u7684 EgressGateway\uff0c\u5982\u679c\u6709\u4e14\u5141\u8bb8\u6b64\u79df\u6237\u4f7f\u7528\uff0c\u5219\u4ece\u6b64\u5206\u914d EgressIP\uff1b</li> <li>\u7ee7\u7eed\u67e5\u770b\u662f\u5426\u6709\u540d\u79f0\u4e3a <code>default</code> \u5168\u5c40\u9ed8\u8ba4 EgressGateway\uff0c\u5982\u679c\u6709\u4e14\u5141\u8bb8\u6b64\u79df\u6237\u4f7f\u7528\uff0c\u5219\u4ece\u6b64\u5206\u914d EgressIP\u3002</li> </ul> </li> <li>\u652f\u6301\u4f7f\u7528\u8282\u70b9 IP \u4f5c\u4e3a Egress IP\uff08\u53ea\u5141\u8bb8\u9009\u62e9\u4e00\u79cd\uff09\uff1b</li> <li>\u9009\u62e9\u9700\u8981\u5e94\u7528 Egress Gateway Policy \u7684 Pod\uff1b    a. \u4ee5 Label \u7684\u65b9\u5f0f\u8fdb\u884c\u9009\u62e9    b. \u76f4\u63a5\u6307\u5b9a Pod \u7684\u7f51\u6bb5 \uff08a \u548c b \u4e0d\u80fd\u540c\u65f6\u4f7f\u7528\uff09</li> <li>\u6307\u5b9a\u8bbf\u95ee Egress \u7684\u76ee\u6807\u5730\u5740\uff0c\u82e5\u672a\u6307\u5b9a\u76ee\u6807\u5730\u5740\uff0c\u5219\u751f\u6548\u7684\u7b56\u7565\u4f4d\u76ee\u6807\u5730\u5740\u975e\u96c6\u7fa4\u5185 CIDR \u65f6\uff0c\u5168\u90e8\u8f6c\u53d1\u5230 Egress \u8282\u70b9\u3002</li> </ol>"},{"location":"proposal/03-egress-ip/README_zh-CN/#egressendpointslice","title":"EgressEndpointSlice","text":"<p>\u805a\u5408 EgressGatewayPolicy \u5339\u914d\u4e2d\u7684\u7aef\u70b9\uff0c\u4ee5\u63d0\u9ad8\u6269\u5c55\u6027\uff0c\u4ec5\u652f\u6301 EgressGatewayPolicy \u4f7f\u7528 <code>podSelector</code> \u7684\u65b9\u5f0f\u5339\u914d Pod \u7684\u60c5\u51b5\u3002\u6bcf\u4e2a EgressEndpointSlice \u4e2d\u7684 Endpoint \u4e2a\u6570\u9ed8\u8ba4\u4e0d\u8d85\u8fc7 100\uff0c\u6700\u5927\u503c\u53ef\u4ee5\u8fdb\u884c\u8bbe\u7f6e\u3002\u662f EgressGatewayPolicy \u7684\u9644\u5c5e\u8d44\u6e90\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressEndpointSlice\nmetadata:\nname: \"policy-test-dx66t\"     # 1\nnamespace: \"default\"         labels:\negressgateway.spidernet.io/egressgatewaypolicy: \"policy-test\"  # 2\nownerReferences:   # 3\n- apiVersion: egressgateway.spidernet.io/v1beta1\nblockOwnerDeletion: true\ncontroller: true\nkind: EgressGatewayPolicy\nname: \"policy-test\"\nuid: 1b2ec0a8-b929-4528-8f99-499f981d319e\ndata:\nendpoints:                   # 4\n- podName: \"web-app\"         ipv4List:\n- \"172.29.30.123\" ipv6List:\n- \"xxx\"         nodeName: \"node1\"          # 5\nuuid: \"\"\n</code></pre> <ol> <li>\u540d\u79f0\u7531 <code>policy-name-xxxxx</code> \u7ec4\u6210\uff0c\u540e\u9762 5 \u4f4d\u968f\u673a\u751f\u6210\uff1b</li> <li>\u6240\u5c5e\u7684 EgressGatewayPolicy \u540d\u79f0\uff1b</li> <li>\u521b\u5efa\u65f6\u540c\u6b65\u8bbe\u7f6e ownerReferences\uff1b</li> <li>\u5339\u914d\u4e2d\u7684 endpoints \u7684\u5217\u8868\uff1b</li> <li>Pod \u6240\u5728\u7684\u8282\u70b9\u3002</li> </ol>"},{"location":"proposal/03-egress-ip/README_zh-CN/#_6","title":"\u6570\u636e\u9762\u89c4\u5219","text":"<p>\u5bf9\u9700\u8981\u751f\u6548\u7684\u89c4\u5219\u5206\u4e3a\u4e09\u7c7b\uff1a\u6240\u6709\u8282\u70b9\uff0c\u76f8\u5bf9\u4e8e EgressGatewayPolicy \u7684\u300c\u7f51\u5173\u8282\u70b9\u300d\u548c\u300c\u975e\u7f51\u5173\u8282\u70b9\u300d\u3002</p>"},{"location":"proposal/03-egress-ip/README_zh-CN/#_7","title":"\u6240\u6709\u8282\u70b9","text":"<ol> <li>\u5404\u8282\u70b9\u4e4b\u95f4\uff0c\u96a7\u9053\u9700\u8981\u6253\u901a\u7684\u89c4\u5219\u5c31\u5c31\u4e0d\u4e00\u4e00\u5c55\u5f00\uff1b</li> <li>\u5c06 policy \u547d\u4e2d\u7684\u6d41\u91cf\uff0c\u91cd\u65b0\u6253\u6807\u7b7e\u3002\u8282\u70b9\u7b2c\u4e00\u6b21\u53d8\u6210\u7f51\u5173\u8282\u70b9\u65f6\u66f4\u65b0\uff0c\u6216\u8005\u8282\u70b9 join \u65f6\u505a\u4e00\u6b21\uff0c\u540e\u9762\u4e0d\u66f4\u65b0\uff1b    <pre><code>iptables -t mangle -N EGRESSGATEWAY-RESET-MARK\niptables -t mangle -I FORWARD 1  -j EGRESSGATEWAY-RESET-MARK -m comment --comment \"egress gateway: mark egress packet\"\niptables -t mangle -A EGRESSGATEWAY-RESET-MARK \\\n-m mark --mark $NODE_MARK/0x26000000 \\\n-j MARK --set-mark 0x12000000 \\\n-m comment --comment \"egress gateway: change mark\"\n</code></pre></li> <li>\u4fdd\u6301 policy \u547d\u4e2d\u6d41\u91cf\u7684\u6807\u7b7e\u3002\u76f4\u63a5\u521b\u5efa\u4e00\u6b21\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\uff1b    <pre><code>iptables -t filter -I FORWARD 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t filter -I OUTPUT 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t mangle -I POSTROUTING 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\n</code></pre></li> <li>policy \u547d\u4e2d\u7684\u6e90 IP\u3001\u76ee\u7684 IP \u7684 ipset\uff1b    <pre><code>IPSET_RULE_DEST_NAME=egress-dest-uuid\nipset x $IPSET_RULE_DEST_NAME\nipset create $IPSET_RULE_DEST_NAME hash:net\nipset add $IPSET_RULE_DEST_NAME 10.6.105.150/32\n\nIPSET_RULE_SRC_NAME=egress-src-uuid\nipset x $IPSET_RULE_SRC_NAME\nipset create $IPSET_RULE_SRC_NAME hash:net\nipset add $IPSET_RULE_SRC_NAME 172.29.234.173/32\n</code></pre></li> <li>\u805a\u5408 policy \u547d\u4e2d\u6d41\u91cf\u6253\u6807\u7b7e\u7684\u94fe\u3002\u76f4\u63a5\u521b\u5efa\u4e00\u6b21\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\uff1b    <pre><code>iptables -t mangle -N EGRESSGATEWAY-MARK-REQUEST\niptables -t mangle -I PREROUTING 1 -j EGRESSGATEWAY-MARK-REQUEST -m comment --comment \"egress gateway: mark egress packet\"\n</code></pre></li> <li>\u805a\u5408\u4e0d\u9700\u8981\u505a SNAT \u89c4\u5219\u7684\u94fe\u3002\u76f4\u63a5\u521b\u5efa\u4e00\u6b21\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\uff1b    <pre><code>iptables -t nat -N EGRESSGATEWAY-NO-SNAT\niptables -t nat -I POSTROUTING 1  -j EGRESSGATEWAY-NO-SNAT -m comment --comment \"egress gateway: no snat\"\niptables -t nat -A EGRESSGATEWAY-NO-SNAT -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: no snat\"\n</code></pre></li> <li>\u805a\u5408\u9700\u8981\u505a SNAT \u89c4\u5219\u7684\u94fe\u3002\u76f4\u63a5\u521b\u5efa\u4e00\u6b21\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\u3002    <pre><code>iptables -t nat -N EGRESSGATEWAY-SNAT-EIP\n# \u9700\u8981\u5728\u4e0d\u9700\u8981 SNAT \u7684\u89c4\u5219\u540e\u9762\u63d2\u5165\uff0c\u624d\u80fd\u4fdd\u8bc1\u8be5\u94fe\u5728\u6700\u524d\u9762\niptables -t nat -I POSTROUTING 1  -j EGRESSGATEWAY-SNAT-EIP -m comment --comment \"egress gateway: snat EIP\"\n</code></pre></li> </ol>"},{"location":"proposal/03-egress-ip/README_zh-CN/#eip-egress-gateway","title":"\u76f8\u5bf9\u4e8e EIP \u7684\u975e Egress Gateway \u8282\u70b9","text":"<ol> <li>policy \u547d\u4e2d\u7684\u6d41\u91cf\u6253\u6807\u7b7e\uff0c\u4fdd\u8bc1\u80fd\u4ece\u96a7\u9053\u8d70\u3002\u5176\u4e2d NODE_MARK \u7684\u503c\u6839\u636e policy \u5bf9\u5e94\u7684 EIP \u6240\u5728\u8282\u70b9\u51b3\u5b9a\u3002    <pre><code>iptables -A EGRESSGATEWAY-MARK-REQUEST -t mangle -m conntrack --ctdir ORIGINAL \\\n-m set --match-set $IPSET_RULE_DEST_NAME dst  \\\n-m set --match-set $IPSET_RULE_SRC_NAME src  \\\n-j MARK --set-mark $NODE_MARK -m comment --comment \"rule uuid: mark request packet\"\n</code></pre></li> <li>\u7b56\u7565\u8def\u7531\u89c4\u5219    <pre><code>ip rule add fwmark $NODE_MARK table $TABLE_NUM\n</code></pre> 3.\u9002\u914d Weave \u907f\u514d\u505a SNAT \u6210 Egress \u96a7\u9053\u7684 IP\u3002\u505a\u6210\u5f00\u5173    <pre><code>iptables -t nat -A EGRESSGATEWAY-NO-SNAT \\\n-m set --match-set $IPSET_RULE_DEST_NAME dst  \\\n-m set --match-set $IPSET_RULE_SRC_NAME src  \\\n-j ACCEPT -m comment --comment \"egress gateway: weave does not do SNAT\"\n</code></pre></li> </ol>"},{"location":"proposal/03-egress-ip/README_zh-CN/#eip-egress-gateway_1","title":"\u76f8\u5bf9\u4e8e EIP \u7684 Egress Gateway \u8282\u70b9","text":"<ol> <li>policy \u547d\u4e2d\u7684\u6d41\u91cf\u3002\u51fa\u7f51\u5173\u65f6\u505a SNAT\u3002\u5b9e\u65f6\u66f4\u65b0\u3002    <pre><code>iptables -t nat -A EGRESSGATEWAY-SNAT-EIP \\\n-m set --match-set $IPSET_RULE_SRC_NAME src \\\n-m set --match-set $IPSET_RULE_DST_NAME dst \\\n-j SNAT --to-source $EIP\n</code></pre></li> </ol>"},{"location":"proposal/03-egress-ip/README_zh-CN/#egressgatewaypolicy-eip","title":"EgressGatewayPolicy \u9009\u7f51\u5173\u8282\u70b9\u53ca EIP \u5206\u914d\u903b\u8f91","text":"<p>\u4e00\u4e2a policy \u4f1a\u6839\u636e\u9009\u7f51\u5173\u8282\u70b9\u7684\u7b56\u7565\uff0c\u9009\u62e9\u4e00\u4e2a\u8282\u70b9\u4f5c\u4e3a\u7f51\u5173\u8282\u70b9\u3002\u7136\u540e\u6839\u636e\u662f\u5426\u4f7f\u7528 EIP\uff0c\u6765\u51b3\u5b9a\u662f\u5426\u5206\u914d EIP\u3002\u5206\u914d\u7684 EIP \u5c06\u7ed1\u5b9a\u5230\u6240\u9009\u7684\u7f51\u5173\u8282\u70b9\u4e0a</p> <p>\u5206\u914d\u903b\u8f91\u90fd\u662f\u4ee5\u5355\u4e2a EgressGateway \u4e3a\u5bf9\u8c61\uff0c\u800c\u4e0d\u662f\u6240\u6709\u7684 EgressGateway\u3002</p>"},{"location":"proposal/03-egress-ip/README_zh-CN/#policy","title":"policy \u9009\u7f51\u5173\u8282\u70b9\u7684\u6a21\u5f0f","text":"<ul> <li>\u5e73\u5747\u9009\u62e9\uff1a\u5f53\u9700\u8981\u9009\u62e9\u7f51\u5173\u8282\u70b9\u65f6\uff0c\u9009\u62e9\u4f5c\u4e3a\u7f51\u5173\u8282\u70b9\u6700\u5c11\u7684\u4e00\u4e2a\u8282\u70b9\u3002</li> <li>\u6700\u5c11\u8282\u70b9\u9009\u62e9\uff1a\u5c3d\u91cf\u9009\u540c\u4e00\u4e2a\u8282\u70b9\u4f5c\u4e3a\u7f51\u5173\u8282\u70b9</li> <li>\u9650\u5ea6\u9009\u62e9\uff1a\u4e00\u4e2a\u8282\u70b9\u6700\u591a\u53ea\u80fd\u6210\u4e3a\u51e0\u4e2a policy \u7684\u7f51\u5173\u8282\u70b9\uff0c\u9650\u5ea6\u53ef\u4ee5\u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u4e3a 5\u3002\u6ca1\u6709\u8fbe\u5230\u9650\u5ea6\u524d\uff0c\u5219\u4f18\u5148\u9009\u62e9\u8be5\u8282\u70b9\uff0c\u8fbe\u5230\u9650\u5ea6\u5c31\u9009\u5176\u4ed6\u7684\u8282\u70b9\uff0c\u5982\u679c\u90fd\u8fbe\u5230\u4e86\u9650\u5ea6\uff0c\u5219\u968f\u673a\u9009\u62e9</li> </ul>"},{"location":"proposal/03-egress-ip/README_zh-CN/#eip","title":"EIP \u5206\u914d\u903b\u8f91","text":"<ul> <li>\u968f\u673a\u5206\u914d\uff1a\u5728\u6240\u6709\u7684 EIP \u4e2d\u968f\u673a\u9009\u62e9\u4e00\u4e2a\uff0c\u4e0d\u7ba1\u8be5 EIP \u662f\u5426\u5df2\u7ecf\u5206\u914d</li> <li>\u4f18\u5148\u4f7f\u7528\u672a\u5206\u914d\u7684 EIP\uff1a\u5148\u4f7f\u7528\u672a\u5206\u914d\u7684 EIP\uff0c\u5982\u679c\u90fd\u4f7f\u7528\u4e86\u5219\u518d\u968f\u673a\u5206\u914d\u4e00\u4e2a\u5df2\u4f7f\u7528\u7684 EIP</li> <li>\u9650\u5ea6\u9009\u62e9\uff1a\u4e00\u4e2a EIP \u6700\u591a\u53ea\u80fd\u88ab\u51e0\u4e2a policy \u4f7f\u7528\uff0c\u9650\u5ea6\u53ef\u4ee5\u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u4e3a 5\uff0c\u6ca1\u6709\u8fbe\u5230\u9650\u5ea6\u524d\uff0c\u5219\u5148\u5206\u914d\u8be5 EIP\uff0c\u8fbe\u5230\u9650\u5ea6\u5219\u9009\u5176\u4ed6\u7684 EIP\u3002\u90fd\u8fbe\u5230\u9650\u5ea6\u5219\u968f\u673a\u5206\u914d\u3002</li> </ul>"},{"location":"proposal/03-egress-ip/README_zh-CN/#eip_1","title":"EIP \u56de\u6536\u903b\u8f91","text":"<p>\u5f53\u4e00\u4e2a EIP \u6ca1\u6709\u88ab policy \u4f7f\u7528\u65f6\uff0c\u5219\u56de\u6536\u8be5 EIP\uff0c\u56de\u6536\u5c31\u662f\u5728 eips \u4e2d\u5c06\u8be5 EIP \u5b57\u6bb5\u5220\u9664</p>"},{"location":"proposal/03-egress-ip/README_zh-CN/#_8","title":"\u5176\u4ed6","text":"<ol> <li> <p>dummy \u7f51\u5361\u53ca EIP\uff1a\u6bcf\u4e2a\u8282\u70b9\u53ea\u6709\u4e00\u4e2a\u540d\u4e3a <code>egress.eip</code> \u7684 dummy \u7f51\u5361\uff0c\u6240\u6709\u7684 EIP \u90fd\u751f\u6548\u5728\u8be5\u8282\u70b9\u4e0a    <pre><code># \u521b\u5efa dummy \u7f51\u5361\nip link add egress.eip type dummy\nip link set egress.eip up\n\n# \u8bbe\u7f6e EIP\nip addr add 10.6.168.100 dev egress.eip\n</code></pre></p> </li> <li> <p>\u7531\u4e8e EIP \u662f\u751f\u6548\u5728 dummy \u7f51\u5361\u4e0a\u7684\uff0c\u6240\u4ee5\u9700\u8981\u914d\u7f6e ARP \u4ee3\u7b54\u3002    <pre><code>sysctl -w net.ipv4.conf.all.arp_ignore=0\n# \u6240\u6709\u7684\u7269\u7406\u7f51\u5361\u90fd\u9700\u8981\u8bbe\u7f6e\u4ee3\u7b54\uff0c\u4e0d\u786e\u5b9a\u4ece\u90a3\u79cd\u7f51\u5361\u51fa\u53bb\nsysctl -w net.ipv4.conf.xxx.arp_ignore=0\n</code></pre></p> </li> <li> <p>mangle-FORWARD match \u91cd\u65b0\u6253\u6807\u7b7e\uff0c\u56e0\u4e3a <code>NODE_MARK = 0x26 + value + 0000</code>\uff0c\u6240\u4ee5\u5339\u914d\u65f6\u53ea\u8981\u5339\u914d\u524d\u976216 \u4f4d\u3002    <pre><code>iptables -t mangle -I FORWARD 1 -m mark --mark 0x26000000/0x26000000 -j MARK --set-mark 0x12000000 -m comment --comment \"egress gateway: change mark\"\n</code></pre></p> </li> <li> <p>\u66f4\u65b0 ipset \u5185\u5bb9\uff0cCRD \u4e2d\u805a\u5408\u4e86\u6700\u65b0\u7684 IP \u5185\u5bb9\uff0c\u53ef\u4ee5\u5148\u521b\u5efa\u4e34\u65f6 ipset \u518d\u901a\u8fc7 swap \u8fdb\u884c\u4ea4\u6362\uff0c\u5927\u91cf\u7b80\u5316 ipset \u64cd\u4f5c\uff0c\u63d0\u9ad8\u6548\u7387\u3002    <pre><code>ipset create egress-dst-v4-xxx-tmp ipset add egress-dst-v4-xxx-tmp $NEW_IP_RANGE\nipset swap egress-dst-v4-xxx egress-dst-v4-xxx-tmp </code></pre></p> </li> </ol>"},{"location":"proposal/03-egress-ip/README_zh-CN/#_9","title":"\u4ee3\u7801\u8bbe\u8ba1","text":""},{"location":"proposal/04-auto-detect-egress-ignore-cidr/","title":"Egress ignore CIDR","text":""},{"location":"proposal/04-auto-detect-egress-ignore-cidr/#motivation","title":"Motivation","text":"<p>To simplify the configuration of the Egress policy, the Egress Ignore CIDR feature is introduced to allow manual and automatic acquisition of the cluster's CIDR. when the <code>destSubnet</code> field of the EgressGatewayPolicy is empty, the data plane automatically matches the EgressClusterInfo CR with traffic outside of the CIDR and forwards it to the Egress gateway. CIDR in the EgressClusterInfo CR and forwards it to the Egress gateway.</p>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/#objective","title":"Objective","text":"<ul> <li>Optimize the EgressGatewayPolicy experience.</li> </ul>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/#design","title":"Design","text":""},{"location":"proposal/04-auto-detect-egress-ignore-cidr/#egressclusterinfo-crd","title":"EgressClusterInfo CRD","text":"<p>Cluster-level CRD.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressClusterInfo\nmetadata:\nname: default  # 1\nspec:\nautoDetect:\nclusterIP: true # 2\nnodeIP: true # 3\npodCidrMode: auto # 4\nextraCidr: # 5\n- 10.10.10.1\nstatus:\nclusterIP: # 6\nipv4:\n- 172.41.0.0/16\nipv6:\n- fd41::/108\nextraCidr: # 7\n- 10.10.10.1\nnodeIP: # 8\negressgateway-control-plane:\nipv4:\n- 172.18.0.3\nipv6:\n- fc00:f853:ccd:e793::3\negressgateway-worker:\nipv4:\n- 172.18.0.2\nipv6:\n- fc00:f853:ccd:e793::2\negressgateway-worker2:\nipv4:\n- 172.18.0.4\nipv6:\n- fc00:f853:ccd:e793::4\npodCIDR: # 9\ndefault-ipv4-ippool:\nipv4:\n- 172.40.0.0/16\ndefault-ipv6-ippool:\nipv6:\n- fd40::/48\ntest-ippool:\nipv4:\n- 177.70.0.0/16\npodCidrMode: calico # 10\n</code></pre> <ol> <li>the name is `default', only one can be created by system maintenance; 2.</li> <li><code>clusterIP</code>, if set to <code>true</code>, the <code>Service CIDR</code> will automatically detect the <code>nodeIP</code> associated with the <code>nodeIP</code>.</li> <li><code>nodeIP</code>, if set to <code>true</code>, it will automatically detect changes in <code>nodeIP</code> and dynamically update it to <code>status.nodeIP</code> in <code>EgressClusterInfo</code>. 4.</li> <li><code>podCidrMode</code>, currently supports <code>k8s</code>, <code>calico</code>, <code>auto</code>, <code>\"\"</code>, indicates to automatically detect the corresponding podCidr, default is <code>auto</code>, if <code>auto</code> means to automatically detect the cni used by the cluster, and use the cluster's podCidr if it can't be detected. if <code>\"\"</code> means not to detect the podCidr, if <code>\"\"</code> means not to detect the podCidr. If <code>\"\"</code> is used, the cluster's podCidr is used.</li> <li><code>extraCidr</code>, you can manually fill in the <code>IP</code> cluster to be ignored.</li> <li><code>status.clusterIP</code>, if <code>spec.autoDetect.clusterIP</code> is <code>true</code>, the cluster <code>Service CIDR</code> is automatically detected and updated here.</li> <li><code>status.extraCidr</code>, which corresponds to `spec.extraCidr</li> <li><code>status.nodeIP</code>, if <code>spec.autoDetect.nodeIP</code> is <code>true</code>, then automatically detect cluster <code>nodeIP</code> and update here</li> <li><code>status.podCIDR</code>, corresponding to <code>spec.autoDetect.podCidrMode</code>, performs the relevant <code>podCidr</code> update</li> <li><code>status.podCidrMode</code>, corresponding to scenarios where <code>spec.autoDetect.podCidrMode</code> is `auto</li> </ol>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/#data-plane-policy","title":"Data plane policy","text":""},{"location":"proposal/04-auto-detect-egress-ignore-cidr/#ipset","title":"ipset","text":"<p>The data-plane changes the iptables match policy to <code>-match-set !egress-ingore-cidr dst</code> when dealing with an EgressGatewayPolicy where <code>destSubnet</code> is empty.</p> <pre><code>iptables -A EGRESSGATEWAY-MARK-REQUEST -t mangle -m conntrack --ctdir ORIGINAL \\\n-m set --match-set !egress-ingore-cidr dst  \\\n-m set --match-set $IPSET_RULE_SRC_NAME src  \\\n-j MARK --set-mark $NODE_MARK -m comment --comment \"rule uuid: mark request packet\"\n</code></pre>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/#code-design","title":"Code design","text":""},{"location":"proposal/04-auto-detect-egress-ignore-cidr/#controller","title":"Controller","text":"<p>Add a new control loop that watches the cluster's relevant resources based on the <code>spec.autoDetect</code> configuration, updating the auto-detected CIDR to the <code>status</code> of the EgressClusterInfo CR.</p>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/#agent","title":"Agent","text":"<ul> <li>Processes EgressClusterInfo updates into an ipset named <code>egress-ingore-cidr</code> in the control loop for Policy;</li> <li>For EgressGatewayPolicy policies when the <code>destSubnet</code> field is empty, match traffic using the ipset named <code>egress-ingore-cidr</code>.</li> </ul>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/README_zh-CN/","title":"Egress ignore CIDR","text":""},{"location":"proposal/04-auto-detect-egress-ignore-cidr/README_zh-CN/#_1","title":"\u52a8\u673a","text":"<p>\u4e3a\u4e86\u7b80\u5316 Egress \u7b56\u7565\u7684\u914d\u7f6e\uff0c\u5f15\u5165 Egress Ignore CIDR \u529f\u80fd\uff0c\u5141\u8bb8\u4ee5\u624b\u52a8\u548c\u81ea\u52a8\u7684\u65b9\u5f0f\u83b7\u53d6\u96c6\u7fa4\u7684 CIDR\u3002\u5f53 EgressGatewayPolicy \u7684 <code>destSubnet</code> \u5b57\u6bb5\u4e3a\u7a7a\u65f6\uff0c\u6570\u636e\u9762\u5c06\u4f1a\u81ea\u52a8\u5339\u914d EgressClusterInfo CR \u4e2d\u7684 CIDR \u4e4b\u5916\u7684\u6d41\u91cf\uff0c\u5e76\u5c06\u5176\u8f6c\u53d1\u5230 Egress \u7f51\u5173\u3002</p>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/README_zh-CN/#_2","title":"\u76ee\u6807","text":"<ul> <li>\u4f18\u5316 EgressGatewayPolicy \u4f7f\u7528\u4f53\u9a8c</li> </ul>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/README_zh-CN/#_3","title":"\u8bbe\u8ba1","text":""},{"location":"proposal/04-auto-detect-egress-ignore-cidr/README_zh-CN/#egressclusterinfo-crd","title":"EgressClusterInfo CRD","text":"<p>\u96c6\u7fa4\u7ea7 CRD\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressClusterInfo\nmetadata:\nname: default  # 1\nspec:\nautoDetect:\nclusterIP: true # 2\nnodeIP: true # 3\npodCidrMode: auto # 4\nextraCidr: # 5\n- 10.10.10.1\nstatus:\nclusterIP: # 6\nipv4:\n- 172.41.0.0/16\nipv6:\n- fd41::/108\nextraCidr: # 7\n- 10.10.10.1\nnodeIP: # 8\negressgateway-control-plane:\nipv4:\n- 172.18.0.3\nipv6:\n- fc00:f853:ccd:e793::3\negressgateway-worker:\nipv4:\n- 172.18.0.2\nipv6:\n- fc00:f853:ccd:e793::2\negressgateway-worker2:\nipv4:\n- 172.18.0.4\nipv6:\n- fc00:f853:ccd:e793::4\npodCIDR: # 9\ndefault-ipv4-ippool:\nipv4:\n- 172.40.0.0/16\ndefault-ipv6-ippool:\nipv6:\n- fd40::/48\ntest-ippool:\nipv4:\n- 177.70.0.0/16\npodCidrMode: calico # 10\n</code></pre> <ol> <li>\u540d\u79f0\u4e3a <code>default</code>\uff0c\u7531\u7cfb\u7edf\u7ef4\u62a4\u53ea\u80fd\u521b\u5efa\u4e00\u4e2a;</li> <li><code>clusterIP</code>\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a <code>true</code>\uff0c<code>Service CIDR</code> \u4f1a\u81ea\u52a8\u68c0\u6d4b</li> <li><code>nodeIP</code>\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a <code>true</code>\uff0c\u4f1a\u81ea\u52a8\u68c0\u6d4b <code>nodeIP</code> \u76f8\u5173\u53d8\u5316\uff0c\u5e76\u52a8\u6001\u66f4\u65b0\u5230 <code>EgressClusterInfo</code> \u7684 <code>status.nodeIP</code> \u4e2d</li> <li><code>podCidrMode</code>\uff0c\u76ee\u524d\u652f\u6301 <code>k8s</code>\u3001 <code>calico</code>\u3001<code>auto</code>\u3001 <code>\"\"</code>\uff0c\u8868\u793a\u8981\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684 podCidr\uff0c\u9ed8\u8ba4\u4e3a <code>auto</code>\uff0c\u5982\u679c\u4e3a <code>auto</code> \u8868\u793a\u81ea\u52a8\u68c0\u6d4b\u96c6\u7fa4\u4f7f\u7528\u7684 cni\uff0c \u5982\u679c\u68c0\u6d4b\u4e0d\u5230\uff0c\u5219\u4f7f\u7528 \u96c6\u7fa4\u7684 podCidr\u3002\u5982\u679c\u4e3a <code>\"\"</code> \u8868\u793a\u4e0d\u68c0\u6d4b</li> <li><code>extraCidr</code>\uff0c\u53ef\u624b\u52a8\u586b\u5199\u8981\u5ffd\u7565\u6389\u7684 <code>IP</code> \u96c6\u5408</li> <li><code>status.clusterIP</code>\uff0c\u5982\u679c <code>spec.autoDetect.clusterIP</code> \u4e3a <code>true</code>\uff0c\u5219\u81ea\u52a8\u68c0\u6d4b\u96c6\u7fa4 <code>Service CIDR</code>\uff0c\u5e76\u66f4\u65b0\u5230\u6b64\u5904</li> <li><code>status.extraCidr</code>\uff0c\u5bf9\u5e94 <code>spec.extraCidr</code> </li> <li><code>status.nodeIP</code>\uff0c\u5982\u679c <code>spec.autoDetect.nodeIP</code> \u4e3a <code>true</code>\uff0c\u5219\u81ea\u52a8\u68c0\u6d4b\u96c6\u7fa4 <code>nodeIP</code>\uff0c\u5e76\u66f4\u65b0\u5230\u6b64\u5904</li> <li><code>status.podCIDR</code>\uff0c\u5bf9\u5e94 <code>spec.autoDetect.podCidrMode</code>\uff0c\u8fdb\u884c\u76f8\u5173 <code>podCidr</code> \u7684\u66f4\u65b0</li> <li><code>status.podCidrMode</code>\uff0c\u5bf9\u5e94 <code>spec.autoDetect.podCidrMode</code> \u4e3a <code>auto</code> \u7684\u573a\u666f</li> </ol>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/README_zh-CN/#_4","title":"\u6570\u636e\u9762\u7b56\u7565","text":""},{"location":"proposal/04-auto-detect-egress-ignore-cidr/README_zh-CN/#ipset","title":"ipset","text":"<p>\u6570\u636e\u9762\u5728\u5904\u7406 <code>destSubnet</code> \u4e3a\u7a7a\u7684\u7684 EgressGatewayPolicy \u65f6\uff0c\u5c06 iptables \u5339\u914d\u7b56\u7565\u6539\u4e3a <code>--match-set !egress-ingore-cidr dst</code>\u3002</p> <pre><code>iptables -A EGRESSGATEWAY-MARK-REQUEST -t mangle -m conntrack --ctdir ORIGINAL \\\n-m set --match-set !egress-ingore-cidr dst  \\\n-m set --match-set $IPSET_RULE_SRC_NAME src  \\\n-j MARK --set-mark $NODE_MARK -m comment --comment \"rule uuid: mark request packet\"\n</code></pre>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/README_zh-CN/#_5","title":"\u4ee3\u7801\u8bbe\u8ba1","text":""},{"location":"proposal/04-auto-detect-egress-ignore-cidr/README_zh-CN/#controller","title":"Controller","text":"<p>\u65b0\u589e\u4e00\u4e2a\u63a7\u5236\u5faa\u73af\uff0c\u6839\u636e <code>spec.autoDetect</code> \u914d\u7f6e\u6765 Watch \u96c6\u7fa4\u7684\u76f8\u5173\u8d44\u6e90\uff0c\u66f4\u65b0\u81ea\u52a8\u68c0\u6d4b\u7684 CIDR \u5230 EgressClusterInfo CR \u7684 <code>status</code> \u4e2d\u3002</p>"},{"location":"proposal/04-auto-detect-egress-ignore-cidr/README_zh-CN/#agent","title":"Agent","text":"<ul> <li>\u5728 Policy \u7684\u63a7\u5236\u5faa\u73af\u4e2d\uff0c\u5904\u7406 EgressClusterInfo \u66f4\u65b0\u5230\u540d\u4e3a <code>egress-ingore-cidr</code> \u7684 ipset \u4e2d\uff1b</li> <li>\u5bf9\u4e8e <code>destSubnet</code> \u5b57\u6bb5\u4e3a\u7a7a\u65f6\u7684 EgressGatewayPolicy \u7b56\u7565\uff0c\u4f7f\u7528 <code>egress-ingore-cidr</code> \u7684 ipset \u5339\u914d\u6d41\u91cf\u3002</li> </ul>"},{"location":"proposal/05-egress-gateway-policy-cluster/","title":"EgressGatewayPolicyCluster","text":""},{"location":"proposal/05-egress-gateway-policy-cluster/#motivation","title":"Motivation","text":"<p>Complementing the lack of cluster-level policy</p>"},{"location":"proposal/05-egress-gateway-policy-cluster/#goal","title":"Goal","text":"<ul> <li>Support cluster-level policy</li> <li>Support for prioritization</li> </ul>"},{"location":"proposal/05-egress-gateway-policy-cluster/#design","title":"Design","text":"<ul> <li>Cluster-level policy with additional <code>namespaceSelector</code> field. When empty, it applies to the entire cluster. If it is not empty, it applies to the eligible NSs.</li> <li>Due to the new cluster-level policy, when two policies, <code>appliedTo</code> and <code>destSubnet</code>, at the cluster level and namespace level are consistent, but <code>egressGatewayName</code> or <code>egressIP</code> are inconsistent, there will be a problem of which one of the two policies will take effect in the end. So a new field for priority, <code>priority</code>, was introduced to solve this problem. The range is 1-65536, the smaller the value, the higher the priority. Users can set the priority themselves. If not set, the default priority of EgressGatewayPolicy is 1000, and the default priority of EgressGatewayPolicyCluster is 32768. If the priority is the same, it will be randomized.</li> </ul>"},{"location":"proposal/05-egress-gateway-policy-cluster/#egresspolicy-crd","title":"EgressPolicy CRD","text":"<pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nnamespace: \"default\"\nname: \"policy-test\"\nspec:\npriority: 100             # 1\negressGatewayName: \"eg1\"\negressIP:\nipv4: \"\"                            ipv6: \"\"\nuseNodeIP: false\nappliedTo:\npodSelector:\nmatchLabels:    app: \"shopping\"\npodSubnet:\n- \"172.29.16.0/24\"\n- 'fd00:1/126'\ndestSubnet:\n- \"10.6.1.92/32\"\n- \"fd00::92/128\"\n</code></pre> <ol> <li>New field, prioritization of policies</li> </ol>"},{"location":"proposal/05-egress-gateway-policy-cluster/#egressclusterpolicy-crd","title":"EgressClusterPolicy CRD","text":"<pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressClusterPolicy\nmetadata:\nnamespace: \"default\"\nname: \"policy-test\"\nspec:\npriority: 100             # 1\negressGatewayName: \"eg1\"\negressIP:\nipv4: \"\"                            ipv6: \"\"\nuseNodeIP: false\nappliedTo:\npodSelector:\nmatchLabels:    app: \"shopping\"\npodSubnet:\n- \"172.29.16.0/24\"\n- 'fd00:1/126'\nnamespaceSelector:      # 1\nmatchLabels:    app: \"shopping\"\ndestSubnet:\n- \"10.6.1.92/32\"\n- \"fd00::92/128\"\n</code></pre> <ol> <li>strategy prioritization</li> <li>namespace filters</li> </ol> <p>Otherwise, both are consistent</p>"},{"location":"proposal/05-egress-gateway-policy-cluster/README_zh-CN/","title":"EgressGatewayPolicyCluster","text":""},{"location":"proposal/05-egress-gateway-policy-cluster/README_zh-CN/#_1","title":"\u52a8\u673a","text":"<p>\u8865\u5145\u6ca1\u6709\u96c6\u7fa4\u7ea7\u522b policy \u7684\u529f\u80fd</p>"},{"location":"proposal/05-egress-gateway-policy-cluster/README_zh-CN/#_2","title":"\u76ee\u6807","text":"<ul> <li>\u652f\u6301\u96c6\u7fa4\u7ea7\u522b\u7684 policy</li> <li>\u652f\u6301\u4f18\u5148\u7ea7</li> </ul>"},{"location":"proposal/05-egress-gateway-policy-cluster/README_zh-CN/#_3","title":"\u8bbe\u8ba1","text":"<ul> <li>\u96c6\u7fa4\u7ea7\u522b\u7684 policy\uff0c\u591a\u4e86 <code>namespaceSelector</code> \u5b57\u6bb5\u3002\u4e3a\u7a7a\u65f6\uff0c\u5219\u4f5c\u7528\u4e8e\u6574\u4e2a\u96c6\u7fa4\u3002\u4e0d\u4e3a\u7a7a\u65f6\uff0c\u5219\u4f5c\u7528\u4e8e\u7b26\u5408\u6761\u4ef6\u7684 NS\u3002</li> <li>\u7531\u4e8e\u65b0\u589e\u4e86\u96c6\u7fa4\u7ea7\u522b\u7684 policy\uff0c\u5f53\u96c6\u7fa4\u7ea7\u522b\u4e0e namespace \u7ea7\u522b\u7684\u4e24\u4e2a policy\uff0c <code>appliedTo</code>\u3001<code>destSubnet</code> \u4e00\u81f4\uff0c\u4f46 <code>egressGatewayName</code>  \u6216<code>egressIP</code> \u4e0d\u4e00\u81f4\u65f6\uff0c\u4e24\u4e2a\u7b56\u7565\u8c01\u6700\u7ec8\u751f\u6548\u5c31\u5c06\u6210\u4e3a\u4e00\u4e2a\u95ee\u9898\u3002\u6240\u4ee5\u5f15\u5165\u4e00\u4e2a\u4f18\u5148\u7ea7\u7684\u65b0\u5b57\u6bb5 <code>priority</code> \u6765\u89e3\u51b3\u8be5\u95ee\u9898\u3002\u8303\u56f4\u4e3a 1-65536\uff0c\u6570\u503c\u8d8a\u5c0f\uff0c\u4f18\u5148\u7ea7\u8d8a\u9ad8\u3002\u7528\u6237\u53ef\u4ee5\u81ea\u884c\u8bbe\u7f6e\u4f18\u5148\u7ea7\u3002\u5982\u679c\u6ca1\u8bbe\u7f6e\u65f6\uff0cEgressGatewayPolicy \u9ed8\u8ba4\u4f18\u5148\u7ea7\u4e3a 1000\uff0cEgressGatewayPolicyCluster \u9ed8\u8ba4\u4f18\u5148\u7ea7\u4e3a 32768.\u5982\u679c\u4f18\u5148\u7ea7\u4e00\u81f4\u65f6\uff0c\u5219\u968f\u673a\u6392\u5e8f\u3002</li> </ul>"},{"location":"proposal/05-egress-gateway-policy-cluster/README_zh-CN/#egresspolicy-crd","title":"EgressPolicy CRD","text":"<pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nnamespace: \"default\"\nname: \"policy-test\"\nspec:\npriority: 100             # 1\negressGatewayName: \"eg1\"\negressIP:\nipv4: \"\"                            ipv6: \"\"\nuseNodeIP: false\nappliedTo:\npodSelector:\nmatchLabels:    app: \"shopping\"\npodSubnet:\n- \"172.29.16.0/24\"\n- 'fd00:1/126'\ndestSubnet:\n- \"10.6.1.92/32\"\n- \"fd00::92/128\"\n</code></pre> <ol> <li>\u65b0\u589e\u5b57\u6bb5\uff0c\u7b56\u7565\u7684\u4f18\u5148\u7ea7</li> </ol>"},{"location":"proposal/05-egress-gateway-policy-cluster/README_zh-CN/#egressclusterpolicy-crd","title":"EgressClusterPolicy CRD","text":"<pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressClusterPolicy\nmetadata:\nnamespace: \"default\"\nname: \"policy-test\"\nspec:\npriority: 100             # 1\negressGatewayName: \"eg1\"\negressIP:\nipv4: \"\"                            ipv6: \"\"\nuseNodeIP: false\nappliedTo:\npodSelector:\nmatchLabels:    app: \"shopping\"\npodSubnet:\n- \"172.29.16.0/24\"\n- 'fd00:1/126'\nnamespaceSelector:      # 1\nmatchLabels:    app: \"shopping\"\ndestSubnet:\n- \"10.6.1.92/32\"\n- \"fd00::92/128\"\n</code></pre> <ol> <li>\u7b56\u7565\u7684\u4f18\u5148\u7ea7</li> <li>namespace \u7b5b\u9009\u5668</li> </ol> <p>\u5176\u4ed6\u65b9\u9762\uff0c\u4e24\u8005\u4e00\u81f4</p>"},{"location":"proposal/06-underlay-cni-supports/","title":"Underlay CNI supports","text":""},{"location":"proposal/06-underlay-cni-supports/#motivation","title":"Motivation","text":"<p>EgressGateway is not available in an Underlay CNI environment.</p>"},{"location":"proposal/06-underlay-cni-supports/#target","title":"Target","text":"<p>EgressGateway supports nanotube traffic in an Underlay CNI environment.</p>"},{"location":"proposal/06-underlay-cni-supports/#problems-to-be-solved","title":"Problems to be solved","text":"<p>As shown in the diagram, the datapath for the round-trip Underlay access to the external Server is: \"Process &lt;-&gt; A &lt;-&gt; B &lt;-&gt; Server\".</p> <p></p> <p>The EgressGateway's rules don't work at all, and in order to pipe the Underlay traffic, two things need to be addressed, hijacking the traffic to the Pod's host and avoiding routing asymmetric messages from being dropped when the answering traffic arrives at the Pod's host</p>"},{"location":"proposal/06-underlay-cni-supports/#hijack-a-pod-message-that-matches-the-egressgateway-policy-to-the-host-on-which-it-resides","title":"Hijack a Pod message that matches the EgressGateway policy to the host on which it resides","text":"<p>There are two things you need to do to solve this problem: 1, open the channel between the Pod and the host. 2, so that messages matching the policy are forwarded to the host through the channel.</p> <p>First, overlay + underlay can be realized with the help of the overlay NIC. For a single underlay, when the Pod is created, use a veth pair with one end on the host and the other end plugged into the Pod's network namespace. To accomplish the above, a kubelet call to CNI during pod creation can do it, a spiderpool plugin can just do it, or a privileged agent Pod can do it (the path is a bit wild).</p> <p>Thing 2, you can route, iptables, etc. to forward the matched traffic to the host via the veth pair in front of you. This can be done by setting spiderpool crd spidercoordinators.spec.hijackCIDR, and spiderpool will set the appropriate route. The rules can also be set via sidecar.</p>"},{"location":"proposal/06-underlay-cni-supports/#send-datapath","title":"Send datapath","text":"<p>As shown in the figure, by adding a new veth pair and routing the traffic through the veth to the host, the datapath is actually the same as the overlay.</p> <p></p>"},{"location":"proposal/06-underlay-cni-supports/#reply-datapath","title":"Reply datapath","text":"<p>As shown in the figure, the datapath returned is \"Server-&gt;D-&gt;C-&gt;B-&gt;E-&gt;Process\"</p> <p></p> <ul> <li>The srcIP=ServerIP, dstIP=EIP of the message as it passes through the D-segment datapath to the EgressGateway.</li> <li>The C datapath looks up the connection tracking table and NATs the message, srcIP=ServerIP, dstIP=PodIP.</li> <li>B segment datapath, because it is an underlay environment, so the EgressNode can communicate directly with the Pod, through the switch or router, the message goes directly to the Pod, you can see that at this time does not go through the host's network namespace. You can see that the message does not go through the host's network namespace at this time. This will lead to routing asymmetry problems</li> </ul>"},{"location":"proposal/06-underlay-cni-supports/#returned-message-routing-asymmetry-problem","title":"Returned message routing asymmetry problem","text":"<p>Here's a quick rundown of why the problem occurs:</p> <ul> <li>The first message of the three-way handshake, SYN, arrives at the host from the Pod, passes through the host's network stack, and is packetized and forwarded out.</li> <li>The second message of the three handshakes, SYN+ACK, arrives at the EgressNode node, then goes directly to the physical NIC of the node where the Pod is located, and then arrives directly at the Pod, without going through the host's network stack, resulting in inconsistent routing.</li> <li>The third message of the three handshakes, ACK, arrives at the host from the Pod, because it does not receive the SYN+ACK message, but directly receives the ACK message, which is considered to be an invalid packet, and thus is discarded by one of the kube-proxy's DROP rules, resulting in the failure of the three handshakes.</li> </ul> <pre><code>Chain KUBE-FORWARD (1 references)\npkts bytes target prot opt in out source destination\n    0 0 DROP all -- * * * 0.0.0.0/0 0.0.0.0/0 ctstate INVALID\n</code></pre> <p>To solve this problem, you need to ensure that the return packet also passes through the network namespace of the host where the Pod is located in order to avoid the above problem. Instead of returning the packet directly to the Pod, the packet can be tunneled back through the EgressGateway to the node where the Service Pod resides by setting up the appropriate rules on the egress gateway node. this can be accomplished as follows:</p> <pre><code>On the egress gateway node, new connections coming through the tunnel are marked as EgressGateway hits.\niptables -t mangle -A PREROUTING -i egress.vxlan -m conntrack --ctstate NEW -j MARK --set-mark 0x27\n\nAdd mark to the connection tracking table for recovery on packet return\niptables -t mangle -A PREROUTING -m mark --mark 0x27 -j CONNMARK --save-mark\n\nESTABLISHED connections, packets need to be recovered based on the contents of the connection tracking table Mark\niptables -t mangle -A PREROUTING -m conntrack --ctstate ESTABLISHED -j CONNMARK --restore-mark\n\nAdd routes to tunnel the packets back, one for each of them\nip rule add from all fwmark 0x27 lookup 600\nip r add &lt;Pod IP&gt; via &lt;Pod Node&gt; dev egress.vxlan t 600\nClear the mark of the inner packets to avoid interfering with the outer packets\niptables -t mangle -A POSTROUTING -m mark --mark 0x27 -j MARK --set-mark 0x00\n</code></pre> <p>As shown in the figure, after the above rule, the new answer datapath is \"Server-&gt;D-&gt;C-&gt;B-&gt;A-&gt;Process\"</p> <p></p> <p>The biggest difference is that from the gateway node to the node where the Pod is located, it is through the EgressGateway tunnel, and after the message arrives at the node where the Pod is located, it is forwarded to the Pod from the veth pair through the route, and the spiderpool will send out the corresponding route when it creates the veth pair for the Pod, or it can send out the corresponding route through the agent. The spiderpool will issue the corresponding route while creating the veth pair for the Pod, or it can issue the corresponding routing rules through the agent. Because it passes through the host's network stack. This avoids the routing asymmetry problem.</p>"},{"location":"proposal/06-underlay-cni-supports/#summary","title":"Summary","text":"<p>Except for the rules that need to be issued at the gateway node so that the answer message can be returned to the Pod through the EgressGateway, everything else that needs to be done can be accomplished with the help of the spiderpool configuration.</p>"},{"location":"proposal/06-underlay-cni-supports/README_zh-CN/","title":"underlay CNI supports","text":""},{"location":"proposal/06-underlay-cni-supports/README_zh-CN/#_1","title":"\u52a8\u673a","text":"<p>EgressGateway \u5728 Underlay CNI \u73af\u5883\u4e0b\u4e0d\u9002\u7528</p>"},{"location":"proposal/06-underlay-cni-supports/README_zh-CN/#_2","title":"\u76ee\u6807","text":"<p>EgressGateway \u652f\u6301\u7eb3\u7ba1 Underlay CNI \u73af\u5883\u4e0b\u7684\u6d41\u91cf</p>"},{"location":"proposal/06-underlay-cni-supports/README_zh-CN/#_3","title":"\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898","text":"<p>\u5982\u56fe\u6240\u793a\uff0cUnderlay \u8bbf\u95ee\u5916\u90e8 Server \u6765\u56de\u7684 datapath \u4e3a\uff1a\"Process &lt;-&gt; A &lt;-&gt; B &lt;-&gt; Server\"\u3002</p> <p></p> <p>EgressGateway \u7684\u89c4\u5219\u6839\u672c\u4e0d\u751f\u6548\uff0c\u8981\u60f3\u5c06 Underlay \u7684\u6d41\u91cf\u8fdb\u884c\u7eb3\u7ba1\uff0c\u5219\u9700\u8981\u89e3\u51b3\u4e24\u4ef6\u4e8b\uff0c\u5c06\u6d41\u91cf\u52ab\u6301\u5230 Pod \u7684\u6240\u5728\u7684\u4e3b\u673a\u4e0a\uff0c\u53ca\u5f53\u5e94\u7b54\u7684\u6d41\u91cf\u5230\u8fbe Pod \u6240\u5728\u4e3b\u673a\u65f6\uff0c\u907f\u514d\u8def\u7531\u4e0d\u5bf9\u79f0\u62a5\u6587\u88ab\u4e22\u5f03</p>"},{"location":"proposal/06-underlay-cni-supports/README_zh-CN/#egressgateway-policy-pod","title":"\u5c06\u5339\u914d EgressGateway  policy \u7684 Pod \u62a5\u6587\u52ab\u6301\u5230\u5b83\u6240\u5728\u7684\u4e3b\u673a\u4e0a","text":"<p>\u8981\u89e3\u51b3\u8be5\u95ee\u9898\u9700\u8981\u505a\u4e24\u4ef6\u4e8b\uff1a 1\u3001\u6253\u901a Pod \u4e0e\u4e3b\u673a\u4e4b\u95f4\u7684\u901a\u9053 2\u3001\u4f7f\u7b26\u5408 policy \u7684\u62a5\u6587\u901a\u8fc7\u901a\u9053\u8f6c\u53d1\u5230\u4e3b\u673a</p> <p>\u4e8b\u8bf7\u4e00\uff0coverlay + underlay \u65f6\u53ef\u4ee5\u501f\u52a9 overlay \u7684\u7f51\u5361\u5b9e\u73b0\u3002\u5355\u4e00\u7684 underlay \u5728 Pod \u521b\u5efa\u65f6\uff0c\u4f7f\u7528 veth pair \u4e00\u7aef\u5728\u4e3b\u673a\uff0c\u53e6\u4e00\u7aef\u63d2\u5728 Pod \u7f51\u7edc\u547d\u540d\u7a7a\u95f4\u5185\u3002\u8981\u5b8c\u6210\u4e0a\u8ff0\u4e8b\u60c5\uff0c\u5728 Pod \u521b\u5efa\u65f6 kubelet \u8c03\u7528 CNI \u53ef\u4ee5\u5b8c\u6210\uff0cspiderpool \u63d2\u4ef6\u521a\u597d\u53ef\u4ee5\u5b8c\u6210\uff0c\u6216\u8005\u662f\u7279\u6743 agent Pod \u6765\u5b8c\u6210\uff08\u8def\u5b50\u6709\u4e00\u70b9\u91ce\uff09\u3002</p> <p>\u4e8b\u60c5\u4e8c\uff0c\u53ef\u4ee5\u901a\u8fc7\u8def\u7531\u3001iptables \u7b49\u65b9\u5f0f\u5c06\u5339\u914d\u7684\u6d41\u91cf\u901a\u8fc7\u524d\u9762\u7684 veth pair \u8f6c\u53d1\u5230\u4e3b\u673a\u4e0a\u3002\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e spiderpool crd  spidercoordinators.spec.hijackCIDR \u6765\u5b8c\u6210\uff0cspiderpool \u4f1a\u8bbe\u7f6e\u76f8\u5e94\u7684\u8def\u7531\u3002\u4e5f\u53ef\u4ee5\u901a\u8fc7 sidecar \u8bbe\u7f6e\u76f8\u5e94\u7684\u89c4\u5219\u3002</p>"},{"location":"proposal/06-underlay-cni-supports/README_zh-CN/#datapath","title":"\u53d1\u9001 datapath","text":"<p>\u5982\u56fe\u6240\u793a\uff0c\u901a\u8fc7\u65b0\u589e veth pair\uff0c\u5e76\u901a\u8fc7\u8def\u7531\u5c06\u6d41\u91cf\u901a\u8fc7 veth \u8f6c\u53d1\u5230\u4e3b\u673a\u4e0a\uff0c\u6b64\u65f6\u7684 datapath \u4e0e overlay \u5176\u5b9e\u662f\u4e00\u6837\u7684\u3002</p> <p></p>"},{"location":"proposal/06-underlay-cni-supports/README_zh-CN/#datapath_1","title":"\u5e94\u7b54 datapath","text":"<p>\u5982\u56fe\u6240\u793a\uff0c\u8fd4\u56de\u7684 datapath \u4e3a \"Server-&gt;D-&gt;C-&gt;B-&gt;E-&gt;Process\"</p> <p></p> <ul> <li>\u62a5\u6587\u7ecf\u8fc7 D \u6bb5 datapath \u5230\u8fbe EgressGateway \u65f6\u7684 srcIP=ServerIP\u3001dstIP=EIP</li> <li>C \u6bb5 datapath \u4f1a\u67e5\u8be2\u8fde\u63a5\u8ddf\u8e2a\u8868\uff0c\u4f1a\u5c06\u62a5\u6587\u8fdb\u884c NAT\uff0csrcIP=ServerIP\u3001dstIP=PodIP</li> <li>B \u6bb5 datapath\uff0c\u56e0\u4e3a\u662f underlay \u73af\u5883\uff0c\u6240\u4ee5 EgressNode \u53ef\u4ee5\u76f4\u63a5\u4e0e Pod \u901a\u4fe1\uff0c\u7ecf\u8fc7\u4ea4\u6362\u673a\u6216\u8005\u8def\u7531\u5668\uff0c\u62a5\u6587\u76f4\u8fbe Pod\uff0c\u53ef\u4ee5\u770b\u5230\u6b64\u65f6\u5e76\u6ca1\u6709\u7ecf\u8fc7\u4e3b\u673a\u7684\u7f51\u7edc\u547d\u540d\u7a7a\u95f4\u3002\u8fd9\u6837\u5c31\u4f1a\u51fa\u73b0\u8def\u7531\u4e0d\u5bf9\u79f0\u95ee\u9898</li> </ul>"},{"location":"proposal/06-underlay-cni-supports/README_zh-CN/#_4","title":"\u8fd4\u56de\u7684\u62a5\u6587\u8def\u7531\u4e0d\u5bf9\u79f0\u95ee\u9898","text":"<p>\u5728\u8fd9\u91cc\u68b3\u7406\u4e00\u4e0b\u4e3a\u4ec0\u4e48\u4f1a\u51fa\u73b0\u8be5\u95ee\u9898\uff1a - \u4e09\u6b21\u63e1\u624b\u7684\u7b2c\u4e00\u4e2a\u62a5\u6587 SYN\uff0c\u4ece Pod \u5230\u8fbe\u4e3b\u673a\uff0c\u7ecf\u8fc7\u4e3b\u673a\u7684\u7f51\u7edc\u534f\u8bae\u6808\uff0c\u5c01\u5305\u540e\u8f6c\u53d1\u51fa\u53bb - \u4e09\u6b21\u63e1\u624b\u7684\u7b2c\u4e8c\u4e2a\u62a5\u6587 SYN+ACK\uff0c\u62a5\u6587\u5230\u8fbe EgressNode \u8282\u70b9\uff0c\u7136\u540e\u76f4\u63a5\u5230 Pod \u6240\u5728\u8282\u70b9\u7684\u7269\u7406\u7f51\u5361\uff0c\u518d\u76f4\u63a5\u5230\u8fbe Pod\uff0c\u6ca1\u6709\u7ecf\u8fc7\u4e3b\u673a\u7684\u7f51\u7edc\u534f\u8bae\u6808\uff0c\u5bfc\u81f4\u6765\u56de\u8def\u7531\u4e0d\u4e00\u81f4 - \u4e09\u6b21\u63e1\u624b\u7684\u7b2c\u4e09\u4e2a\u62a5\u6587 ACK\uff0c\u4ece Pod \u5230\u8fbe\u4e3b\u673a\uff0c\u56e0\u4e3a\u6ca1\u6709\u6536\u5230 SYN+ACK \u62a5\u6587\uff0c\u5c31\u76f4\u63a5\u6536\u5230 ACK \u62a5\u6587\uff0c\u6b64\u65f6\u4f1a\u8ba4\u4e3a ACK \u62a5\u6587\u662f\u65e0\u6548\u7684\u5305\uff0c\u4ece\u800c\u88ab kube-proxy \u7684\u4e00\u6761 DROP \u89c4\u5219\u547d\u4e2d\u4e22\u5f03\uff0c\u5bfc\u81f4\u4e09\u6b21\u63e1\u624b\u5931\u8d25 </p> <pre><code>Chain KUBE-FORWARD (1 references)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 DROP       all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate INVALID\n</code></pre> <p>\u8981\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u9700\u8981\u4fdd\u8bc1\u56de\u5305\u4e5f\u8981\u7ecf\u8fc7 Pod \u6240\u5728\u4e3b\u673a\u7684\u7f51\u7edc\u547d\u540d\u7a7a\u95f4\uff0c\u624d\u80fd\u907f\u514d\u4e0a\u8ff0\u95ee\u9898\u3002\u53ef\u4ee5\u5728\u51fa\u53e3\u7f51\u5173\u8282\u70b9\u4e0a\u901a\u8fc7\u8bbe\u7f6e\u76f8\u5e94\u7684\u89c4\u5219\uff0c\u5c06\u56de\u5305\u901a\u8fc7 EgressGateway \u7684\u96a7\u9053\u56de\u5230\u4e1a\u52a1 Pod \u6240\u5728\u8282\u70b9\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u8fd4\u56de\u7ed9 Pod\u3002\u5b9e\u73b0\u65b9\u5f0f\u5982\u4e0b\uff1a</p> <pre><code>\u6253\u4e0a\u51fa\u53e3\u7f51\u5173\u8282\u70b9\u4e0a\uff0c\u4ece\u96a7\u9053\u8fc7\u6765\u7684\u65b0\u8fde\u63a5\u6253 Mark\uff0c\u6807\u8bb0\u8fd9\u662f EgressGateway \u547d\u4e2d\u7684\u62a5\u6587\niptables -t mangle -A PREROUTING -i egress.vxlan  -m conntrack --ctstate NEW -j MARK --set-mark 0x27\n\n\u5c06 mark \u6dfb\u52a0\u5230\u8fde\u63a5\u8ddf\u8e2a\u8868\uff0c\u4ee5\u4fbf\u56de\u5305\u65f6\u8fdb\u884c\u6062\u590d\niptables -t mangle -A PREROUTING -m mark --mark 0x27 -j CONNMARK --save-mark\n\nESTABLISHED \u7684\u8fde\u63a5\uff0c\u62a5\u6587\u9700\u8981\u6839\u636e\u8fde\u63a5\u8ddf\u8e2a\u8868\u8bb0\u5f55\u7684\u5185\u5bb9\u8fdb\u884c\u6062\u590d Mark\niptables -t mangle -A PREROUTING  -m conntrack --ctstate ESTABLISHED -j CONNMARK --restore-mark\n\n\u6dfb\u52a0\u8def\u7531\u4f7f\u56de\u5305\u8d70\u96a7\u9053\uff0c\u6bcf\u4e2a\u90fd\u8981\u6dfb\u52a0\u4e00\u6761\u8def\u7531\nip rule add from all fwmark 0x27 lookup 600\nip r add &lt;Pod IP&gt; via &lt;Pod Node&gt; dev egress.vxlan t 600\n\n\u6e05\u9664\u5185\u5c42\u5305\u7684\u7684 Mark\uff0c\u907f\u514d\u5e72\u6270\u5916\u5c42\u7684\u62a5\u6587\niptables -t mangle -A  POSTROUTING -m mark --mark 0x27 -j MARK --set-mark 0x00\n</code></pre> <p>\u5982\u56fe\u6240\u793a\uff0c\u7ecf\u8fc7\u4e0a\u9762\u7684\u89c4\u5219\uff0c\u65b0\u7684\u5e94\u7b54 datapath \u4e3a \"Server-&gt;D-&gt;C-&gt;B-&gt;A-&gt;Process\"</p> <p></p> <p>\u6700\u5927\u7684\u4e0d\u540c\u5c31\u662f\uff0c\u4ece\u7f51\u5173\u8282\u70b9\u5230 Pod \u6240\u5728\u8282\u70b9\uff0c\u662f\u901a\u8fc7 EgressGateway \u96a7\u9053\uff0c\u62a5\u6587\u5230\u8fbe Pod \u6240\u5728\u8282\u70b9\u540e\uff0c\u901a\u8fc7\u8def\u7531\u6307\u5b9a\u4ece veth pair \u8f6c\u53d1\u7ed9 Pod\uff0cspiderpool \u5728\u524d\u9762\u7ed9 Pod \u521b\u5efa veth pair \u7684\u540c\u65f6\uff0c\u4f1a\u4e0b\u53d1\u5bf9\u5e94\u7684\u8def\u7531\uff0c\u6216\u8005\u53ef\u4ee5\u901a\u8fc7 agent \u4e0b\u53d1\u76f8\u5e94\u7684\u8def\u7531\u89c4\u5219\u3002\u56e0\u4e3a\u7ecf\u8fc7\u4e86\u4e3b\u673a\u7684\u7f51\u7edc\u534f\u8bae\u6808\u3002\u4ece\u800c\u89c4\u907f\u4e86\u8def\u7531\u4e0d\u5bf9\u79f0\u95ee\u9898</p>"},{"location":"proposal/06-underlay-cni-supports/README_zh-CN/#_5","title":"\u603b\u7ed3","text":"<p>\u9664\u4e86\u5728\u7f51\u5173\u8282\u70b9\u4e0a\u9700\u8981\u4e0b\u53d1\u89c4\u5219\uff0c\u4f7f\u5e94\u7b54\u62a5\u6587\u901a\u8fc7 EgressGateway \u8fd4\u56de\u5230 Pod \u6240\u5728\u8282\u70b9\u5916\uff0c\u5176\u4ed6\u9700\u8981\u5b8c\u6210\u7684\u4e8b\u60c5\uff0c\u901a\u8fc7\u914d\u7f6e spiderpool \u90fd\u53ef\u4ee5\u5e2e\u5fd9\u5b8c\u6210\u3002</p>"},{"location":"reference/EgressClusterEndpointSlice/","title":"CRD EgressClusterEndpointSlice","text":"<p>The EgressClusterEndpointSlice CRD is used to aggregate address information of Pods matched by EgressClusterPolicy. This resource is for internal use only, aiming to improve the performance of the control plane.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressClusterEndpointSlice\nmetadata:\ngenerateName: cluster-policy-\nlabels:\nspidernet.io/policy-name: cluster-policy          # (1)\nname: cluster-policy-zp667\nownerReferences:\n- apiVersion: egressgateway.spidernet.io/v1beta1  # (2)\nblockOwnerDeletion: true\ncontroller: true\nkind: EgressClusterPolicy\nname: cluster-policy\nuid: fdca1dd5-9c3b-4d58-b043-451e10f15ea8\nendpoints:                                             # (3)\n- ipv4:\n- 10.21.60.74                                    # (4)\nipv6:\n- fd00:21::5328:9c2:3579:8cca                    # (5)\nnode: workstation3                                 # (6)\nns: ns1                                            # (7)\npod: ns2-mock-app-5c4cd6bb87-g4fdj                 # (8)\n</code></pre> <ol> <li>This label value indicates the EgressClusterPolicy to which the EgressClusterEndpointSlice belongs.</li> <li>By using <code>ownerReferences</code>, the CRD is associated with its parent resource, enabling automatic recycling of EgressClusterEndpointSlice when the EgressClusterPolicy is deleted.</li> <li>The EgressClusterEndpointSlice object is used to summarize the address information of Pods matched by EgressClusterPolicy. By default, a new EgressClusterEndpointSlice is created when there are more than 100 matched results.</li> <li>The IPv4 address list of Pods.</li> <li>The IPv6 address list of Pods.</li> <li>Information about the node where the Pods are located.</li> <li>Information about the tenant to which the Pods belong.</li> <li>The names of the Pods.</li> </ol>"},{"location":"reference/EgressClusterInfo/","title":"CRD EgressClusterInfo","text":"<p>The EgressClusterInfo CRD introduces the Egress Ignore CIDR feature to simplify the configuration of Egress policies and allows automatic acquisition of the cluster's CIDR. When the <code>destSubnet</code> field of the EgressGatewayPolicy is empty, the data plane will automatically match traffic outside the CIDR in the EgressClusterStatus CR and forward it to the Egress gateway.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressClusterInfo\nmetadata:\nname: default  # (1)\nspec:\nautoDetect:\nclusterIP: true # (2)\nnodeIP: true # (3)\npodCidrMode: auto # (4)\nextraCidr: # (5)\n- 10.10.10.1\nstatus:\nclusterIP: # (6)\nipv4:\n- 172.41.0.0/16\nipv6:\n- fd41::/108\nextraCidr: # (7)\n- 10.10.10.1\nnodeIP: # (8)\negressgateway-control-plane:\nipv4:\n- 172.18.0.3\nipv6:\n- fc00:f853:ccd:e793::3\negressgateway-worker:\nipv4:\n- 172.18.0.2\nipv6:\n- fc00:f853:ccd:e793::2\negressgateway-worker2:\nipv4:\n- 172.18.0.4\nipv6:\n- fc00:f853:ccd:e793::4\npodCIDR: # (9)\ndefault-ipv4-ippool:\nipv4:\n- 172.40.0.0/16\ndefault-ipv6-ippool:\nipv6:\n- fd40::/48\ntest-ippool:\nipv4:\n- 177.70.0.0/16\npodCidrMode: calico # (10)\n</code></pre> <ol> <li>The name is <code>default</code>.Only one can be created by the system maintenance;</li> <li><code>clusterIP</code>. If it is set to <code>true</code>, <code>Service CIDR</code> will be detected automatically</li> <li><code>nodeIP</code>. If it is set to <code>true</code>, it will automatically detect changes related to <code>nodeIP</code> and dynamically update it to <code>status.nodeIP</code> of <code>EgressClusterInfo</code></li> <li><code>podCidrMode</code> currently supports <code>k8s</code>, <code>calico</code>, <code>auto</code>, and <code>\"\"</code>. It indicates whether to automatically detect the corresponding <code>podCidr</code> setting. The default value is <code>auto</code>. When set to <code>auto</code>, it means that the cluster's used CNI (Container Network Interface) will be automatically detected. If detection fails, the cluster's <code>podCidr</code> will be used. If set to <code>\"\"</code>, it signifies no detection.</li> <li><code>extraCidr</code>. You can manually fill in the <code>IP</code> set to be ignored</li> <li><code>status.clusterIP</code>. If <code>spec.autoDetect.clusterIP</code> is <code>true</code>, then automatically detect the cluster <code>Service CIDR</code>, and update</li> <li><code>status.extraCidr</code>, corresponding to <code>spec.extraCidr</code></li> <li><code>status.nodeIP</code>. If <code>spec.autoDetect.nodeIP</code> is <code>true</code>, then automatically detect cluster <code>nodeIP</code>, and update</li> <li><code>status.podCIDR</code>, corresponding to <code>spec.autoDetect.podCidrMode</code>, and then update related <code>podCidr</code></li> <li><code>status.podCidrMode</code> corresponding to <code>spec.autoDetect.podCidrMode</code> being set to <code>auto</code></li> </ol>"},{"location":"reference/EgressClusterPolicy/","title":"CRD EgressClusterPolicy","text":"<p>The EgressClusterPolicy CRD is used to define cluster-level Egress policy rules, similar to the EgressPolicy CRD, but with the added <code>spec.appliedTo.namespaceSelector</code> attribute.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressClusterPolicy\nmetadata:\nname: \"policy-test\"\nspec:\npriority: 100\negressGatewayName: \"eg1\"\negressIP:\nipv4: \"\"\nipv6: \"\"\nuseNodeIP: false\nappliedTo:\npodSelector:\nmatchLabels:\napp: \"shopping\"\npodSubnet:\n- \"172.29.16.0/24\"\n- 'fd00:1/126'\nnamespaceSelector:   # (1)\nmatchLabels:\napp: \"shopping\"\ndestSubnet:\n- \"10.6.1.92/32\"\n- \"fd00::92/128\"\n</code></pre>"},{"location":"reference/EgressClusterPolicy/#definition","title":"Definition","text":""},{"location":"reference/EgressClusterPolicy/#metadata","title":"Metadata","text":"Field Description Schema Validation namespace The namespace of the EgressPolicy resource string required name The name of the EgressPolicy resource string required"},{"location":"reference/EgressClusterPolicy/#spec","title":"Spec","text":"Field Description Schema Validation Values Default egressGatewayName Reference to the EgressGateway to use string required egressIP Configuration for the egress IP settings egressIP optional appliedTo Selector for the Pods to which the EgressPolicy should be applied appliedTo required destSubnet When accessing the subnets in this list, use the Egress IP. If <code>feature.clusterCIDR.autoDetect</code> was enabled during installation and <code>destSubnet</code> is not configured, then access to external networks outside the cluster will automatically use the Egress IP. []string optional CIDR notation priority Priority of the policy integer optional"},{"location":"reference/EgressClusterPolicy/#egressip","title":"egressIP","text":"Field Description Schema Validation Values Default ipv4 Specific IPv4 address to use if defined string optional valid IPv4 ipv6 Specific IPv6 address to use if defined string optional valid IPv6 useNodeIP Flag to indicate if the Node IP should be used as the Egress IP when no specific IP address is defined bool optional true/false false"},{"location":"reference/EgressClusterPolicy/#appliedto","title":"appliedTo","text":"Field Description Schema Validation Values Default podSelector Use Egress Policy on Pods Matched by Selector map[string]string optional podSubnet Use Egress Policy on Pods Matched by Subnet (Not Implemented) []string optional CIDR namespaceSelector The <code>namespaceSelector</code> uses a selector to select the list of matching namespaces. Within the selected namespace scope, use the <code>podSelector</code> to select the matching Pods, and then apply the Egress policy to these selected Pods."},{"location":"reference/EgressEndpointSlice/","title":"CRD EgressEndpointSlice","text":"<p>The EgressEndpointSlice CRD is used to aggregate address information of Pods matched by EgressPolicy. This resource is for internal use only, aiming to improve the performance of the control plane.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressEndpointSlice\nmetadata:\ngenerateName: ns-policy-\nlabels:\nspidernet.io/policy-name: ns-policy          # (1)\nname: ns-policy-zp667\nownerReferences:\n- apiVersion: egressgateway.spidernet.io/v1beta1  # (2)\nblockOwnerDeletion: true\ncontroller: true\nkind: EgressPolicy\nname: ns-policy\nuid: fdca1dd5-9c3b-4d58-b043-451e10f15ea8\nendpoints:                                             # (3)\n- ipv4:\n- 10.21.60.74                                    # (4)\nipv6:\n- fd00:21::5328:9c2:3579:8cca                    # (5)\nnode: workstation3                                 # (6)\nns: ns1                                            # (7)\npod: ns2-mock-app-5c4cd6bb87-g4fdj                 # (8)\n</code></pre> <ol> <li>This label value indicates the EgressPolicy to which the EgressEndpointSlice belongs.</li> <li>By using <code>ownerReferences</code>, the CRD is associated with its parent resource, enabling automatic recycling of EgressEndpointSlice when the EgressPolicy is deleted.</li> <li>The EgressEndpointSlice object is used to summarize the address information of Pods matched by EgressPolicy. By default, a new EgressEndpointSlice is created when there are more than 100 matched results.</li> <li>The IPv4 address list of Pods.</li> <li>The IPv6 address list of Pods.</li> <li>Information about the node where the Pods are located.</li> <li>Information about the tenant to which the Pods belong.</li> <li>The names of the Pods.</li> </ol>"},{"location":"reference/EgressGateway/","title":"CRD EgressGateway","text":"<p>The EgressGateway CRD is used to select a group of nodes as the Egress nodes of the cluster and configure the Egress IP pool for this group of nodes. The Egress IP can fall within this range. Cluster scope resource.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\nname: \"eg1\"\nspec:\nippools:                     ipv4:                       - \"10.6.1.55\"\n- \"10.6.1.60-10.6.1.65\"\n- \"10.6.1.70/28\"\nipv6:                      - \"\"\nipv4DefaultEIP: \"\"\nipv6DefaultEIP: \"\"\nnodeSelector:\nselector:\nmatchLabels:\negress: \"true\"\npolicy: \"doing\"\nstatus:\nnodeList:\n- name: \"node1\"\nstatus: \"Ready\"\nepis:\n- ipv4: \"10.6.1.55\"\nipv6: \"fd00::55\"\npolicies:\n- name: \"app\"\nnamespace: \"default\"\n</code></pre>"},{"location":"reference/EgressGateway/#definition","title":"Definition","text":""},{"location":"reference/EgressGateway/#metadata","title":"Metadata","text":"Field Description Schema Validation name The name of this EgressGateway resource string required"},{"location":"reference/EgressGateway/#spec","title":"Spec","text":"Field Description Schema Validation Values Default ippools Set the range of egress IP pool that EgressGateway can use ippools optional nodeSelector Match egress nodes by label nodeSelector require clusterDefault Default EgressGateway for the cluster bool optional true/false false"},{"location":"reference/EgressGateway/#ippools","title":"ippools","text":"Field Description Schema Validation Values Default ipv4 IPv4 pool []string optional <code>10.6.0.1</code> <code>10.6.0.1-10.6.0.10</code> <code>10.6.0.1/26</code> ipv6 IPv6 pool []string optional <code>fd::01</code> <code>fd01::01-fd01:0a</code> <code>fd10:01/64</code> ipv4DefaultEIP Default egress IPv4, if the EgressPolicy does not specify EIP and the EIP assignment policy is <code>default</code>, the EIP assigned to this EgressPolicy will be <code>ipv4DefaultEIP</code> string optional ipv6DefaultEIP Default egress IPv6, the rules are the same as <code>ipv6DefaultEIP</code> string optional"},{"location":"reference/EgressGateway/#nodeselector","title":"nodeSelector","text":"Field Description Schema Validation Values Default selector.matchLabels Node match labels map[string]string optional"},{"location":"reference/EgressGateway/#status-subresource","title":"Status (subresource)","text":"Field Description Schema Validation Values Default nodeList Match node list nodeList optional"},{"location":"reference/EgressGateway/#nodelist","title":"nodeList","text":"Field Description Schema Validation Values Default name Name of the node string optional status Current status of the node string optional <code>Ready</code>, <code>NotReady</code> epis List of endpoint IPs epis optional"},{"location":"reference/EgressGateway/#epis","title":"epis","text":"Field Description Schema Validation Values Default ipv4 If EgressPolicy and EgressClusterPolicy use node IP, this field is empty. string optional ipv6 In the dual-stack situation, IPv4 and IPv6 are one-to-one corresponding. string optional policies Policy list of the node policies optional"},{"location":"reference/EgressGateway/#policies","title":"policies","text":"Field Description Schema Validation Values Default name Name of the policy string optional namespace Namespace of the policy string optional"},{"location":"reference/EgressPolicy/","title":"CRD EgressPolicy","text":"<p>The EgressPolicy CRD is used to specify the Pods and its destination CIDRs for which an Egress strategy should be applied, along with the corresponding IP addresses to be used for Egress.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nnamespace: \"default\"\nname: \"policy-test\"\nspec:\negressGatewayName: \"eg1\" egressIP:\nipv4: \"\"                            ipv6: \"\"\nuseNodeIP: false       appliedTo:                podSelector:\nmatchLabels:\napp: \"shopping\"\npodSubnet:              - \"172.29.16.0/24\"\n- 'fd00:1/126'\ndestSubnet:\n- \"10.6.1.92/32\"\n- \"fd00::92/128\"\npriority: 100\n</code></pre>"},{"location":"reference/EgressPolicy/#definition","title":"Definition","text":""},{"location":"reference/EgressPolicy/#metadata","title":"Metadata","text":"Field Description Schema Validation namespace The namespace of the EgressPolicy resource string required name The name of the EgressPolicy resource string required"},{"location":"reference/EgressPolicy/#spec","title":"Spec","text":"Field Description Schema Validation Values Default egressGatewayName Reference to the EgressGateway to use string required egressIP Configuration for the egress IP settings egressIP optional appliedTo Selector for the Pods to which the EgressPolicy should be applied appliedTo required destSubnet When accessing the subnets in this list, use the Egress IP. If <code>feature.clusterCIDR.autoDetect</code> was enabled during installation and <code>destSubnet</code> is not configured, then access to external networks outside the cluster will automatically use the Egress IP. []string optional CIDR notation priority Priority of the policy integer optional"},{"location":"reference/EgressPolicy/#egressip","title":"egressIP","text":"Field Description Schema Validation Values Default ipv4 Specific IPv4 address to use if defined string optional valid IPv4 ipv6 Specific IPv6 address to use if defined string optional valid IPv6 useNodeIP Flag to indicate if the Node IP should be used as the Egress IP when no specific IP address is defined bool optional true/false false"},{"location":"reference/EgressPolicy/#appliedto","title":"appliedTo","text":"Field Description Schema Validation Values Default podSelector Use Egress Policy on Pods Matched by Selector map[string]string optional podSubnet Use Egress Policy on Pods Matched by Subnet (Not Implemented) []string optional CIDR"},{"location":"reference/EgressTunnel/","title":"CRD EgressTunnel","text":"<p>The EgressTunnel CRD is used to record tunnel network interface information for cross-node communication. It is a cluster scope resource that corresponds one-to-one with the Kubernetes Node resource name.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressTunnel\nmetadata:\nname: \"node1\"\nstatus:\ntunnel:\nipv4: \"192.200.222.157\"  # (1)\nipv6: \"fd01::f2\"         # (2)        \nmac: \"66:50:85:cb:b2:bf\" # (3)\nparent:\nname: \"ens160\"        # (4)\nipv4: \"10.6.1.21/16\"  # (5)\nipv6: \"fd00::21/112\"  # (6)\nphase: \"Ready\"              # (7)\nmark: \"0x26000000\"          # (8)\n</code></pre> <ol> <li>Tunnel IPv4 address</li> <li>Tunnel IPv6 address</li> <li>Tunnel MAC address</li> <li>Tunnel parent network interface</li> <li>Tunnel parent network interface IPv4 address</li> <li>Tunnel parent network interface IPv6 address</li> <li>Current tunnel status<ul> <li><code>Pending</code>: wait for IP allocation</li> <li><code>Init</code>: successful tunnel IP allocation</li> <li><code>Ready</code>: the tunnel IP is allocated and tunnel is established</li> <li><code>Failed</code>: tunnel IP allocation fails</li> <li><code>HeartbeatTimeout</code> heartbeat Timeout for Agent</li> <li><code>NodeNotReady</code> Node Status is NotReady</li> </ul> </li> <li>Packet mark value, one for each node. For example, if node A has egress traffic that needs to be forwarded to gateway node B, the traffic of node A will be marked with a mark.Each node is assigned a unique packet mark value. For instance, if Node A needs to forward Egress traffic to the gateway node B, it applies a specific mark to the packets originating from Node A.</li> </ol>"},{"location":"reference/_example_zh/","title":"CRD","text":""},{"location":"reference/_example_zh/#_1","title":"\u57fa\u672c\u63cf\u8ff0","text":"<p>\u672cCRD \u662f\u505a\u4ec0\u4e48\u7684</p>"},{"location":"reference/_example_zh/#_2","title":"\u914d\u7f6e\u8bf4\u660e","text":"<p>\u8868\u683c\uff08\u5b57\u6bb5\u3001\u63cf\u8ff0\u3001\u7f3a\u7701\u503c\uff09\uff0c\u5305\u62ec\u4e86 status \u7684\u4fe1\u606f\u8bf4\u660e</p>"},{"location":"reference/_example_zh/#_3","title":"\u4f7f\u7528\u4f8b\u5b50","text":"<p>\u7ed9\u51fa\u4e00\u4e9b\u573a\u666f\u573a\u666f\u4e0b\u7684 CR yaml</p>"},{"location":"reference/egctl/","title":"egctl cli reference","text":"<p><code>egctl</code> is a command line tool for managing EgressGateway related resources.</p>"},{"location":"reference/egctl/#command-overview","title":"Command Overview","text":""},{"location":"reference/egctl/#vip-move","title":"vip move","text":"<p>Move a VIP to a specified node.</p> <ul> <li><code>--egressGatewayName</code>: Specifies the name of the EgressGateway.</li> <li><code>--vip</code>: The Egress IP address you want to move.</li> <li><code>--targetNode</code>: The name of the target EgressGateway Node where the Egress IP will take effect.</li> </ul> <pre><code>egctl vip move --egressGatewayName &lt;egress-gateway-name&gt; --vip &lt;vip-address&gt; --targetNode &lt;node-name&gt;\n</code></pre>"},{"location":"reference/metrics/","title":"metrics","text":"<p>This chapter comprehensively introduces all the metrics exported by EgressGateway, and explains the meaning of each metric based on the metric type and description.</p>"},{"location":"reference/metrics/#controller-metrics","title":"Controller metrics","text":"Name Type Description <code>certwatcher_read_certificate_errors_total</code> counter Total number of certificate read errors. <code>certwatcher_read_certificate_total</code> counter Total number of certificate reads. <code>controller_runtime_active_workers</code> gauge Number of currently used workers per controller. <code>controller_runtime_max_concurrent_reconciles</code> gauge Maximum number of concurrent reconciles per controller. <code>controller_runtime_reconcile_errors_total</code> counter Total number of reconciliation errors per controller. <code>controller_runtime_reconcile_time_seconds</code> histogram Length of time per reconciliation per controller. <code>controller_runtime_reconcile_total</code> counter Total number of reconciliations per controller. <code>controller_runtime_webhook_latency_seconds</code> histogram Histogram of the latency of processing admission requests. <code>controller_runtime_webhook_requests_in_flight</code> gauge Current number of admission requests being served. <code>controller_runtime_webhook_requests_total</code> counter Total number of admission requests by HTTP status code. <code>egress_ip_allocate_next_restore_calls</code> counter Total number of number of IP allocate next calls for restore operations. <code>egress_ip_allocate_release_calls</code> counter Total number of number of IP release calls. <code>egress_mark_allocate_next_calls</code> counter Total number of mark allocate next count calls. <code>egress_mark_release_calls</code> counter Total number of mark release calls. <code>go_gc_duration_seconds</code> summary A summary of the pause duration of garbage collection cycles. <code>go_goroutines</code> gauge Number of goroutines that currently exist. <code>go_info</code> gauge Information about the Go environment. <code>go_memstats_alloc_bytes</code> gauge Number of bytes allocated and still in use. <code>go_memstats_alloc_bytes_total</code> counter Total number of bytes allocated, even if freed. <code>go_memstats_buck_hash_sys_bytes</code> gauge Number of bytes used by the profiling bucket hash table. <code>go_memstats_frees_total</code> counter Total number of frees. <code>go_memstats_gc_sys_bytes</code> gauge Number of bytes used for garbage collection system metadata. <code>go_memstats_heap_alloc_bytes</code> gauge Number of heap bytes allocated and still in use. <code>go_memstats_heap_idle_bytes</code> gauge Number of heap bytes waiting to be used. <code>go_memstats_heap_inuse_bytes</code> gauge Number of heap bytes that are in use. <code>go_memstats_heap_objects</code> gauge Number of allocated objects. <code>go_memstats_heap_released_bytes</code> gauge Number of heap bytes released to OS. <code>go_memstats_heap_sys_bytes</code> gauge Number of heap bytes obtained from system. <code>go_memstats_last_gc_time_seconds</code> gauge Number of seconds since 1970 of last garbage collection. <code>go_memstats_lookups_total</code> counter Total number of pointer lookups. <code>go_memstats_mallocs_total</code> counter Total number of mallocs. <code>go_memstats_mcache_inuse_bytes</code> gauge Number of bytes in use by mcache structures. <code>go_memstats_mcache_sys_bytes</code> gauge Number of bytes used for mcache structures obtained from system. <code>go_memstats_mspan_inuse_bytes</code> gauge Number of bytes in use by mspan structures. <code>go_memstats_mspan_sys_bytes</code> gauge Number of bytes used for mspan structures obtained from system. <code>go_memstats_next_gc_bytes</code> gauge Number of heap bytes when next garbage collection will take place. <code>go_memstats_other_sys_bytes</code> gauge Number of bytes used for other system allocations. <code>go_memstats_stack_inuse_bytes</code> gauge Number of bytes in use by the stack allocator. <code>go_memstats_stack_sys_bytes</code> gauge Number of bytes obtained from system for stack allocator. <code>go_memstats_sys_bytes</code> gauge Number of bytes obtained from system. <code>go_threads</code> gauge Number of OS threads created. <code>leader_election_master_status</code> gauge Gauge of if the reporting system is master of the relevant lease, 0 indicates backup, 1 indicates master. <code>process_cpu_seconds_total</code> counter Total user and system CPU time spent in seconds. <code>process_max_fds</code> gauge Maximum number of open file descriptors. <code>process_open_fds</code> gauge Number of open file descriptors. <code>process_resident_memory_bytes</code> gauge Resident memory size in bytes. <code>process_start_time_seconds</code> gauge Start time of the process since unix epoch in seconds. <code>process_virtual_memory_bytes</code> gauge Virtual memory size in bytes. <code>process_virtual_memory_max_bytes</code> gauge Maximum amount of virtual memory available in bytes. <code>rest_client_requests_total</code> counter Number of HTTP requests, partitioned by status code, method, and host. <code>workqueue_adds_total</code> counter Total number of adds handled by workqueue. <code>workqueue_depth</code> gauge Current depth of workqueue. <code>workqueue_longest_running_processor_seconds</code> gauge How many seconds has the longest running processor for workqueue been running. <code>workqueue_queue_duration_seconds</code> histogram How long in seconds an item stays in workqueue before being requested. <code>workqueue_retries_total</code> counter Total number of retries handled by workqueue. <code>workqueue_unfinished_work_seconds</code> gauge How many seconds of work has been done that is in progress and hasn't been observed by work_duration. <code>workqueue_work_duration_seconds</code> histogram How long in seconds processing an item from workqueue takes."},{"location":"reference/metrics/#agent-metrics","title":"Agent metrics","text":"Name Type Description <code>certwatcher_read_certificate_errors_total</code> counter Total number of certificate read errors <code>certwatcher_read_certificate_total</code> counter Total number of certificate reads <code>controller_runtime_active_workers</code> gauge Number of currently used workers per controller <code>controller_runtime_max_concurrent_reconciles</code> gauge Maximum number of concurrent reconciles per controller <code>controller_runtime_reconcile_errors_total</code> counter Total number of reconciliation errors per controller <code>controller_runtime_reconcile_time_seconds</code> histogram Length of time per reconciliation per controller <code>controller_runtime_reconcile_total</code> counter Total number of reconciliations per controller <code>go_gc_duration_seconds</code> summary A summary of the pause duration of garbage collection cycles <code>go_goroutines</code> gauge Number of goroutines that currently exist <code>go_info</code> gauge Information about the Go environment <code>go_memstats_alloc_bytes</code> gauge Number of bytes allocated and still in use <code>go_memstats_alloc_bytes_total</code> counter Total number of bytes allocated, even if freed <code>go_memstats_buck_hash_sys_bytes</code> gauge Number of bytes used by the profiling bucket hash table <code>go_memstats_frees_total</code> counter Total number of frees <code>go_memstats_gc_sys_bytes</code> gauge Number of bytes used for garbage collection system metadata <code>go_memstats_heap_alloc_bytes</code> gauge Number of heap bytes allocated and still in use <code>go_memstats_heap_idle_bytes</code> gauge Number of heap bytes waiting to be used <code>go_memstats_heap_inuse_bytes</code> gauge Number of heap bytes that are in use <code>go_memstats_heap_objects</code> gauge Number of allocated objects <code>go_memstats_heap_released_bytes</code> gauge Number of heap bytes released to OS <code>go_memstats_heap_sys_bytes</code> gauge Number of heap bytes obtained from system <code>go_memstats_last_gc_time_seconds</code> gauge Number of seconds since 1970 of last garbage collection <code>go_memstats_lookups_total</code> counter Total number of pointer lookups <code>go_memstats_mallocs_total</code> counter Total number of mallocs <code>go_memstats_mcache_inuse_bytes</code> gauge Number of bytes in use by mcache structures <code>go_memstats_mcache_sys_bytes</code> gauge Number of bytes used for mcache structures obtained from system <code>go_memstats_mspan_inuse_bytes</code> gauge Number of bytes in use by mspan structures <code>go_memstats_mspan_sys_bytes</code> gauge Number of bytes used for mspan structures obtained from system <code>go_memstats_next_gc_bytes</code> gauge Number of heap bytes when next garbage collection will take place <code>go_memstats_other_sys_bytes</code> gauge Number of bytes used for other system allocations <code>go_memstats_stack_inuse_bytes</code> gauge Number of bytes in use by the stack allocator <code>go_memstats_stack_sys_bytes</code> gauge Number of bytes obtained from system for stack allocator <code>go_memstats_sys_bytes</code> gauge Number of bytes obtained from system <code>go_threads</code> gauge Number of OS threads created <code>iptables_chains</code> gauge Number of active iptables chains <code>iptables_lines_executed</code> counter Number of iptables rule updates executed <code>iptables_lock_acquire_secs</code> summary Time in seconds that it took to acquire the iptables lock(s) <code>iptables_lock_retries</code> counter Number of times the iptables lock was held by someone else and retries were needed <code>iptables_restore_calls</code> counter Number of iptables-restore calls <code>iptables_restore_errors</code> counter Number of iptables-restore errors <code>iptables_rules</code> gauge Number of active iptables rules <code>iptables_save_calls</code> counter Number of iptables-save calls <code>iptables_save_errors</code> counter Number of iptables-save errors <code>process_cpu_seconds_total</code> counter Total user and system CPU time spent in seconds <code>process_max_fds</code> gauge Maximum number of open file descriptors <code>process_open_fds</code> gauge Number of open file descriptors <code>process_resident_memory_bytes</code> gauge Resident memory size in bytes <code>process_start_time_seconds</code> gauge Start time of the process since unix epoch in seconds <code>process_virtual_memory_bytes</code> gauge Virtual memory size in bytes <code>process_virtual_memory_max_bytes</code> gauge Maximum amount of virtual memory available in bytes <code>rest_client_requests_total</code> counter Number of HTTP requests, partitioned by status code, method, and host <code>workqueue_adds_total</code> counter Total number of adds handled by workqueue <code>workqueue_depth</code> gauge Current depth of workqueue <code>workqueue_longest_running_processor_seconds</code> gauge How many seconds has the longest running processor for workqueue been running <code>workqueue_queue_duration_seconds</code> histogram How long in seconds an item stays in workqueue before being requested <code>workqueue_retries_total</code> counter Total number of retries handled by workqueue <code>workqueue_unfinished_work_seconds</code> gauge How many seconds of work has been done that is in progress and hasn't been observed by work_duration <code>workqueue_work_duration_seconds</code> histogram How long in seconds processing an item from workqueue takes"},{"location":"usage/Aliyun/","title":"Run EgressGateway on Aliyun Cloud","text":"<p>This article explains how to use the EgressGateway in Alibaba Cloud. In Alibaba Cloud, because IPs (including Elastic Public IPs) are bound to nodes individually, it's impossible to achieve the feature where an Egress IP can migrate between nodes. In the following, we use the node IP (not using a specified IP pool) as the Egress IP. When using a node IP as the Egress IP, if multiple nodes are selected as Egress gateways to achieve HA (High Availability), the Egress IP will switch to another node's IP if one node fails.</p> <p>Example use cases are as follows:</p> <ul> <li>In east-west traffic within a VPC network, there are clusters A and B. Cluster B requires the visitor's network IP to be on a whitelist. Therefore, an EgressGateway is deployed in cluster A so that all network traffic accessing cluster B uses the Egress IP. This IP's traffic will apply special policies in external applications.</li> <li>In a north-south VPC network traffic scenario, cluster nodes need to access the internet, but business nodes do not purchase public IPs. Pods needing external network access can connect to the external network through the public IP bound to the Egress node within the cluster.</li> </ul>"},{"location":"usage/Aliyun/#requirements","title":"Requirements","text":"<ul> <li>At least 2 nodes in the Kubernetes cluster</li> <li>Calico network component installed</li> </ul>"},{"location":"usage/Aliyun/#installing-egressgateway","title":"Installing EgressGateway","text":"<p>Set Calico's iptables mode to Append before installation.</p> <p>If you installed Calico via YAML, you should execute the following command: <pre><code>kubectl set env daemonset -n calico-system calico-node FELIX_CHAININSERTMODE=Append\n</code></pre></p> <p>If you manage Calico through Calico Operator, you should execute the following command: <pre><code>kubectl patch felixconfigurations default --type='merge' -p '{\"spec\":{\"chainInsertMode\":\"Append\"}}'\n</code></pre></p> <p>Add the Helm repository.</p> <pre><code>helm repo add egressgateway https://spidernet-io.github.io/egressgateway/\nhelm repo update\n</code></pre> <p>Install EgressGateway using Helm.</p> <pre><code>helm install egress --wait --debug egressgateway/egressgateway\n</code></pre> <p>Check if all Pods are in the Running state.</p> <pre><code>root@node1:~# kubectl get pods -A | grep egressgateway\ndefault    egressgateway-agent-lkglz                  1/1     Running   0    86m\ndefault    egressgateway-agent-s5xwk                  1/1     Running   0    86m\ndefault    egressgateway-controller-6cd86df57-xm2d4   1/1     Running   0    86m\n</code></pre>"},{"location":"usage/Aliyun/#deploying-test-service","title":"Deploying Test Service","text":"<p>We have set up a new machine to act as an east-west server in the VPC network. The IP address of the machine I launched here is <code>172.17.81.29</code>.</p> <p></p> <p>Run the following command to start the test server. Its function is to handle <code>curl ip:8080</code>, which will return the client's IP address. This allows us to check if the Egress IP is functioning properly.</p> <pre><code>docker run -d --net=host ghcr.io/spidernet-io/egressgateway-nettools:latest /usr/bin/nettools-server -protocol web -webPort 8080\n</code></pre>"},{"location":"usage/Aliyun/#creating-a-test-pod","title":"Creating a Test Pod","text":"<p>Check the nodes of our current cluster.</p> <pre><code>$ kubectl get nodes\nNAME    STATUS   ROLES           AGE   VERSION\nnode1   Ready    control-plane   66m   v1.30.0\nnode2   Ready    &lt;none&gt;          66m   v1.30.0\n</code></pre> <p>In this setup, we will deploy the Pod to node1. Later, we will implement the capabilities of the EgressGateway, which will allow the Pod on node1 to route to node2, and use node2's IP to access the external network.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: nginx\nlabels:\napp: nginx\nspec:\ncontainers:\n- image: nginx\nimagePullPolicy: IfNotPresent\nname: nginx\nresources: {}\nnodeName: node1\n</code></pre> <p>Check if the Pod is in the Running state.</p> <pre><code>root@node1:~# kubectl get pods -o wide | grep nginx\nnginx  1/1  Running  0  77m  10.200.166.133  node1  &lt;none&gt;  &lt;none&gt;\n</code></pre>"},{"location":"usage/Aliyun/#creating-egressgateway-cr","title":"Creating EgressGateway CR","text":"<p>The purpose of the EgressGateway Custom Resource (CR) is to select a set of nodes within the cluster to serve as the Egress gateway. In the definition below, the <code>nodeSelector</code> will match node2 as the Egress gateway.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\n  name: \"egressgateway\"\nspec:\n  nodeSelector:\n    selector:\n      matchLabels:\n        egress: \"true\"\n</code></pre>"},{"location":"usage/Aliyun/#selecting-a-node-as-the-egress-exit","title":"Selecting a Node as the Egress Exit","text":"<p>Check the nodes of our current cluster. The Public IP of my node2 is <code>8.217.200.161</code>.</p> <pre><code>$ kubectl get nodes\nNAME    STATUS   ROLES           AGE   VERSION\nnode1   Ready    control-plane   66m   v1.30.0\nnode2   Ready    &lt;none&gt;          66m   v1.30.0\n</code></pre> <p>In this step, we will label node2 so that it is matched by our EgressGateway defined above.</p> <pre><code>kubectl label node node2 egress=true\n</code></pre> <p>After labeling the node with <code>kubectl label</code>, you can use the following command to retrieve the EgressGateway Custom Resource and check if the <code>status.nodeList</code> includes the node2 you just labeled.</p> <pre><code>$ kubectl get egw egressgateway -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\n  name: egressgateway\nspec:\n  nodeSelector:\n    selector:\n      matchLabels:\n        egress: \"true\"\nstatus:\n  nodeList:\n  - name: node2\n    status: Ready\n</code></pre>"},{"location":"usage/Aliyun/#creating-egresspolicy","title":"Creating EgressPolicy","text":"<p>The EgressPolicy Custom Resource (CR) is used to match Pods whose traffic will exit the cluster through the Egress gateway. In the definition of the EgressPolicy below, <code>34.117.186.192</code> is the address for <code>ipinfo.io</code>, which can be obtained by running <code>dig ipinfo.io</code>.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nname: nginx-egress-policy\nspec:\negressGatewayName: egressgateway\negressIP:\nuseNodeIP: true\nappliedTo:\npodSelector:\nmatchLabels:\napp: nginx\ndestSubnet:\n- 172.17.81.29/32   # # East-West Test Service IP\n- 34.117.186.192/32 # The IP address for ipinfo.io, used for testing north-south network traffic in clusters.\n</code></pre>"},{"location":"usage/Aliyun/#east-west-network-access-test","title":"East-West Network Access Test","text":"<p>At this point, we will use the <code>kubectl exec</code> command to enter the nginx Pod for testing.</p> <pre><code>$ curl 172.17.81.29:8080\nRemote IP: 172.17.81.28:59022\n</code></pre> <p>We see that the return result is the previously set IP <code>172.17.81.28</code>, and with this, the experiment using IP as Egress is concluded.</p>"},{"location":"usage/Aliyun/#testing-north-south-network-access","title":"Testing North-South Network Access","text":"<p>To test the Pod's access to north-south network services, we observed that the Pod on node1 used the public IP bound to node2 to complete internet access.</p> <pre><code>$ curl ipinfo.io\n{\n\"ip\": \"8.217.200.161\",\n  \"city\": \"Hong Kong\",\n  \"region\": \"Hong Kong\",\n  \"country\": \"HK\",\n  \"loc\": \"22.2783,114.1747\",\n  \"org\": \"AS45102 Alibaba (US) Technology Co., Ltd.\",\n  \"timezone\": \"Asia/Hong_Kong\",\n  \"readme\": \"https://ipinfo.io/missingauth\"\n}\n</code></pre>"},{"location":"usage/ClusterDefaultEgressGateway/","title":"Cluster Level Default EgressGateway","text":""},{"location":"usage/ClusterDefaultEgressGateway/#introduction","title":"Introduction","text":"<p>Setting a default EgressGateway for the entire cluster can simplify the process of using EgressPolicy under a namespace or using EgressClusterPolicy at the cluster level, as it eliminates the need to specify the EgressGateway name each time. Please note that only one default EgressGateway can be set for the cluster.</p>"},{"location":"usage/ClusterDefaultEgressGateway/#prerequisites","title":"Prerequisites","text":"<ul> <li>EgressGateway component is installed.</li> </ul>"},{"location":"usage/ClusterDefaultEgressGateway/#steps","title":"Steps","text":"<ol> <li> <p>When creating an EgressGateway, you can specify <code>spec.clusterDefault</code> as <code>true</code> to make it the default EgressGateway for the cluster. If <code>spec.egressGatewayName</code> is not specified in EgressClusterPolicy, and <code>spec.egressGatewayName</code> is not specified in EgressPolicy and the tenant has not configured a default EgressGateway, the cluster's default EgressGateway will be automatically used.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\nname: default\nspec:\nclusterDefault: true\nippools:\nipv4:\n- 10.6.1.55\n- 10.6.1.56\nipv4DefaultEIP: 10.6.1.55\nipv6:\n- fd00::55\n- fd00::56\nipv6DefaultEIP: fd00::56\nnodeSelector:\nselector:\nmatchLabels:\negress: \"true\"    </code></pre> </li> <li> <p>Use the following definition to create an EgressPolicy, ignoring the definition of the <code>spec.egressGatewayName</code> field:</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nname: mock-app\nspec:\nappliedTo:\npodSelector:\nmatchLabels:\napp: mock-app\ndestSubnet:\n- 10.6.1.92/32\n</code></pre> </li> <li> <p>Run the following command again to confirm that the EgressPolicy has been set to the default EgressGateway:</p> <pre><code>$ kubectl get egresspolicies mock-app -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\n  creationTimestamp: \"2023-08-09T11:54:34Z\"\ngeneration: 1\nname: mock-app\n  namespace: default\n  resourceVersion: \"6233341\"\nuid: 5692c5e6-a72b-41bd-a611-1106abd41bc2\nspec:\n  appliedTo:\n    podSelector:\n      matchLabels:\n        app: mock-app\n  destSubnet:\n  - 10.6.1.92/32\n  - fd00::92/128\n  - 172.30.40.0/21\n  egressGatewayName: default\n</code></pre> </li> </ol>"},{"location":"usage/EgressGatewayFailover/","title":"EgressGateway Failover","text":""},{"location":"usage/EgressGatewayFailover/#controller-failover","title":"Controller Failover","text":"<p>When the EgressGateway controller fails over, you can control the number of Controller replicas by specifying the <code>controller.replicas</code> parameter during installation. If one of the replicas in multiple Controller replicas fails, the system will automatically elect another replica as the primary controller to ensure service continuity.</p>"},{"location":"usage/EgressGatewayFailover/#datapath-failover","title":"Datapath Failover","text":"<p>When handling datapath failover, creating an <code>EgressGateway</code> can use <code>nodeSelector</code> to select a set of nodes as Egress Nodes. The Egress IP will be bound to one of these nodes. When a node fails or the Egress Agent on a node fails, the Egress IP will automatically move to another available node to ensure service continuity and reliability.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata: name: egw1\nspec:\nclusterDefault: true\nippools:\nipv4:\n- 10.6.1.55\n- 10.6.1.56 ipv4DefaultEIP: 10.6.1.56\nipv6:\n- fd00::55\n- fd00::56\nipv6DefaultEIP: fd00::55\nnodeSelector:\nselector:\nmatchLabels:\negress: \"true\"\nstatus:\nnodeList:\n- name: node1\nstatus: Ready\neips:\n- ipv4: 10.6.1.56\nipv6: fd00::55\npolicies:\n- name: policy1\nnamespace: default\n- name: node2\nstatus: Ready\n</code></pre> <p>In the above definition of EgressGateway, by setting <code>egress: \"true\"</code>, two nodes, node1 and node2, are designated as Egress Nodes. Node1 is the one selected as the active node, and its effective Egress IP can be viewed in the status. If node1 encounters a failure, then node2 will serve as the failover node.</p> <p></p> <p>The timeout for health checks and Egress IP failover can be tuned via Helm values configuration.</p> <ul> <li><code>feature.tunnelMonitorPeriod</code> The egress controller check tunnel last update status at an interval set in seconds, default <code>5</code>.</li> <li><code>feature.tunnelUpdatePeriod</code> The egress agent updates the tunnel status at an interval set in seconds, default <code>5</code>.</li> <li><code>feature.eipEvictionTimeout</code> If the last updated time of the egress tunnel exceeds this time, move the Egress IP of the node to an available node, the unit is seconds, default is <code>5</code>.</li> </ul> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressTunnel\nmetadata:\nname: workstation1\nspec: {}\nstatus:\nlastHeartbeatTime: \"2023-11-27T12:04:56Z\"\nmark: \"0x26d9b723\"\nphase: Ready\n</code></pre> <p>The EgressGateway Agent will periodically update the <code>status.lastHeartbeatTime</code> field at intervals set by <code>feature.tunnelUpdatePeriod</code>. The EgressGateway Controller, on the other hand, will periodically list all EgressTunnels using <code>feature.tunnelMonitorPeriod</code>, and check whether the sum of <code>status.lastHeartbeatTime</code> and <code>feature.eipEvictionTimeout</code> exceeds the current time.</p> <p></p> <p>Datapath Failover troubleshooting steps:</p> <ol> <li>First, check the installation configuration file <code>values.yaml</code> of the EgressGateway application to ensure failover related configurations are set reasonably, in particular ensuring <code>eipEvictionTimeout</code> is greater than the sum of <code>tunnelMonitorPeriod</code> and <code>tunnelUpdatePeriod</code>.</li> <li>Execute <code>kubectl get egt -w</code> to check the status of <code>EgressTunnel</code>. Check if the selected Node is in <code>HeartbeatTimeout</code> state, and if there are other <code>EgressTunnel</code> in <code>Ready</code> state.     <pre><code>kubectl get egt -w\nNAME    TUNNELMAC           TUNNELIPV4        TUNNELIPV6   MARK         PHASE\nnode1   66:50:85:cb:b2:bf   192.200.229.11    fd01::c486   0x26d9b723   Ready\nnode2   66:d4:65:85:e2:c7   192.200.128.75    fd01::6676   0x26abf380   HeartbeatTimeout\nnode3   66:c4:da:a7:58:25   192.200.101.153   fd01::edb5   0x26c4ce84   Ready\n</code></pre></li> <li>If you want to check if there has been an IP switch caused by HeartbeatTimeout, you can retrieve the logs related to <code>update tunnel status to HeartbeatTimeout</code> in the controller container.</li> </ol>"},{"location":"usage/Install/","title":"Install EgressGateway on a Self-managed Cluster","text":""},{"location":"usage/Install/#introduction","title":"Introduction","text":"<p>This page provides instructions for quickly installing EgressGateway on a self-managed Kubernetes cluster.</p>"},{"location":"usage/Install/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>A self-managed Kubernetes cluster with a minimum of 2 nodes.</p> </li> <li> <p>Helm has been installed in your cluster.</p> </li> <li> <p>EgressGateway currently supports the following CNI plugins:</p> </li> </ol> CalicoFlannelWeaveSpiderpool <p>If your cluster is using Calico  as the CNI plugin, run the following command to ensure that EgressGateway's iptables rules are not overridden by Calico rules. Failure to do so may cause EgressGateway to malfunction.</p> <pre><code># set chainInsertMode\n$ kubectl patch felixconfigurations  default --type='merge' -p '{\"spec\":{\"chainInsertMode\":\"Append\"}}'\n# check status\n$ kubectl get FelixConfiguration default -o yaml\n  apiVersion: crd.projectcalico.org/v1\n    kind: FelixConfiguration\n    metadata:\n      generation: 2\nname: default\n      resourceVersion: \"873\"\nuid: 0548a2a5-f771-455b-86f7-27e07fb8223d\n      spec:\n      chainInsertMode: Append\n      ......\n</code></pre> <p>Regarding <code>spec.chainInsertMode</code>, refer to Calico docs for details</p> <p>Flannel CNI does not require any configuration, so you can skip this step.</p> <p>Weave CNI does not require any configuration, so you can skip this step.</p> <p>If your cluster is using Spiderpool in conjunction with another CNI, follow these steps:</p> <p>Add the service addresses outside the cluster to the 'hijackCIDR' field in the 'default' object of spiderpool.spidercoordinators. This ensures that when Pods access these external services, the traffic is routed through the host where the Pod is located, allowing the EgressGateway rules to match.</p> <pre><code># For running Pods, you need to restart them for these routing rules to take effect within the Pods.\nkubectl patch spidercoordinators default  --type='merge' -p '{\"spec\": {\"hijackCIDR\": [\"1.1.1.1/32\", \"2.2.2.2/32\"]}}'\n</code></pre>"},{"location":"usage/Install/#install-egressgateway","title":"Install EgressGateway","text":""},{"location":"usage/Install/#add-egressgateway-repo","title":"Add EgressGateway Repo","text":"<pre><code>helm repo add egressgateway https://spidernet-io.github.io/egressgateway/\nhelm repo update\n</code></pre>"},{"location":"usage/Install/#install-egressgateway_1","title":"Install EgressGateway","text":"<ol> <li> <p>Quickly install EgressGateway through the following command:</p> <pre><code>helm install egressgateway egressgateway/egressgateway \\\n-n kube-system \\\n--set feature.tunnelIpv4Subnet=\"192.200.0.1/16\" \\\n--wait --debug\n</code></pre> <p>In the installation command, please consider the following points:</p> <ul> <li>Make sure to provide the IPv4 and IPv6 subnets for the EgressGateway tunnel nodes in the installation command. These subnets should not conflict with other addresses within the cluster.</li> <li>You can customize the network interface used for EgressGateway tunnels by using the <code>--set feature.tunnelDetectMethod=\"interface=eth0\"</code> option. By default, it uses the network interface associated with the default route.</li> <li>If you want to enable IPv6 support, set the <code>--set feature.enableIPv6=true</code> option and also <code>feature.tunnelIpv6Subnet</code>.</li> <li>The EgressGateway Controller supports high availability and can be configured using <code>--set controller.replicas=2</code>.</li> <li>To enable return routing rules on the gateway nodes, use <code>--set feature.enableGatewayReplyRoute=true</code>. This option is required when using Spiderpool to work with underlay CNI.</li> </ul> </li> <li> <p>Verify that all EgressGateway Pods are running properly.</p> <pre><code>$ kubectl get pod -n kube-system | grep egressgateway\negressgateway-agent-29lt5                  1/1     Running   0          9h\negressgateway-agent-94n8k                  1/1     Running   0          9h\negressgateway-agent-klkhf                  1/1     Running   0          9h\negressgateway-controller-5754f6658-7pn4z   1/1     Running   0          9h\n</code></pre> </li> <li> <p>Any feature configurations can be achieved by adjusting the Helm values of the EgressGateway application.</p> </li> </ol>"},{"location":"usage/Install/#create-egressgateway-instances","title":"Create EgressGateway Instances","text":"<ol> <li> <p>EgressGateway defines a group of nodes as the cluster's egress gateway, responsible for forwarding egress traffic out of the cluster. To define a group of EgressGateway, run the following command:</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\n  name: default\nspec:\n  ippools:\n    ipv4:\n    - \"172.22.0.100-172.22.0.110\"\n  nodeSelector:\n    selector:\n      matchLabels:\n        egressgateway: \"true\"\nEOF\n</code></pre> <p>Descriptions:</p> <ul> <li>In the provided YAML example, adjust <code>spec.ippools.ipv4</code> to define egress exit IP addresses based on your specific environment.</li> <li>Ensure that the CIDR of <code>spec.ippools.ipv4</code> matches the subnet of the egress interface on the gateway nodes (usually the interface associated with the default route). Mismatched subnets can cause connectivity issues for egress traffic.</li> <li>Use <code>spec.nodeSelector</code> in the EgressGateway to select a group of nodes as the egress gateway. You can select multiple nodes to achieve high availability.</li> </ul> </li> <li> <p>Label the egress gateway nodes by applying labels to them. For production environments, it is recommended to label at least 2 nodes. For POC environments, label 1 node.</p> <pre><code>kubectl get node\nkubectl label node $NodeName egressgateway=\"true\"\n</code></pre> </li> <li> <p>Check the status:</p> <pre><code>$ kubectl get EgressGateway default -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\n  name: default\n  uid: 7ce835e2-2075-4d26-ba63-eacd841aadfe\nspec:\n  ippools:\n    ipv4:\n    - 172.22.0.100-172.22.0.110\n    ipv4DefaultEIP: 172.22.0.110\n  nodeSelector:\n    selector:\n      matchLabels:\n        egressgateway: \"true\"\nstatus:\n  nodeList:\n  - name: egressgateway-worker1\n    status: Ready\n  - name: egressgateway-worker2\n    status: Ready\n</code></pre> <p>Descriptions:</p> <ul> <li>The <code>status.nodeList</code> field indicates the nodes that match the <code>spec.nodeSelector</code>, along with the status of their corresponding EgressTunnel objects.</li> <li>The <code>spec.ippools.ipv4DefaultEIP</code> field randomly selects one IP address from <code>spec.ippools.ipv4</code> as the default VIP for this group of EgressGateways. This default VIP is used when creating EgressPolicy objects for applications that do not specify a VIP address.</li> </ul> </li> </ol>"},{"location":"usage/Install/#create-applications-and-egress-policies","title":"Create Applications and Egress Policies","text":"<ol> <li> <p>Create an application that will be used to test Pod access to external resources and apply labels to it.</p> <pre><code>kubectl create deployment visitor --image nginx\n</code></pre> </li> <li> <p>Create an EgressPolicy CR object for your application.</p> <p>An EgressPolicy instance is used to define which Pods' egress traffic should be forwarded through EgressGateway nodes, along with other configuration details. You can create an example as follows. When a matching Pod accesses any external address in the cluster (excluding Node IP, CNI Pod CIDR, ClusterIP), it will be forwarded through EgressGateway nodes. Note that EgressPolicy objects are tenant-level, so they must be created under the tenant of the selected application.</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\n name: test\n namespace: default\nspec:\n egressGatewayName: default\n appliedTo:\n  podSelector:\n   matchLabels:\n    app: \"visitor\"\nEOF\n</code></pre> <p>Descriptions:</p> <ul> <li><code>spec.egressGatewayName</code> specifies the name of the EgressGateway group to use.</li> <li><code>spec.appliedTo.podSelector</code> determines which Pods within the cluster this policy should apply to.</li> <li>There are two options for the source IP address of egress traffic in the cluster:<ul> <li>You can use the IP address of the gateway nodes. This is suitable for public clouds and traditional networks but has the downside of potential IP changes if a gateway node fails. You can enable this by setting <code>spec.egressIP.useNodeIP=true</code>.</li> <li>You can use a dedicated VIP. EgressGateway uses ARP principles for VIP implementation, making it suitable for traditional networks rather than public clouds. The advantage is that the egress source IP remains fixed. If no settings are specified in the EgressPolicy, the default VIP of the egressGatewayName will be used, or you can manually specify <code>spec.egressIP.ipv4</code> , which must match the IP pool configured in the EgressGateway.</li> </ul> </li> </ul> </li> <li> <p>Check the status of the EgressPolicy</p> <pre><code>$ kubectl get EgressPolicy -A\nNAMESPACE   NAME   GATEWAY   IPV4           IPV6   EGRESSTUNNEL\ndefault     test   default   172.22.0.110          egressgateway-worker2\n\n$ kubectl get EgressPolicy test -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\n  name: test\nnamespace: default\nspec:\n  appliedTo:\n    podSelector:\n      matchLabels:\n        app: visitor\n  egressIP:\n    allocatorPolicy: default\n    useNodeIP: false\nstatus:\n  eip:\n    ipv4: 172.22.0.110\n  node: egressgateway-worker2\n</code></pre> <p>Descriptions:</p> <ul> <li><code>status.eip</code> displays the egress IP address used by the group of applications.</li> <li><code>status.node</code> shows which EgressGateway node is responsible for real-time egress traffic forwarding. EgressGateway nodes support high availability. When multiple EgressGateway nodes exist, all EgressPolicy instances will be evenly distributed among them.</li> </ul> </li> <li> <p>Check the status of EgressEndpointSlices.</p> <p>Each EgressPolicy object has a corresponding EgressEndpointSlices that stores the IP  collection of Pods selected by the EgressPolicy. If your application is unable to access external resources, you can check if the IP addresses in this object are correct.</p> <pre><code>$ kubectl get egressendpointslices -A\nNAMESPACE   NAME         AGE\ndefault     test-kvlp6   18s\n\n$ kubectl get egressendpointslices test-kvlp6 -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nendpoints:\n- ipv4:\n  - 172.40.14.195\n  node: egressgateway-worker\n  ns: default\n  pod: visitor-6764bb48cc-29vq9\nkind: EgressEndpointSlice\nmetadata:\n  name: test-kvlp6\n  namespace: default\n</code></pre> </li> </ol>"},{"location":"usage/Install/#test-results","title":"Test Results","text":"<ol> <li> <p>Deploy the nettools application outside the cluster to simulate an external service. nettools will return the requester's source IP address in the HTTP response.</p> <pre><code>docker run -d --net=host ghcr.io/spidernet-io/egressgateway-nettools:latest /usr/bin/nettools-server -protocol web -webPort 8080\n</code></pre> </li> <li> <p>Verify the effect of egress traffic in the visitor Pod within the cluster. You should observe that when the visitor accesses the external service, nettools returns a source IP matching the EgressPolicy <code>.status.eip</code>.     <pre><code>$ kubectl get pod\nNAME                       READY   STATUS    RESTARTS   AGE\nvisitor-6764bb48cc-29vq9   1/1     Running   0          15m\n\n$ kubectl exec -it visitor-6764bb48cc-29vq9 bash\n$ curl 10.6.1.92:8080\nRemote IP: 172.22.0.110\n</code></pre></p> </li> </ol>"},{"location":"usage/MoveIP/","title":"Migration of Egress IP Between Gateway Nodes","text":""},{"location":"usage/MoveIP/#use-cases","title":"Use Cases","text":"<ul> <li>With EgressGateway, we can select multiple Nodes as EgressNodes. When a Node requires maintenance, we can manually migrate the VIP of that Node to another Node using CLI commands.</li> <li>For other reasons, when it's necessary to manually move a Node's VIP to another Node.</li> </ul>"},{"location":"usage/MoveIP/#steps-for-use","title":"Steps for Use","text":"<p>We examine the definition of EgressGateway by executing <code>kubectl get egw egressgateway -o yaml</code>.</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\nfinalizers:\n- egressgateway.spidernet.io/egressgateway\nname: egressgateway\nspec:\nippools:\nipv4:\n- 10.6.91.1-10.6.93.125\nipv4DefaultEIP: 10.6.92.222\nnodeSelector:\nselector:\nmatchLabels:\negress: \"true\"\nstatus:\nipUsage:\nipv4Free: 37\nipv4Total: 637\nipv6Free: 0\nipv6Total: 0\nnodeList:\n- name: workstation2\nstatus: Ready\n- name: workstation3\nstatus: Ready\neips:\n- ipv4: 10.6.92.209\npolicies:\n- name: policy-1\nnamespace: default\n</code></pre> <p>Before the migration, the Egress IP was on the workstation2 node.</p> <pre><code>node@workstation:~$ kubectl get egp\nNAME       GATEWAY          IPV4          IPV6       EGRESS NODE\npolicy-1   egressgateway    10.6.92.209              workstation3\n</code></pre> <p>We migrate the Egress IP of <code>workstation3</code> to the <code>workstation2</code> Node by executing the command below.</p> <pre><code>kubectl exec -it egressgateway-controller-86c84f4858-b6dz4 bash\negctl vip move --egressGatewayName egressgateway --vip 10.6.92.209 --targetNode workstation2\nMoving VIP 10.6.92.209 to node workstation2...\nSuccessfully moved VIP 10.6.92.209 to node workstation2\n</code></pre> <p>After migration, the Egress IP node has been moved to the workstation2 node.</p> <pre><code>node@workstation:~$ kubectl get egress\nNAME       GATEWAY          IPV4          IPV6       EGRESS NODE\npolicy-1   egressgateway    10.6.92.209              workstation2\n</code></pre>"},{"location":"usage/NamespaceDefaultEgressGateway/","title":"Namespace Level Default EgressGateway","text":""},{"location":"usage/NamespaceDefaultEgressGateway/#introduction","title":"Introduction","text":"<p>Setting a default EgressGateway for a namespace simplifies the process of specifying the EgressGateway name when using EgressPolicy under the namespace. The priority of the namespace level default EgressGateway is higher than that of the cluster level. In other words, when a namespace level default gateway is specified, the tenant's default settings will be used first. Otherwise, the cluster's default settings will be used.</p>"},{"location":"usage/NamespaceDefaultEgressGateway/#prerequisites","title":"Prerequisites","text":"<ul> <li>EgressGateway component is installed.</li> <li>An EgressGateway CR has been created.</li> </ul>"},{"location":"usage/NamespaceDefaultEgressGateway/#steps","title":"Steps","text":"<ol> <li> <p>Use the following command to specify the default EgressGateway name for the tenant:</p> <pre><code>kubectl label ns default spidernet.io/egressgateway-default=egressgateway\n</code></pre> </li> <li> <p>Use the following definition to create an EgressPolicy, ignoring the definition of the <code>spec.egressGatewayName</code> field:</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nname: mock-app\nspec:\nappliedTo:\npodSelector:\nmatchLabels:\napp: mock-app\ndestSubnet:\n- 10.6.1.92/32\n</code></pre> </li> <li> <p>Run the following command again to confirm that the EgressPolicy has been set to the default EgressGateway:</p> <pre><code>$ kubectl get egresspolicies mock-app -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\n  creationTimestamp: \"2023-08-09T10:54:34Z\"\ngeneration: 1\nname: mock-app\n  namespace: default\n  resourceVersion: \"6233341\"\nuid: 5692c5e6-a71b-41bd-a611-1106abd41ba3\nspec:\n  appliedTo:\n    podSelector:\n      matchLabels:\n        app: mock-app\n  destSubnet:\n  - 10.6.1.92/32\n  - fd00::92/128\n  - 172.30.40.0/21\n  egressGatewayName: egressgateway\n</code></pre> </li> </ol>"},{"location":"usage/Uninstall/","title":"Uninstall","text":"<p>To ensure that the running applications are not affected before uninstalling EgressGateway, it is recommended to perform the following steps:</p> <ol> <li> <p>Check if the number of resources related to EgressGateway is 0. Run the following commands:</p> <pre><code>kubectl get egressclusterpolicies.egressgateway.spidernet.io -o name | wc -l\nkubectl get egresspolicies.egressgateway.spidernet.io -o name | wc -l\nkubectl get egressgateways.egressgateway.spidernet.io -o name | wc -l\n</code></pre> <p>These commands will output the number of EgressGateway-related EgressClusterPolicy, EgressPolicy, and EgressGateway resources. If the output result is 0, it means there are no resources associated with EgressGateway. If the output result is not 0, further processing is needed to ensure that the uninstall operation does not affect the ongoing business applications.</p> <p>If the output is not 0, you should continue with the following commands. Otherwise, skip to step 2.</p> <pre><code>kubectl get egressclusterpolicies.egressgateway.spidernet.io\nkubectl get egresspolicies.egressgateway.spidernet.io -o wide\nkubectl get egressgateways.egressgateway.spidernet.io\n</code></pre> <p>For example, if you find there are still resources of EgressPolicies not deleted, you should check the resource details:</p> <pre><code>kubectl get egresspolicies &lt;resource-name&gt; --namespace &lt;resource-namespace&gt; -o yaml\n</code></pre> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nname: ns-policy\nnamespace: default\nspec:\nappliedTo:\npodSelector:\nmatchLabels:\napp: mock-app\negressGatewayName: egressgateway\nstatus:\neip:\nipv4: 10.6.1.55\nipv6: fd00::55\nnode: workstation2\n</code></pre> <p>Ensure that deleting will not affect business applications by searching for <code>appliedTo.podSelector</code>, then execute the following command to delete:</p> <pre><code>kubectl delete egresspolicies &lt;resource-name&gt; --namespace &lt;resource-namespace&gt;\n</code></pre> </li> <li> <p>Query the EgressGateway installed in the current cluster. Run the following command:</p> <pre><code>helm ls -A | grep -i egress\n</code></pre> <p>This will output the name, namespace, version, and other information of the EgressGateway installed in the current cluster.</p> </li> <li> <p>Uninstall EgressGateway. If you are sure you want to uninstall EgressGateway, you can run the following command:</p> <pre><code>helm uninstall &lt;egressgateway-name&gt; --namespace &lt;egressgateway-namespace&gt;\n</code></pre> <p>Replace <code>&lt;egressgateway-name&gt;</code> with the name of the EgressGateway you want to uninstall, and replace <code>&lt;egressgateway-namespace&gt;</code> with the namespace where EgressGateway is located.</p> <p>It is worth noting that before uninstalling EgressGateway, it is recommended to back up related data and ensure that the uninstall operation does not affect the ongoing business applications.</p> </li> <li> <p>During the uninstallation process, sometimes the EgressTunnels CRD of EgressGateway may remain in a waiting state for deletion. If you encounter this situation, you can try using the following command to resolve the issue:</p> <pre><code>kubectl patch crd egresstunnels.egressgateway.spidernet.io -p '{\"metadata\":{\"finalizers\": []}}' --type=merge\n</code></pre> <p>This command removes the finalizer in the EgressGateway CRD, allowing Kubernetes to delete it. This issue is caused by the controller-manager, and we are monitoring the Kubernetes team's progress on fixing it.</p> </li> </ol>"},{"location":"usage/Upgrade/","title":"Upgrade","text":"<p>This document will guide you on how to use the <code>helm upgrade</code> command to upgrade EgressGateway.</p>"},{"location":"usage/Upgrade/#basic-command-format","title":"Basic Command Format","text":"<pre><code>helm upgrade [RELEASE] [CHART] [flags]\n</code></pre> <p>Here, <code>[RELEASE]</code> represents the application name set during installation, <code>[CHART]</code> refers to the chart, and <code>[flags]</code> can specify additional parameters. To learn more about the parameters for <code>helm upgrade</code>, please refer to the helm upgrade page.</p>"},{"location":"usage/Upgrade/#version-upgrade","title":"Version Upgrade","text":"<p>Follow these steps to perform a version upgrade:</p> <ol> <li> <p>Before upgrading, run the following command to update the local Chart to the latest version:</p> <pre><code>helm repo update\n</code></pre> </li> <li> <p>View the latest version:</p> <pre><code>helm search repo egressgateway\n</code></pre> </li> <li> <p>Execute the upgrade command:</p> <pre><code>helm upgrade \\\negress \\\negressgateway/egressgateway \\\n--reuse-values \\\n--version [version]\n</code></pre> </li> </ol> <p>Replace <code>[version]</code> with the version you want to update.</p>"},{"location":"usage/Upgrade/#configuration-upgrade","title":"Configuration upgrade","text":"<p>Follow these steps to perform a configuration upgrade:</p> <ol> <li> <p>To view the available values parameters, visit the values documentation.</p> </li> <li> <p>Update the configuration using the <code>--set</code> flags. The following example shows how to change the egress agent log level to debug level. By using the <code>--reuse-values</code> parameter, you can reuse the values from the previous release and merge any overrides from the command line.</p> <pre><code>helm upgrade \\\negress \\\negressgateway/egressgateway \\\n--set agent.debug.logLevel=debug \\\n--reuse-values\n</code></pre> </li> </ol>"},{"location":"usage/_feature_example_zh/","title":"\u67d0\u529f\u80fd","text":""},{"location":"usage/_feature_example_zh/#_2","title":"\u4ecb\u7ecd","text":"<p>\u672c\u6587\u4e3a\u4e86\u6f14\u793a\u4ec0\u4e48\uff0c\u5b83\u7684\u5e94\u7528\u573a\u666f</p>"},{"location":"usage/_feature_example_zh/#_3","title":"\u9879\u76ee\u529f\u80fd","text":"<p>\u672c\u9879\u76ee\u6709\u4ec0\u4e48\u529f\u80fd\uff0c\u5b83\u4e3a\u4ec0\u4e48\u80fd\u89e3\u51b3\u95ee\u9898\uff0c\u529f\u80fd\u7684\u5e94\u7528\u573a\u666f\uff0c\u529f\u80fd\u5b9e\u65bd\u7684\u9650\u5236\u6709\u54ea\u4e9b</p>"},{"location":"usage/_feature_example_zh/#_4","title":"\u5b9e\u65bd\u8981\u6c42","text":"<p>\u5b89\u88c5\u8981\u6c42\uff0c\u5982 \u5185\u6838\u9650\u5236\u3001K8S\u7248\u672c\u3001\u7b2c\u4e09\u65b9\u9879\u76ee\u7248\u672c\u7b49\uff0c\u672c\u9879\u76ee\u5b89\u88c5\u65f6\u54ea\u4e9b\u9009\u578b\u8981\u6253\u5f00\u6216\u5173\u95ed</p>"},{"location":"usage/_feature_example_zh/#_5","title":"\u6b65\u9aa4","text":"<p>step by step \u5c0f\u767d\u53ef\u5b9e\u65bd\uff0c\u6bcf\u4e00\u6b65\u9aa4\u7684\u7ed3\u679c\u786e\u8ba4\u548c\u72b6\u6001\u67e5\u770b(\u7528\u4e8e\u6392\u969c)\uff0c\u7279\u6b8a\u8bf4\u660e\uff0cyaml \u6709\u5bf9\u5e94\u7684\u5de5\u7a0b\u6587\u4ef6</p>"},{"location":"usage/_install_example_zh/","title":"\u5b89\u88c5\u6587\u6863","text":""},{"location":"usage/_install_example_zh/#_2","title":"\u4ecb\u7ecd","text":"<p>\u672c\u6587\u8bf4\u660e\u4e3a\u4e86\u5b89\u88c5\u51fa\u4ec0\u4e48\u6837\u7684\u4e00\u5957\u96c6\u7fa4\uff0c\u5b83\u7684\u4ef7\u503c\u662f\u4ec0\u4e48</p>"},{"location":"usage/_install_example_zh/#_3","title":"\u5b9e\u65bd\u8981\u6c42","text":"<p>\u5b89\u88c5\u8981\u6c42\uff0c\u5982 \u5185\u6838\u9650\u5236\u3001K8S\u7248\u672c\u3001\u7b2c\u4e09\u65b9\u9879\u76ee\u7248\u672c\u7b49</p>"},{"location":"usage/_install_example_zh/#_4","title":"\u6b65\u9aa4","text":"<p>step by step \u5c0f\u767d\u53ef\u5b9e\u65bd\uff0c\u6bcf\u4e00\u6b65\u9aa4\u7684\u7ed3\u679c\u786e\u8ba4\u548c\u72b6\u6001\u67e5\u770b\uff0c\u7279\u6b8a\u8bf4\u660e\uff0cyaml \u6709\u5bf9\u5e94\u7684\u5de5\u7a0b\u6587\u4ef6</p> <p>\u53ea\u8c08\u5b89\u88c5\uff0c\u786e\u8ba4\u5b89\u88c5\u6210\u529f\u72b6\u6001</p>"},{"location":"zh/","title":"EgressGateway","text":"<p>\u5728 Kubernetes\uff08k8s\uff09\u96c6\u7fa4\u4e2d\uff0cPod \u8bbf\u95ee\u5916\u90e8\u670d\u52a1\u65f6\uff0c\u5176\u51fa\u53e3 IP \u5730\u5740\u4e0d\u662f\u56fa\u5b9a\u7684\u3002\u5728 Overlay \u7f51\u7edc\u4e2d\uff0c\u51fa\u53e3 IP \u5730\u5740\u4e3a Pod \u6240\u5728\u8282\u70b9\u7684\u5730\u5740\uff0c\u800c\u5728 Underlay \u7f51\u7edc\u4e2d\uff0cPod \u76f4\u63a5\u4f7f\u7528\u81ea\u8eab\u7684 IP \u5730\u5740\u4e0e\u5916\u90e8\u901a\u4fe1\u3002\u56e0\u6b64\uff0c\u5f53 Pod \u53d1\u751f\u65b0\u7684\u8c03\u5ea6\u65f6\uff0c\u65e0\u8bba\u54ea\u79cd\u7f51\u7edc\u6a21\u5f0f\uff0cPod \u4e0e\u5916\u90e8\u901a\u4fe1\u65f6\u7684 IP \u5730\u5740\u90fd\u4f1a\u53d1\u751f\u53d8\u5316\u3002\u8fd9\u79cd\u4e0d\u7a33\u5b9a\u6027\u7ed9\u7cfb\u7edf\u7ef4\u62a4\u4eba\u5458\u5e26\u6765\u4e86 IP \u5730\u5740\u7ba1\u7406\u7684\u6311\u6218\u3002\u7279\u522b\u662f\u5728\u96c6\u7fa4\u89c4\u6a21\u6269\u5927\u4ee5\u53ca\u9700\u8981\u8fdb\u884c\u7f51\u7edc\u6545\u969c\u8bca\u65ad\u65f6\uff0c\u5728\u96c6\u7fa4\u5916\u90e8\uff0c\u57fa\u4e8e Pod \u539f\u672c\u7684\u51fa\u53e3 IP \u6765\u7ba1\u63a7\u51fa\u53e3\u6d41\u91cf\u5f88\u96be\u5b9e\u73b0\u3002 \u4e3a\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0cEgressGateway \u88ab\u5f15\u5165\u5230 k8s \u96c6\u7fa4\u4e2d\uff0c\u5b83\u662f\u4e00\u4e2a\u5f00\u6e90\u7684 Egress \u7f51\u5173\uff0c\u65e8\u5728\u89e3\u51b3\u5728\u4e0d\u540cCNI\u7f51\u7edc\u6a21\u5f0f\u4e0b\uff08Calico\u3001Flannel\u3001Weave\u3001Spiderpool\uff09\u51fa\u53e3 Egress IP \u5730\u5740\u7684\u95ee\u9898\u3002\u901a\u8fc7\u7075\u6d3b\u914d\u7f6e\u548c\u7ba1\u7406\u51fa\u53e3\u7b56\u7565\uff0c\u4e3a\u79df\u6237\u7ea7\u6216\u96c6\u7fa4\u7ea7\u5de5\u4f5c\u8d1f\u8f7d\u8bbe\u7f6e Egress IP\uff0c\u4f7f\u5f97 Pod \u8bbf\u95ee\u5916\u90e8\u7f51\u7edc\u65f6\uff0c\u7cfb\u7edf\u4f1a\u7edf\u4e00\u4f7f\u7528\u8fd9\u4e2a\u8bbe\u7f6e\u7684 Egress IP \u4f5c\u4e3a\u51fa\u53e3\u5730\u5740\uff0c\u4ece\u800c\u63d0\u4f9b\u4e86\u7a33\u5b9a\u7684\u51fa\u53e3\u6d41\u91cf\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002</p>"},{"location":"zh/#_1","title":"\u67b6\u6784","text":""},{"location":"zh/#egressgateway_1","title":"\u4e3a\u4ec0\u4e48\u9009\u62e9 EgressGateway","text":""},{"location":"zh/#_2","title":"\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u529f\u80fd\u548c\u4f18\u52bf","text":"<ul> <li>\u89e3\u51b3 IPv4/IPv6 \u53cc\u6808\u8fde\u63a5\u95ee\u9898\uff0c\u786e\u4fdd\u7f51\u7edc\u901a\u4fe1\u5728\u4e0d\u540c\u534f\u8bae\u6808\u4e0b\u7684\u65e0\u7f1d\u8fde\u63a5\u3002</li> <li>\u89e3\u51b3 Egress \u8282\u70b9\u7684\u9ad8\u53ef\u7528\u6027\u95ee\u9898\uff0c\u786e\u4fdd\u7f51\u7edc\u8fde\u901a\u6027\u4e0d\u53d7\u5355\u70b9\u6545\u969c\u7684\u5e72\u6270\u3002</li> <li>\u5141\u8bb8\u66f4\u7cbe\u7ec6\u7684\u7b56\u7565\u63a7\u5236\uff0c\u53ef\u4ee5\u901a\u8fc7 EgressGateway \u7075\u6d3b\u5730\u8fc7\u6ee4 Pods \u7684 Egress \u7b56\u7565\uff0c\u5305\u62ec Destination CIDR\u3002</li> <li>\u5141\u8bb8\u8fc7\u6ee4 Egress \u5e94\u7528\uff08Pod\uff09\uff0c\u80fd\u591f\u66f4\u7cbe\u786e\u5730\u7ba1\u7406\u7279\u5b9a\u5e94\u7528\u7684\u51fa\u53e3\u6d41\u91cf\u3002</li> <li>\u652f\u6301\u591a\u4e2a\u51fa\u53e3\u7f51\u5173\u5b9e\u4f8b\uff0c\u80fd\u591f\u5904\u7406\u591a\u4e2a\u7f51\u7edc\u5206\u533a\u6216\u96c6\u7fa4\u4e4b\u95f4\u7684\u901a\u4fe1\u3002</li> <li>\u652f\u6301\u79df\u6237\u7ea7\u522b\u7684 Egress IP\u3002</li> <li>\u652f\u6301\u81ea\u52a8\u68c0\u6d4b\u96c6\u7fa4\u6d41\u91cf\u7684 Egress \u7f51\u5173\u7b56\u7565\u3002</li> <li>\u652f\u6301\u547d\u540d\u7a7a\u95f4\u9ed8\u8ba4 Egress \u5b9e\u4f8b\u3002</li> <li>\u53ef\u7528\u4e8e\u8f83\u4f4e\u5185\u6838\u7248\u672c\uff0c\u9002\u7528\u4e8e\u5404\u79cd Kubernetes \u90e8\u7f72\u73af\u5883\u3002</li> </ul>"},{"location":"zh/#_3","title":"\u517c\u5bb9\u4ee5\u4e0b\u7f51\u7edc\u89e3\u51b3\u65b9\u6848","text":"<ul> <li>Calico</li> <li>Flannel</li> <li>Weave</li> <li>Spiderpool</li> </ul>"},{"location":"zh/#egressgateway_2","title":"\u5f00\u59cb\u4f7f\u7528 EgressGateway","text":"<p>\u53c2\u8003\u5b89\u88c5\u6307\u5357</p>"},{"location":"zh/#_4","title":"\u793e\u533a","text":"<p>\u6211\u4eec\u6b22\u8fce\u4efb\u4f55\u5f62\u5f0f\u7684\u8d21\u732e\u3002\u5982\u679c\u60a8\u6709\u4efb\u4f55\u6709\u5173\u8d21\u732e\u65b9\u9762\u7684\u7591\u95ee\uff0c\u8bf7\u53c2\u9605\u8d21\u732e\u6307\u5357\u3002</p>"},{"location":"zh/#license","title":"License","text":"<p>EgressGateway \u57fa\u4e8e Apache License\uff0cVersion 2.0\u3002\u8be6\u7ec6\u53c2\u8003 LICENSE \u67e5\u770b\u5b8c\u6574 LICENSE \u5185\u5bb9\u3002</p>"},{"location":"zh/Troubleshooting/#vxlan","title":"VXLAN \u901f\u5ea6","text":"<p>EgressGateway \u4f7f\u7528\u4e86 vxlan \u96a7\u9053\uff0c\u7ecf\u8fc7\u6d4b\u8bd5 vxlan \u635f\u8017\u5728 10% \u5de6\u53f3\u3002\u5982\u679c\u60a8\u53d1\u73b0 EgressGateway \u7684\u901f\u5ea6\u4e0d\u8fbe\u6807\uff0c\u53ef\u4ee5\u6267\u884c\u5982\u4e0b\u6b65\u9aa4\u68c0\u67e5\uff1a</p> <ol> <li>\u786e\u8ba4\u5bbf\u4e3b\u673a\u8282\u70b9\u5230\u8282\u70b9\u7684\u901f\u5ea6\u7b26\u5408\u9884\u671f\uff1b<ol> <li>vxlan \u4f7f\u7528\u7684\u5bbf\u4e3b\u673a\u7684\u7f51\u5361\u7684 offload \u8bbe\u7f6e\u4f1a\u5bf9 vxlan \u63a5\u53e3\u7684\u901f\u5ea6\u4ea7\u751f\u8f83\u5c0f\u7684\u5f71\u54cd\uff08\u5728 10G \u7f51\u5361\u6d4b\u8bd5\u4e2d\u4ec5\u4f1a\u6709 0.5 Gbits/sec \u7684\u5dee\u8ddd\uff09\uff0c\u53ef\u4ee5\u6267\u884c <code>ethtool --offload host-interface-name rx on tx on</code> \u5f00\u542f offload\u3002</li> </ol> </li> <li>vxlan \u7f51\u5361\u7684 offload \u8bbe\u7f6e\u53ef\u4ee5\u5bf9 vxlan \u63a5\u53e3\u901f\u5ea6\u4ea7\u751f\u8f83\u5927\u7684\u5f71\u54cd\uff08\u5728 10G \u7f51\u5361\u6d4b\u8bd5\u4e2d\uff0c\u4e0d\u5f00\u542f 2.5 Gbits/sec\uff0c\u5f00\u542f 8.9 Gbits/sec\uff09\uff0c\u4f60\u53ef\u4ee5\u8fd0\u884c <code>ethtool -k egress.vxlan</code> \u68c0\u67e5 checksum offload \u662f\u5426\u5173\u95ed\uff0c\u5e76\u901a\u8fc7 helm values \u7684\u914d\u7f6e <code>feature.vxlan.disableChecksumOffload</code> \u4e3a <code>false</code> \u5f00\u542f offload\u3002</li> </ol>"},{"location":"zh/Troubleshooting/#_1","title":"\u7269\u7406\u673a","text":"<p>\u4ee5\u4e0b\u662f\u6211\u4eec\u4f7f\u7528\u7269\u7406\u670d\u52a1\u5668\u505a\u538b\u6d4b\u7684\u6570\u636e\u3002</p> Name CPU MEM Interface Node 1 Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz 128G 10G Mellanox Node 2 Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz 128G 10G Mellanox Node Target Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz 128G 10G Mellanox Case Item Detail case1 node -&gt; node <code>9.44 Gbits/sec sender - 9.41 Gbits/sec receiver</code> case2 egress vxlan -&gt; egress vxlan <code>9.11 Gbits/sec sender - 9.09 Gbits/sec receiver</code> case3 pod -&gt; egress node -&gt; target <code>9.01 Gbits/sec sender - 8.98 Gbits/sec receiver</code> <p></p>"},{"location":"zh/Troubleshooting/#_2","title":"\u865a\u62df\u673a","text":"<p>\u4ee5\u4e0b\u662f\u4f7f\u7528 VMWare \u7684\u865a\u62df\u673a\uff0c\u9650\u5236 Node \u89c4\u683c\u4e3a 4C8G \u538b\u6d4b\u7684\u6570\u636e\uff0c</p> Name CPU MEM Interface Node 1 Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz 4C 8G VMXNET3 Node 2 Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz 4C 8G VMXNET3 Node Target Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz 4C 8G VMXNET3 Case Item Detail case1 node -&gt; node <code>2.99 Gbits/sec sender - 2.99 Gbits/sec receiver</code> case2 egress vxlan -&gt; egress vxlan <code>1.73 Gbits/sec sender - 1.71 Gbits/sec receiver</code> case3 pod -&gt; egress node -&gt; target <code>1.23 Gbits/sec sender - 1.22 Gbits/sec receiver</code>"},{"location":"zh/concepts/Architecture/","title":"Architecture","text":"<p>EgressGateway \u7531\u63a7\u5236\u9762\u548c\u6570\u636e\u9762 2 \u90e8\u5206\u7ec4\u6210\uff0c\u63a7\u5236\u9762\u7531 4 \u4e2a\u63a7\u5236\u5faa\u73af\u7ec4\u6210\uff0c\u6570\u636e\u9762\u7531 3 \u4e2a\u63a7\u5236\u5faa\u73af\u7ec4\u6210\u3002\u63a7\u5236\u9762\u4ee5 Deployment \u65b9\u5f0f\u90e8\u7f72\uff0c\u652f\u6301\u591a\u526f\u672c\u9ad8\u53ef\u7528\uff0c\u6570\u636e\u9762\u4ee5 DaemonSet \u7684\u65b9\u5f0f\u90e8\u7f72\u3002\u63a7\u5236\u5faa\u73af\u5177\u4f53\u5982\u4e0b\u56fe\uff1a</p> <p></p>"},{"location":"zh/concepts/Architecture/#_1","title":"\u63a7\u5236\u5668","text":""},{"location":"zh/concepts/Architecture/#egresstunnel-a","title":"EgressTunnel \u8c03\u8c10\u5faa\u73af (a)","text":""},{"location":"zh/concepts/Architecture/#_2","title":"\u521d\u59cb\u5316","text":"<ol> <li>\u4ece ConfigMap \u914d\u7f6e\u6587\u4ef6\u4e2d\u83b7\u53d6\u53cc\u6808\u5f00\u542f\u60c5\u51b5\u53ca\u5bf9\u5e94\u7684\u96a7\u9053 CIDR</li> <li>\u901a\u8fc7\u8282\u70b9\u540d\u79f0\u6839\u636e\u7b97\u6cd5\u751f\u6210\u552f\u4e00\u7684\u6807\u7b7e\u503c</li> <li>\u4f1a\u68c0\u67e5 Node \u662f\u5426\u6709\u5bf9\u5e94\u7684 EgressTunnel\uff0c\u6ca1\u6709\u7684\u8bdd\u5c31\u521b\u5efa\u5bf9\u5e94\u7684 EgressTunnel\uff0c\u4e14\u72b6\u6001\u8bbe\u7f6e\u4e3a <code>Pending</code>\u3002\u6709\u96a7\u9053 IP \u5219\u5c06 IP \u4e0e\u8282\u70b9\u7ed1\u5b9a\uff0c\u7ed1\u5b9a\u524d\u4f1a\u68c0\u67e5 IP \u662f\u5426\u5408\u6cd5\uff0c\u4e0d\u5408\u6cd5\u5219\u5c06\u72b6\u6001\u8bbe\u7f6e\u4e3a <code>Pending</code></li> </ol>"},{"location":"zh/concepts/Architecture/#egresstunnel-event","title":"EgressTunnel Event","text":"<ul> <li>Del\uff1a\u5148\u91ca\u653e\u96a7\u9053 IP\uff0c\u518d\u5220\u9664\u3002\u5982\u679c EgressTunnel \u5bf9\u5e94\u7684\u8282\u70b9\u8fd8\u5b58\u5728\uff0c\u91cd\u65b0\u521b\u5efa EgressTunnel</li> <li>Other\uff1a</li> <li>phase != <code>Init</code> || phase != <code>Ready</code>\uff1a\u5219\u5206\u914d IP\uff0c\u5206\u914d\u6210\u529f\u5c06\u72b6\u6001\u8bbe\u7f6e\u4e3a <code>Init</code>\uff0c\u5206\u914d\u5931\u8d25\u5c06\u72b6\u6001\u8bbe\u7f6e\u4e3a <code>Failed</code>\u3002\u8fd9\u91cc\u662f\u5168\u5c40\u552f\u4e00\u4f1a\u5206\u914d\u96a7\u9053 IP \u7684\u5730\u65b9</li> <li>mark != algorithm(NodeName)\uff1a\u8be5\u5b57\u6bb5\u7981\u6b62\u4fee\u6539\uff0c\u76f4\u63a5\u62a5\u9519\u8fd4\u56de</li> </ul>"},{"location":"zh/concepts/Architecture/#node-event","title":"Node Event","text":"<ul> <li>Del\uff1a\u5220\u9664\u5bf9\u5e94\u7684 EgressTunnel</li> <li>Other\uff1a</li> <li>\u8282\u70b9\u5bf9\u5e94\u7684 EgressTunnel \u4e0d\u5b58\u5728\uff0c\u5219\u521b\u5efa EgressTunnel</li> <li>\u65e0\u96a7\u9053 IP\uff0c\u8bbe\u7f6e phase \u4e3a <code>Pending</code></li> <li>\u6709\u96a7\u9053 IP\uff0c\u6821\u9a8c\u96a7\u9053\u662f\u5426\u5408\u6cd5\uff0c\u4e0d\u5408\u6cd5\u5219\u8bbe\u7f6e phase \u4e3a <code>Pending</code></li> <li>\u96a7\u9053 IP \u5408\u6cd5\uff0c\u6821\u9a8c IP \u662f\u5426\u5206\u914d\u7ed9\u672c\u8282\u70b9\uff0c\u4e0d\u662f\u5219\u8bbe\u7f6e phase \u4e3a <code>Pending</code></li> <li>\u96a7\u9053 IP \u662f\u5206\u914d\u7ed9\u672c\u8282\u70b9\uff0cphase \u72b6\u6001\u4e0d\u4e3a <code>Ready</code> \u5219\u8bbe\u7f6e phase \u4e3a <code>Init</code></li> </ul>"},{"location":"zh/concepts/Architecture/#egressgateway-b","title":"EgressGateway \u8c03\u8c10\u5faa\u73af (b)","text":""},{"location":"zh/concepts/Architecture/#egressgateway-event","title":"EgressGateway Event","text":"<ul> <li>Del\uff1a</li> <li>Webhook \u5224\u65ad\u662f\u5426\u8fd8\u88ab\u5176\u4ed6 Policy \u5f15\u7528\uff0c\u5982\u679c\u5b58\u5728\u5219\u4e0d\u5141\u8bb8\u5220\u9664\u3002</li> <li> <p>\u901a\u8fc7\u4e86 Webhook \u7684\u6821\u9a8c\u8bf4\u660e\u6ca1\u6709\u88ab\u5f15\u7528\uff0c\u6240\u6709\u7684\u89c4\u5219\u4e5f\u88ab\u6e05\u7406\uff0c\u5219\u53ef\u4ee5\u76f4\u63a5\u5220\u9664\u3002</p> </li> <li> <p>Other\uff1a</p> </li> <li>EIP \u51cf\u5c11\uff0c\u5982\u679c EIP \u88ab\u5f15\u7528\uff0c\u7981\u6b62\u4fee\u6539\u3002\u5206\u914d IPV4 \u4e0e IPV6 \u65f6\uff0c\u8981\u6c42\u4e00\u4e00\u5bf9\u5e94\uff0c\u6240\u4ee5\u4e24\u8005\u7684\u4e2a\u6570\u9700\u8981\u4e00\u81f4\u3002</li> <li>\u5982\u679c nodeSelector \u88ab\u4fee\u6539\uff0c\u4ece status \u83b7\u53d6\u65e7\u7684 Node \u4fe1\u606f\uff0c\u4e0e\u6700\u65b0\u7684 Node \u8fdb\u884c\u5bf9\u6bd4\u3002\u5c06\u5220\u9664\u8282\u70b9\u4e0a\u7684 EIP \u91cd\u65b0\u5206\u914d\u5230\u65b0\u7684 Node \u4e0a\u3002\u66f4\u65b0\u5bf9\u5e94 EgressTunnel \u4e2d\u7684 EIP \u4fe1\u606f\u3002</li> </ul>"},{"location":"zh/concepts/Architecture/#egresspolicy-event","title":"EgressPolicy Event","text":"<ul> <li>Del\uff1a\u5217\u51fa EgressPolicy \u627e\u5230\u88ab\u5f15\u7528\u7684 EgressGateway\uff0c\u518d\u5bf9 EgressPolicy \u4e0e EgressGateway \u89e3\u7ed1\u3002\u89e3\u7ed1\u9700\u8981\u505a\u7684\u4e8b\u60c5\u6709\uff0c\u627e\u5230\u5bf9\u5e94\u7684 EIP \u4fe1\u606f\u3002\u5982\u679c\u4f7f\u7528\u4e86 EIP\uff0c\u5219\u5224\u65ad\u662f\u5426\u9700\u8981\u56de\u6536 EIP\u3002\u5982\u679c\u6b64\u65f6 EIP \u5df2\u7ecf\u6ca1\u6709 policy \u4f7f\u7528\uff0c\u5219\u56de\u6536 EIP\uff0c\u66f4\u65b0\u81ea\u8eab\u53ca EgressTunnel \u7684 EIP \u4fe1\u606f\u3002</li> <li>Other\uff1a</li> <li>EgressPolicy \u4e0d\u80fd\u4fee\u6539\u7ed1\u5b9a\u7684 EgressGateway\u3002\u5982\u679c\u5141\u8bb8\u4fee\u6539\uff0c\u5219\u5217\u51fa EgressGateway \u627e\u5230\u539f\u5148\u7ed1\u5b9a\u7684 EgressGateway\uff0c\u8fdb\u884c\u89e3\u7ed1\u3002\u518d\u5bf9\u65b0\u7684\u8fdb\u884c\u7ed1\u5b9a\u3002</li> <li>\u65b0\u589e EgressPolicy\uff0c\u5219\u5c06 EgressPolicy \u4e0e EgressGateway \u8fdb\u884c\u7ed1\u5b9a\uff0c\u7ed1\u5b9a\u4e2d\uff0c\u5224\u65ad\u662f\u5426\u9700\u8981\u5206\u914d EIP\u3002</li> </ul>"},{"location":"zh/concepts/Architecture/#node-event_1","title":"Node Event","text":"<ul> <li>Del\uff1a\u5217\u51fa EgressGateway \u6311\u9009\u51fa\u5728\u8be5\u8282\u70b9\u751f\u6548\u7684 EIP\uff0c\u5c06\u8fd9\u4e9b EIP \u91cd\u65b0\u5206\u914d\u5230\u65b0\u7684\u8282\u70b9\u4e0a\u3002\u66f4\u65b0 EgressGateway \u7684 eip.policy\u3002</li> <li>Other\uff1a</li> <li>NoReady \u4e8b\u4ef6\u65f6\uff0c\u76f8\u5f53\u4e8e\u89e6\u53d1\u5220\u9664\u4e8b\u4ef6\u3002</li> <li>\u6807\u7b7e\u4fee\u6539\uff0c\u901a\u8fc7\u904d\u5386 EgressGateway \u6240\u6709\u4fe1\u606f\uff0c\u662f\u5426\u6d89\u53ca nodeSelector\u3002\u5982\u679c\u65e7\u6807\u7b7e\u4e0d\u6d89\u53ca EgressPolicy\uff0c\u5219\u4e0d\u505a\u4efb\u4f55\u5904\u7406\u3002\u5982\u679c\u6709\u6d89\u53ca\uff0c\u76f8\u5f53\u4e8e\u89e6\u53d1\u4e86\u5220\u9664\u4e8b\u4ef6\u3002\u5982\u679c\u65b0\u7684\u6807\u7b7e\u7b26\u5408 EgressGateway \u6761\u4ef6\uff0c\u5219\u66f4\u65b0\u5bf9\u5e94\u7684 EgressGateway \u7684 status \u4fe1\u606f\u3002</li> </ul>"},{"location":"zh/concepts/Architecture/#egresspolicy-eip","title":"EgressPolicy \u9009\u7f51\u5173\u8282\u70b9\u53ca EIP \u5206\u914d\u903b\u8f91","text":"<p>\u4e00\u4e2a EgressPolicy \u4f1a\u6839\u636e\u9009\u7f51\u5173\u8282\u70b9\u7684\u7b56\u7565\uff0c\u9009\u62e9\u4e00\u4e2a\u8282\u70b9\u4f5c\u4e3a\u7f51\u5173\u8282\u70b9\u3002\u7136\u540e\u6839\u636e\u662f\u5426\u4f7f\u7528 EIP\uff0c\u6765\u51b3\u5b9a\u662f\u5426\u5206\u914d EIP\u3002\u5206\u914d\u7684 EIP \u5c06\u7ed1\u5b9a\u5230\u6240\u9009\u7684\u7f51\u5173\u8282\u70b9\u4e0a\u3002</p> <p>\u5206\u914d\u903b\u8f91\u90fd\u662f\u4ee5\u5355\u4e2a EgressGateway \u4e3a\u5bf9\u8c61\uff0c\u800c\u4e0d\u662f\u6240\u6709\u7684 EgressGateway\u3002</p>"},{"location":"zh/concepts/Architecture/#egresspolicy","title":"EgressPolicy \u9009\u7f51\u5173\u8282\u70b9\u7684\u6a21\u5f0f","text":"<ul> <li>\u5e73\u5747\u9009\u62e9\uff1a\u5f53\u9700\u8981\u9009\u62e9\u7f51\u5173\u8282\u70b9\u65f6\uff0c\u9009\u62e9\u4f5c\u4e3a\u7f51\u5173\u8282\u70b9\u6700\u5c11\u7684\u4e00\u4e2a\u8282\u70b9\u3002</li> <li>\u6700\u5c11\u8282\u70b9\u9009\u62e9\uff1a\u5c3d\u91cf\u9009\u540c\u4e00\u4e2a\u8282\u70b9\u4f5c\u4e3a\u7f51\u5173\u8282\u70b9\u3002</li> <li>\u9650\u5ea6\u9009\u62e9\uff1a\u4e00\u4e2a\u8282\u70b9\u6700\u591a\u53ea\u80fd\u6210\u4e3a\u51e0\u4e2a EgressPolicy \u7684\u7f51\u5173\u8282\u70b9\uff0c\u9650\u5ea6\u53ef\u4ee5\u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u4e3a 5\u3002\u6ca1\u6709\u8fbe\u5230\u9650\u5ea6\u524d\uff0c\u5219\u4f18\u9009\u9009\u62e9\u8be5\u8282\u70b9\uff0c\u8fbe\u5230\u9650\u5ea6\u5c31\u5148\u9009\u5176\u4ed6\u7684\u8282\u70b9\uff0c\u5982\u679c\u90fd\u8fbe\u5230\u4e86\u9650\u5ea6\uff0c\u5219\u518d\u968f\u673a\u9009\u62e9\u3002</li> </ul>"},{"location":"zh/concepts/Architecture/#eip","title":"EIP \u5206\u914d\u903b\u8f91","text":"<ul> <li>\u968f\u673a\u5206\u914d\uff1a\u5728\u6240\u6709\u7684 EIP \u4e2d\u968f\u673a\u9009\u62e9\u4e00\u4e2a\uff0c\u4e0d\u7ba1\u8be5 EIP \u662f\u5426\u5df2\u7ecf\u5206\u914d</li> <li>\u4f18\u5148\u4f7f\u7528\u672a\u5206\u914d\u7684 EIP\uff1a\u5148\u4f7f\u7528\u672a\u5206\u914d\u7684 EIP\uff0c\u5982\u679c\u90fd\u4f7f\u7528\u4e86\u5219\u518d\u968f\u673a\u5206\u914d\u4e00\u4e2a\u5df2\u4f7f\u7528\u7684 EIP</li> <li>\u9650\u5ea6\u9009\u62e9\uff1a\u4e00\u4e2a EIP \u6700\u591a\u53ea\u80fd\u88ab\u51e0\u4e2a EgressPolicy \u4f7f\u7528\uff0c\u9650\u5ea6\u53ef\u4ee5\u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u4e3a 5\uff0c\u6ca1\u6709\u8fbe\u5230\u9650\u5ea6\u524d\uff0c\u5219\u5148\u5206\u914d\u8be5 EIP\uff0c\u8fbe\u5230\u9650\u5ea6\u5219\u9009\u5176\u4ed6\u7684 EIP\u3002\u90fd\u8fbe\u5230\u9650\u5ea6\u5219\u968f\u673a\u5206\u914d\u3002</li> </ul>"},{"location":"zh/concepts/Architecture/#eip_1","title":"EIP \u56de\u6536\u903b\u8f91","text":"<p>\u5f53\u4e00\u4e2a EIP \u6ca1\u6709\u88ab\u4f7f\u7528\u65f6\uff0c\u5219\u56de\u6536\u8be5 EIP\uff0c\u56de\u6536\u5c31\u662f\u5728 <code>eips</code> \u4e2d\u5c06\u8be5 EIP \u5b57\u6bb5\u5220\u9664\u3002</p>"},{"location":"zh/concepts/Architecture/#egressclusterinfo-d","title":"EgressClusterInfo \u8c03\u534f\u5faa\u73af (d)","text":""},{"location":"zh/concepts/Architecture/#node-event_2","title":"Node Event","text":"<ul> <li>Create\uff1anode \u521b\u5efa\u65f6\uff0c\u5c06 node \u7684 IP \u81ea\u52a8\u6dfb\u52a0\u5230 egressclusterinfos CR <code>status.egressIgnoreCIDR.nodeIP</code> \u4e2d\u3002</li> <li>Update\uff1anode IP \u6709\u66f4\u65b0\u65f6\uff0c\u5c06 node \u7684 IP \u81ea\u52a8\u66f4\u65b0\u5230 egressclusterinfos CR <code>status.egressIgnoreCIDR.nodeIP</code> \u4e2d\u3002</li> <li>Delete\uff1anode \u88ab\u5220\u9664\u65f6\uff0c\u5c06 node \u7684 IP \u4ece egressclusterinfos CR <code>status.egressIgnoreCIDR.nodeIP</code> \u4e2d\u5220\u9664\u3002</li> </ul>"},{"location":"zh/concepts/Architecture/#calico-ippool-event","title":"Calico IPPool Event","text":"<p>\u5f53 egressgateway \u914d\u7f6e\u6587\u4ef6\u7684 <code>egressIgnoreCIDR.autoDetect.podCIDR</code> \u4e3a \"calico\" \u65f6\uff0c\u76d1\u542c Calico \u7684 IPPool Event\u3002 - Create\uff1aCalico IPPool \u521b\u5efa\u65f6\uff0c\u5c06 IPPool CIDR \u81ea\u52a8\u6dfb\u52a0\u5230 EgressClusterInfo CR <code>status.egressIgnoreCIDR.podCIDR</code> \u4e2d\u3002 - Update\uff1acalico IPPool \u6709\u66f4\u65b0\u65f6\uff0c\u5c06 IPPool CIDR \u81ea\u52a8\u66f4\u65b0\u5230 EgressClusterInfo CR <code>status.egressIgnoreCIDR.podCIDR</code> \u4e2d\u3002 - Delete\uff1acalico IPPool \u88ab\u5220\u9664\u65f6\uff0c\u5c06 IPPool CIDR \u4ece EgressClusterInfo CR <code>status.egressIgnoreCIDR.podCIDR</code> \u4e2d\u5220\u9664\u3002</p>"},{"location":"zh/concepts/Architecture/#_3","title":"\u914d\u7f6e\u6587\u4ef6","text":"<p>\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff0c\u589e\u52a0\u5982\u4e0b\u914d\u7f6e\uff1a</p> <pre><code>feature:\negressIgnoreCIDR:\nautoDetect:\npodCIDR: \"\"      # (1)\nclusterIP: true  # (2)\nnodeIP: true     # (3)\ncustom:\n- \"10.6.1.0/24\"\n</code></pre> <ol> <li><code>podCIDR</code>\uff0c\u76ee\u524d\u652f\u6301 <code>calico</code>\u3001<code>k8s</code>\u3002\u9ed8\u8ba4\u4e3a <code>k8s</code>\u3002</li> <li><code>clusterIP</code>\uff0c\u652f\u6301\u8bbe\u7f6e\u4e3a Service CIDR \u81ea\u52a8\u68c0\u6d4b\u3002</li> <li><code>nodeIP</code>\uff0c\u652f\u6301\u8bbe\u7f6e\u4e3a Node IP \u81ea\u52a8\u68c0\u6d4b\u3002</li> </ol>"},{"location":"zh/concepts/Datapath/","title":"Datapath","text":"<p>\u5bf9\u9700\u8981\u751f\u6548\u7684\u89c4\u5219\u5206\u4e3a\u4e09\u7c7b\uff1a\u6240\u6709\u8282\u70b9\uff0c\u76f8\u5bf9\u4e8e EgressGatewayPolicy \u7684\u300c\u7f51\u5173\u8282\u70b9\u300d\u548c\u300c\u975e\u7f51\u5173\u8282\u70b9\u300d\u3002\u53ea\u6709\u5f53\u4e1a\u52a1 Pod \u8c03\u5ea6\u5230\u7684\u300c\u975e\u7f51\u5173\u8282\u70b9\u300d\uff0c\u8be5\u8282\u70b9\u4e0a\u7684\u89c4\u5219\u624d\u4f1a\u751f\u6548\u3002</p>"},{"location":"zh/concepts/Datapath/#_1","title":"\u6240\u6709\u8282\u70b9","text":"<ol> <li>\u5404\u8282\u70b9\u4e4b\u95f4\uff0c\u96a7\u9053\u6253\u901a\u89c4\u5219\uff1b    <pre><code># \u672c\u5730\u96a7\u9053\u7f51\u5361\u4fe1\u606f\nLOCAL_TUNNEL_IPV4=\"20.0.0.80/24\"\n\nLOCAL_TUNNEL_IPV6=\"fccc::80/64\"\n\nTUNNEL_NAME=\"egress-vxlan\"\n\nVXLAN_ID=\"20\"\n\nLOCAL_DEV=\"eth1\"\n\nLOCA_PHY_IP=\"172.16.1.11\"\n\nDEST_UDP_PORT=\"8789\"\n\nLOCAL_TUNNEL_MAC=\"00:11:00:00:00:80\"\n\n# \u521b\u5efa\u96a7\u9053\u7f51\u5361\nip l d $TUNNEL_NAME &amp;&gt;/dev/null\n\nip link add $TUNNEL_NAME type vxlan id $VXLAN_ID local $LOCA_PHY_IP dstport $DEST_UDP_PORT dev $LOCAL_DEV nolearning\n\nip -6 a add $LOCAL_TUNNEL_IPV6 dev $TUNNEL_NAME\n\nip -4 a add $LOCAL_TUNNEL_IPV4 dev $TUNNEL_NAME\n\nip l set $TUNNEL_NAME address $LOCAL_TUNNEL_MAC\n\nip link set $TUNNEL_NAME up\n\n# \u5bf9\u7aef\u96a7\u9053\u4fe1\u606f\nREMOTE1_TUNNEL_MAC=\"00:11:00:00:00:85\"\n\nREMOTE1_TUNNEL_IPV4=\"20.0.0.85\"\n\nREMOTE1_TUNNEL_IPV6=\"fccc::85\"\n\nREMOTE1_PHY_IP=\"172.16.2.21\"\n\n# \u6dfb\u52a0\u5bf9\u7aef\u96a7\u9053\u8f6c\u53d1\u4fe1\u606f\nbridge fdb append to $REMOTE1_TUNNEL_MAC dst $REMOTE1_PHY_IP dev $TUNNEL_NAME\n\nip -4 n add  $REMOTE1_TUNNEL_IPV4  lladdr  $REMOTE1_TUNNEL_MAC  dev $TUNNEL_NAME\n\nip -6 n add  $REMOTE1_TUNNEL_IPV6  lladdr  $REMOTE1_TUNNEL_MAC  dev $TUNNEL_NAME\n\n# \u6dfb\u52a0\u7b56\u7565\u8def\u7531\u4fe1\u606f\nip rule add fwmark $NODE_MARK table $TABLE_NUM\n\nip route add default via $REMOTE1_TUNNEL_IPV4 dev $TUNNEL_NAME onlink table $TABLE_NUM\n\nip -6 rule add fwmark $NODE_MARK table $TABLE_NUM\n\nip -6 route add default via $REMOTE1_TUNNEL_IPV6 dev $TUNNEL_NAME onlink table $TABLE_NUM\n</code></pre></li> <li>\u5728\u8282\u70b9\u7b2c\u4e00\u6b21\u53d8\u6210\u7f51\u5173\u8282\u70b9\u65f6\u66f4\u65b0\uff0c\u6216\u8005\u8282\u70b9 join \u65f6\uff0c\u5c06 policy \u547d\u4e2d\u7684\u6d41\u91cf\uff0c\u91cd\u65b0\u6253\u6807\u7b7e\u3002\u5176\u4ed6\u60c5\u51b5\u4e0d\u66f4\u65b0\u3002</li> </ol> <pre><code>iptables -t mangle -N EGRESSGATEWAY-RESET-MARK\niptables -t mangle -I FORWARD 1  -j EGRESSGATEWAY-RESET-MARK -m comment --comment \"egress gateway: mark egress packet\"\niptables -t mangle -A EGRESSGATEWAY-RESET-MARK \\\n-m mark --mark $NODE_MARK/0x26000000 \\\n-j MARK --set-mark 0x12000000 \\\n-m comment --comment \"egress gateway: change mark\"\n</code></pre> <ol> <li>\u4fdd\u6301 policy \u547d\u4e2d\u6d41\u91cf\u7684\u6807\u7b7e\u3002\u76f4\u63a5\u521b\u5efa\u4e00\u6b21\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\uff1b</li> </ol> <pre><code>iptables -t filter -I FORWARD 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t filter -I OUTPUT 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\niptables -t mangle -I POSTROUTING 1 -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: keep mark\"\n</code></pre> <ol> <li>\u805a\u5408 policy \u547d\u4e2d\u6d41\u91cf\u6253\u6807\u7b7e\u7684\u94fe\u3002\u76f4\u63a5\u521b\u5efa\u4e00\u6b21\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\uff1b</li> </ol> <pre><code>iptables -t mangle -N EGRESSGATEWAY-MARK-REQUEST\n\niptables -t mangle -I PREROUTING 1 -j EGRESSGATEWAY-MARK-REQUEST -m comment --comment \"egress gateway: mark egress packet\"\n</code></pre> <ol> <li>\u805a\u5408\u4e0d\u9700\u8981\u505a SNAT \u89c4\u5219\u7684\u94fe\u3002\u76f4\u63a5\u521b\u5efa\u4e00\u6b21\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\uff1b</li> </ol> <pre><code>iptables -t nat -N EGRESSGATEWAY-NO-SNAT\n\niptables -t nat -I POSTROUTING 1  -j EGRESSGATEWAY-NO-SNAT -m comment --comment \"egress gateway: no snat\"\niptables -t nat -A EGRESSGATEWAY-NO-SNAT -m mark --mark 0x12000000 -j ACCEPT -m comment --comment \"egress gateway: no snat\"\n</code></pre> <ol> <li>\u805a\u5408\u9700\u8981\u505a SNAT \u89c4\u5219\u7684\u94fe\u3002\u76f4\u63a5\u521b\u5efa\u4e00\u6b21\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\u3002</li> </ol> <pre><code>iptables -t nat -N EGRESSGATEWAY-SNAT-EIP\n\n# \u9700\u8981\u5728\u4e0d\u9700\u8981 SNAT \u7684\u89c4\u5219\u540e\u9762\u63d2\u5165\uff0c\u624d\u80fd\u4fdd\u8bc1\u8be5\u94fe\u5728\u6700\u524d\u9762\niptables -t nat -I POSTROUTING 1  -j EGRESSGATEWAY-SNAT-EIP -m comment --comment \"egress gateway: snat EIP\"\n</code></pre> <ol> <li>egress-ingore-cidr \u5f53 EgressGatewayPolicy \u7684 <code>destSubnet</code> \u5b57\u6bb5\u4e3a\u7a7a\u65f6\uff0c\u6570\u636e\u9762\u5c06\u4f1a\u81ea\u52a8\u5339\u914d EgressClusterStatus CR \u4e2d\u7684 CIDR \u4e4b\u5916\u7684\u6d41\u91cf\uff0c\u5e76\u5c06\u5176\u8f6c\u53d1\u5230 Egress \u7f51\u5173\u3002</li> </ol> <pre><code>IPSET_RULE_DEST_NAME=egress-ingore-cidr\n\nipset x $IPSET_RULE_DEST_NAME\nipset create $IPSET_RULE_DEST_NAME hash:net\n\nipset add $IPSET_RULE_DEST_NAME 10.6.105.150/32\n</code></pre>"},{"location":"zh/concepts/Datapath/#eip-egress-gateway","title":"\u76f8\u5bf9\u4e8e EIP \u7684\u975e Egress Gateway \u8282\u70b9","text":"<ol> <li>policy \u547d\u4e2d\u7684\u6e90 IP\u3001\u76ee\u7684 IP \u7684 ipset\uff1b</li> </ol> <pre><code>IPSET_RULE_DEST_NAME=egress-dest-uuid\n\nipset x $IPSET_RULE_DEST_NAME\nipset create $IPSET_RULE_DEST_NAME hash:net\n\nipset add $IPSET_RULE_DEST_NAME 10.6.105.150/32\n\nIPSET_RULE_SRC_NAME=egress-src-uuid\n\nipset x $IPSET_RULE_SRC_NAME\nipset create $IPSET_RULE_SRC_NAME hash:net\n\nipset add $IPSET_RULE_SRC_NAME 172.29.234.173/32\n</code></pre> <ol> <li>policy \u547d\u4e2d\u7684\u6d41\u91cf\u6253\u6807\u7b7e\uff0c\u4fdd\u8bc1\u80fd\u4ece\u96a7\u9053\u8d70\u3002\u5176\u4e2d NODE_MARK \u7684\u503c\u6839\u636e policy \u5bf9\u5e94\u7684 EIP \u6240\u5728\u8282\u70b9\u51b3\u5b9a\u3002</li> </ol> <pre><code>iptables -A EGRESSGATEWAY-MARK-REQUEST -t mangle -m conntrack --ctdir ORIGINAL \\\n-m set --match-set $IPSET_RULE_DEST_NAME dst  \\\n-m set --match-set $IPSET_RULE_SRC_NAME src  \\\n-j MARK --set-mark $NODE_MARK -m comment --comment \"rule uuid: mark request packet\"\n</code></pre> <ol> <li>\u7b56\u7565\u8def\u7531\u89c4\u5219</li> </ol> <pre><code>ip rule add fwmark $NODE_MARK table $TABLE_NUM\n</code></pre> <ol> <li>\u9002\u914d Weave \u907f\u514d\u505a SNAT \u6210 Egress \u96a7\u9053\u7684 IP\u3002\u505a\u6210\u5f00\u5173</li> </ol> <pre><code>iptables -t nat -A EGRESSGATEWAY-NO-SNAT \\\n-m set --match-set $IPSET_RULE_DEST_NAME dst  \\\n-m set --match-set $IPSET_RULE_SRC_NAME src  \\\n-j ACCEPT -m comment --comment \"egress gateway: weave does not do SNAT\"\n</code></pre>"},{"location":"zh/concepts/Datapath/#eip-egress-gateway_1","title":"\u76f8\u5bf9\u4e8e EIP \u7684 Egress Gateway \u8282\u70b9","text":"<ol> <li>policy \u547d\u4e2d\u7684\u6e90 IP\u3001\u76ee\u7684 IP \u7684 ipset\uff1b</li> </ol> <pre><code>IPSET_RULE_DEST_NAME=egress-dest-uuid\n\nipset x $IPSET_RULE_DEST_NAME\nipset create $IPSET_RULE_DEST_NAME hash:net\n\nipset add $IPSET_RULE_DEST_NAME 10.6.105.150/32\n\nIPSET_RULE_SRC_NAME=egress-src-uuid\n\nipset x $IPSET_RULE_SRC_NAME\nipset create $IPSET_RULE_SRC_NAME hash:net\n\nipset add $IPSET_RULE_SRC_NAME 172.29.234.173/32\n</code></pre> <ol> <li>policy \u547d\u4e2d\u7684\u6d41\u91cf\u3002\u51fa\u7f51\u5173\u65f6\u505a SNAT\u3002\u5b9e\u65f6\u66f4\u65b0\u3002</li> </ol> <pre><code>iptables -t nat -A EGRESSGATEWAY-SNAT-EIP \\\n-m set --match-set $IPSET_RULE_SRC_NAME src \\\n-m set --match-set $IPSET_RULE_DST_NAME dst \\\n-j SNAT --to-source $EIP\n</code></pre>"},{"location":"zh/concepts/Datapath/#_2","title":"\u5176\u4ed6","text":"<ol> <li> <p>NODE_MARK\uff1a\u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u4e00\u4e2a\u5168\u5c40\u552f\u4e00\u7684\u6807\u7b7e\u3002\u6807\u7b7e\u7531\u524d\u7f00 + \u552f\u4e00\u6807\u8bc6\u7b26\u751f\u6210\u3002\u6807\u7b7e\u683c\u5f0f\u5982\u4e0b <code>NODE_MARK = 0x26 + value + 0000</code>\uff0c<code>value</code> \u4e3a 16 \u4f4d\uff0c\u652f\u6301\u7684\u8282\u70b9\u603b\u6570\u4e3a <code>2^16</code>\u3002</p> </li> <li> <p>TABLE_NUM\uff1a</p> <ul> <li>\u7531\u4e8e\u6bcf\u4e2a\u4e3b\u673a\u53ea\u80fd\u6709 [0, 255] \u5f20\u8def\u7531\u8868\uff08\u5176\u4e2d 0\u3001253\u3001254\u3001255 \u5df2\u88ab\u7cfb\u7edf\u4f7f\u7528\uff09\uff0c\u8d85\u51fa\u8868\u7684\u5f20\u6570\u65f6\uff0c\u4f1a\u5bfc\u81f4\u8282\u70b9\u8def\u7531\u6ca1\u6cd5\u8ba1\u7b97\uff0c\u4ece\u800c\u8282\u70b9\u5931\u8054\u3002\u800c\u4e14\u8868\u540d\u4e0e\u8868\u7684 ID \u5339\u914d\uff0c\u5982\u679c\u6ca1\u6709\u5339\u914d\uff0c\u5219\u5185\u6838\u4f1a\u968f\u673a\u5206\u914d\u3002\u6240\u4ee5\u4e3a\u4e86\u4fdd\u9669\u8d77\u89c1\uff0c\u63a7\u5236\u8868\u7684\u7684\u5f20\u6570\uff08n \u8868\u793a\uff0c\u9ed8\u8ba4\u503c\u4e3a 100\uff09\u4e5f\u5c31\u662f\u7f51\u5173\u8282\u70b9\u7684\u4e0a\u9650\uff0c\u53ef\u4ee5\u901a\u8fc7\u53d8\u91cf\u8bbe\u7f6e\u3002</li> <li>TABLE_NUM \u7b97\u6cd5\uff1a\u7528\u6237\u53ef\u4ee5\u8bbe\u7f6e\u4e00\u4e2a\u8d77\u59cb\u503c\uff08s \u8868\u793a\uff0c\u9ed8\u8ba4\u503c\u4e3a 3000\uff09\uff0c\u5219\u8868\u540d\u7684\u8303\u56f4\u4e3a [s, (s+n)]\uff0c\u7528\u6237\u9700\u8981\u4fdd\u8bc1 [s, (s+n)] \u7684\u8868\u540d\u6ca1\u6709\u88ab\u5360\u7528\u3002\u968f\u673a\u4ece [s, (s+n)] \u53d6\u4e00\u4e2a\u8d77\u59cb\u503c\uff0c\u4f9d\u6b21\u589e\u52a0\uff0c\u73af\u5f62\u53d6\u503c\uff0c\u76f4\u5230\u83b7\u5f97\u4e00\u4e2a\u672c\u8282\u70b9\u672a\u4f7f\u7528\u7684\u8868\u540d\uff0c\u672a\u627e\u5230\u5219\u62a5\u9519\u3002</li> </ul> </li> </ol>"},{"location":"zh/reference/EgressClusterEndpointSlice/","title":"CRD EgressClusterEndpointSlice","text":"<p>EgressClusterEndpointSlice CRD \u7528\u4e8e\u805a\u5408 EgressClusterPolicy \u6240\u5339\u914d\u4e2d\u7684 Pods \u5730\u5740\u4fe1\u606f\uff0c\u6b64\u8d44\u6e90\u4ec5\u4f9b\u5185\u90e8\u4f7f\u7528\uff0c\u7528\u4e8e\u63d0\u5347\u63a7\u5236\u9762\u7684\u6027\u80fd\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressClusterEndpointSlice\nmetadata:\ngenerateName: cluster-policy-\nlabels:\nspidernet.io/policy-name: cluster-policy          # (1)\nname: cluster-policy-zp667\nownerReferences:\n- apiVersion: egressgateway.spidernet.io/v1beta1  # (2)\nblockOwnerDeletion: true\ncontroller: true\nkind: EgressClusterPolicy\nname: cluster-policy\nuid: fdca1dd5-9c3b-4d58-b043-451e10f15ea8\nendpoints:                                             # (3)\n- ipv4:\n- 10.21.60.74                                    # (4)\nipv6:\n- fd00:21::5328:9c2:3579:8cca                    # (5)\nnode: workstation3                                 # (6)\nns: ns1                                            # (7)\npod: ns2-mock-app-5c4cd6bb87-g4fdj                 # (8)\n</code></pre> <ol> <li>\u6b64\u6807\u7b7e\u503c\u8868\u793a EgressClusterEndpointSlice \u6240\u5c5e\u7684 EgressClusterPolicy\u3002</li> <li>\u901a\u8fc7\u4f7f\u7528 <code>ownerReferences</code>\uff0c\u8be5 CRD \u4e0e\u5176\u7236\u8d44\u6e90\u5173\u8054\uff0c\u5b9e\u73b0 EgressClusterPolicy \u5220\u9664\u65f6\u81ea\u52a8\u56de\u6536 EgressClusterEndpointSlice \u529f\u80fd\u3002</li> <li>EgressClusterEndpointSlice \u5bf9\u8c61\u7528\u4e8e\u6c47\u603b EgressClusterPolicy \u5339\u914d\u5230\u7684 Pods \u5730\u5740\u4fe1\u606f\uff0c\u9ed8\u8ba4\u5728\u8d85\u8fc7 100 \u4e2a\u5339\u914d\u7ed3\u679c\u65f6\uff0c\u5c06\u521b\u5efa\u65b0\u7684 EgressClusterEndpointSlice\u3002</li> <li>Pods \u7684 IPv4 \u5730\u5740\u5217\u8868\u3002</li> <li>Pods \u7684 IPv6 \u5730\u5740\u5217\u8868\u3002</li> <li>Pods \u6240\u5728\u8282\u70b9\u7684\u4fe1\u606f\u3002</li> <li>Pods \u6240\u5c5e\u79df\u6237\u7684\u4fe1\u606f\u3002</li> <li>Pods \u7684\u540d\u79f0\u3002</li> </ol>"},{"location":"zh/reference/EgressClusterInfo/","title":"CRD EgressClusterInfo","text":"<p>EgressClusterInfo CRD \u4e3a\u4e86\u7b80\u5316 Egress \u7b56\u7565\u7684\u914d\u7f6e\uff0c\u5f15\u5165 Egress Ignore CIDR \u529f\u80fd\uff0c\u5141\u8bb8\u81ea\u52a8\u83b7\u53d6\u96c6\u7fa4\u7684 CIDR\u3002\u5f53 EgressGatewayPolicy \u7684 <code>destSubnet</code> \u5b57\u6bb5\u4e3a\u7a7a\u65f6\uff0c\u6570\u636e\u9762\u5c06\u4f1a\u81ea\u52a8\u5339\u914d EgressClusterStatus CR \u4e2d\u7684 CIDR \u4e4b\u5916\u7684\u6d41\u91cf\uff0c\u5e76\u5c06\u5176\u8f6c\u53d1\u5230 Egress \u7f51\u5173\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressClusterInfo\nmetadata:\nname: default  # (1)\nspec:\nautoDetect:\nclusterIP: true # (2)\nnodeIP: true # (3)\npodCidrMode: auto # (4)\nextraCidr: # (5)\n- 10.10.10.1\nstatus:\nclusterIP: # (6)\nipv4:\n- 172.41.0.0/16\nipv6:\n- fd41::/108\nextraCidr: # (7)\n- 10.10.10.1\nnodeIP: # (8)\negressgateway-control-plane:\nipv4:\n- 172.18.0.3\nipv6:\n- fc00:f853:ccd:e793::3\negressgateway-worker:\nipv4:\n- 172.18.0.2\nipv6:\n- fc00:f853:ccd:e793::2\negressgateway-worker2:\nipv4:\n- 172.18.0.4\nipv6:\n- fc00:f853:ccd:e793::4\npodCIDR: # (9)\ndefault-ipv4-ippool:\nipv4:\n- 172.40.0.0/16\ndefault-ipv6-ippool:\nipv6:\n- fd40::/48\ntest-ippool:\nipv4:\n- 177.70.0.0/16\npodCidrMode: calico # (10)\n</code></pre> <ol> <li>\u540d\u79f0\u4e3a <code>default</code>\uff0c\u7531\u7cfb\u7edf\u7ef4\u62a4\u53ea\u80fd\u521b\u5efa\u4e00\u4e2a;</li> <li><code>clusterIP</code>\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a <code>true</code>\uff0c<code>Service CIDR</code> \u4f1a\u81ea\u52a8\u68c0\u6d4b</li> <li><code>nodeIP</code>\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a <code>true</code>\uff0c\u4f1a\u81ea\u52a8\u68c0\u6d4b <code>nodeIP</code> \u76f8\u5173\u53d8\u5316\uff0c\u5e76\u52a8\u6001\u66f4\u65b0\u5230 <code>EgressClusterInfo</code> \u7684 <code>status.nodeIP</code> \u4e2d</li> <li><code>podCidrMode</code>\uff0c\u76ee\u524d\u652f\u6301 <code>k8s</code>\u3001 <code>calico</code>\u3001<code>auto</code>\u3001 <code>\"\"</code>\uff0c\u8868\u793a\u8981\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684 podCidr\uff0c\u9ed8\u8ba4\u4e3a <code>auto</code>\uff0c\u5982\u679c\u4e3a <code>auto</code> \u8868\u793a\u81ea\u52a8\u68c0\u6d4b\u96c6\u7fa4\u4f7f\u7528\u7684 cni\uff0c \u5982\u679c\u68c0\u6d4b\u4e0d\u5230\uff0c\u5219\u4f7f\u7528 \u96c6\u7fa4\u7684 podCidr\u3002\u5982\u679c\u4e3a <code>\"\"</code> \u8868\u793a\u4e0d\u68c0\u6d4b</li> <li><code>extraCidr</code>\uff0c\u53ef\u624b\u52a8\u586b\u5199\u8981\u5ffd\u7565\u6389\u7684 <code>IP</code> \u96c6\u5408</li> <li><code>status.clusterIP</code>\uff0c\u5982\u679c <code>spec.autoDetect.clusterIP</code> \u4e3a <code>true</code>\uff0c\u5219\u81ea\u52a8\u68c0\u6d4b\u96c6\u7fa4 <code>Service CIDR</code>\uff0c\u5e76\u66f4\u65b0\u5230\u6b64\u5904</li> <li><code>status.extraCidr</code>\uff0c\u5bf9\u5e94 <code>spec.extraCidr</code> </li> <li><code>status.nodeIP</code>\uff0c\u5982\u679c <code>spec.autoDetect.nodeIP</code> \u4e3a <code>true</code>\uff0c\u5219\u81ea\u52a8\u68c0\u6d4b\u96c6\u7fa4 <code>nodeIP</code>\uff0c\u5e76\u66f4\u65b0\u5230\u6b64\u5904</li> <li><code>status.podCIDR</code>\uff0c\u5bf9\u5e94 <code>spec.autoDetect.podCidrMode</code>\uff0c\u8fdb\u884c\u76f8\u5173 <code>podCidr</code> \u7684\u66f4\u65b0</li> <li><code>status.podCidrMode</code>\uff0c\u5bf9\u5e94 <code>spec.autoDetect.podCidrMode</code> \u4e3a <code>auto</code> \u7684\u573a\u666f</li> </ol>"},{"location":"zh/reference/EgressClusterPolicy/","title":"CRD EgressClusterPolicy","text":"<p>EgressClusterPolicy CRD \u7528\u4e8e\u5b9a\u4e49\u96c6\u7fa4\u7ea7 Egress \u7b56\u7565\u89c4\u5219\uff0c\u4e0e EgressPolicy CRD \u7c7b\u4f3c\uff0c\u4f46\u589e\u52a0\u4e86 <code>spec.appliedTo.namespaceSelector</code> \u5b57\u6bb5\uff0c\u5176\u4ed6\u5b57\u6bb5\u4e0e EgressPolicy \u4e00\u81f4\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressClusterPolicy\nmetadata:\nname: \"policy-test\"\nspec:\npriority: 100\negressGatewayName: \"eg1\"\negressIP:\nipv4: \"\"\nipv6: \"\"\nuseNodeIP: false\nallocatorPolicy: default\nappliedTo:\npodSelector:\nmatchLabels:\napp: \"shopping\"\npodSubnet:\n- \"172.29.16.0/24\"\n- 'fd00:1/126'\nnamespaceSelector:   # (1)\nmatchLabels:\napp: \"shopping\"\ndestSubnet:\n- \"10.6.1.92/32\"\n- \"fd00::92/128\"\nstatus:\neip:\nipv4: 172.18.1.2\nipv6: fc00:f853:ccd::9\nnode: egressgateway-worker\n</code></pre>"},{"location":"zh/reference/EgressClusterPolicy/#_1","title":"\u5b9a\u4e49","text":""},{"location":"zh/reference/EgressClusterPolicy/#metadata","title":"metadata","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 namespace EgressPolicy \u8d44\u6e90\u7684\u547d\u540d\u7a7a\u95f4 \u5b57\u7b26\u4e32 \u5fc5\u586b name EgressPolicy \u8d44\u6e90\u7684\u540d\u79f0 \u5b57\u7b26\u4e32 \u5fc5\u586b"},{"location":"zh/reference/EgressClusterPolicy/#spec","title":"spec","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c egressGatewayName \u4f7f\u7528\u7684 EgressGateway \u7684\u5f15\u7528 \u5b57\u7b26\u4e32 \u5fc5\u586b egressIP \u51fa\u53e3 IP \u8bbe\u7f6e\u7684\u914d\u7f6e egressIP \u53ef\u9009 appliedTo \u5e94\u5c06 EgressPolicy \u5e94\u7528\u4e8e\u54ea\u4e9b Pods \u7684\u9009\u62e9\u5668 appliedTo \u5fc5\u586b destSubnet \u8bbf\u95ee\u8be5\u5217\u8868\u7684\u5b50\u7f51\u65f6\u4f7f\u7528 Egress IP\uff0c\u5982\u679c\u5b89\u88c5\u65f6\u5f00\u542f\u4e86 <code>feature.clusterCIDR.autoDetect</code>\uff0cdestSubnet \u6ca1\u8bbe\u7f6e\u65f6\uff0c\u5219\u8bbf\u95ee\u96c6\u7fa4\u5916\u7f51\u7edc\u81ea\u52a8\u4f7f\u7528 Egress IP\u3002 \u5b57\u7b26\u4e32\u6570\u7ec4 \u53ef\u9009 CIDR \u8868\u793a\u6cd5 priority \u7b56\u7565\u7684\u4f18\u5148\u7ea7 \u6574\u6570 \u53ef\u9009"},{"location":"zh/reference/EgressClusterPolicy/#egressip","title":"egressIP","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c ipv4 \u5982\u679c\u5b9a\u4e49\uff0c\u5219\u4f7f\u7528\u7279\u5b9a\u7684 IPv4 \u5730\u5740 string \u53ef\u9009 \u6709\u6548\u7684 IPv4 ipv6 \u5982\u679c\u5b9a\u4e49\uff0c\u5219\u4f7f\u7528\u7279\u5b9a\u7684 IPv6 \u5730\u5740 string \u53ef\u9009 \u6709\u6548\u7684 IPv6 useNodeIP \u5f53\u6ca1\u6709\u5b9a\u4e49\u7279\u5b9a\u7684 IP \u5730\u5740\u65f6\uff0c\u662f\u5426\u4f7f\u7528\u8282\u70b9 IP \u4f5c\u4e3a\u51fa\u53e3 IP \u7684\u6807\u5fd7 bool \u53ef\u9009 true/false false"},{"location":"zh/reference/EgressClusterPolicy/#appliedto","title":"appliedTo","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c podSelector \u901a\u8fc7 Selector \u5339\u914d\u5b9e\u65bd Egress \u7b56\u7565 Pod map[string]string \u53ef\u9009 podSubnet \u901a\u8fc7 Subnet \u5339\u914d\u5b9e\u65bd Egress \u7b56\u7565 Pod\uff08\u672a\u5b9e\u73b0\uff09 []string \u53ef\u9009 CIDR namespaceSelector <code>namespaceSelector</code> \u4f7f\u7528\u9009\u62e9\u5668\u6765\u9009\u62e9\u5339\u914d\u7684\u547d\u540d\u7a7a\u95f4\u5217\u8868\u3002\u5728\u9009\u5b9a\u7684\u547d\u540d\u7a7a\u95f4\u8303\u56f4\u5185\uff0c\u4f7f\u7528 <code>podSelector</code> \u9009\u62e9\u5339\u914d\u7684 Pods\uff0c\u7136\u540e\u5c06 Egress \u7b56\u7565\u5e94\u7528\u5230\u8fd9\u4e9b\u9009\u5b9a\u7684 Pods \u4e0a\u3002"},{"location":"zh/reference/EgressEndpointSlice/","title":"CRD EgressEndpointSlice","text":"<p>EgressEndpointSlice CRD \u7528\u4e8e\u805a\u5408 EgressPolicy \u6240\u5339\u914d\u4e2d\u7684 Pods \u5730\u5740\u4fe1\u606f\uff0c\u6b64\u8d44\u6e90\u4ec5\u4f9b\u5185\u90e8\u4f7f\u7528\uff0c\u7528\u4e8e\u63d0\u5347\u63a7\u5236\u9762\u7684\u6027\u80fd\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressEndpointSlice\nmetadata:\ngenerateName: ns-policy-\nlabels:\nspidernet.io/policy-name: ns-policy          # (1)\nname: ns-policy-zp667\nnamespace: default\nownerReferences:\n- apiVersion: egressgateway.spidernet.io/v1beta1  # (2)\nblockOwnerDeletion: true\ncontroller: true\nkind: EgressPolicy\nname: ns-policy\nuid: fdca1dd5-9c3b-4d58-b043-451e10f15ea8\nendpoints:                                             # (3)\n- ipv4:\n- 10.21.60.74                                    # (4)\nipv6:\n- fd00:21::5328:9c2:3579:8cca                    # (5)\nnode: workstation3                                 # (6)\nns: ns1                                            # (7)\npod: ns2-mock-app-5c4cd6bb87-g4fdj                 # (8)\n</code></pre> <ol> <li>\u6b64\u6807\u7b7e\u503c\u8868\u793a EgressEndpointSlice \u6240\u5c5e\u7684 EgressPolicy\u3002</li> <li>\u901a\u8fc7\u4f7f\u7528 <code>ownerReferences</code>\uff0c\u8be5 CRD \u4e0e\u5176\u7236\u8d44\u6e90\u5173\u8054\uff0c\u5b9e\u73b0 EgressPolicy \u5220\u9664\u65f6\u81ea\u52a8\u56de\u6536 EgressEndpointSlice \u529f\u80fd\u3002</li> <li>EgressEndpointSlice \u5bf9\u8c61\u7528\u4e8e\u6c47\u603b EgressPolicy \u5339\u914d\u5230\u7684 Pods \u5730\u5740\u4fe1\u606f\uff0c\u9ed8\u8ba4\u5728\u8d85\u8fc7 100 \u4e2a\u5339\u914d\u7ed3\u679c\u65f6\uff0c\u5c06\u521b\u5efa\u65b0\u7684 EgressEndpointSlice\u3002</li> <li>Pods \u7684 IPv4 \u5730\u5740\u5217\u8868\u3002</li> <li>Pods \u7684 IPv6 \u5730\u5740\u5217\u8868\u3002</li> <li>Pods \u6240\u5728\u8282\u70b9\u7684\u4fe1\u606f\u3002</li> <li>Pods \u6240\u5c5e\u79df\u6237\u7684\u4fe1\u606f\u3002</li> <li>Pods \u7684\u540d\u79f0\u3002</li> </ol>"},{"location":"zh/reference/EgressGateway/","title":"CRD EgressGateway","text":"<p>EgressGateway CRD \u7528\u4e8e\u9009\u62e9\u4e00\u7ec4\u8282\u70b9\u4f5c\u4e3a\u96c6\u7fa4\u7684 Egress \u8282\u70b9\uff0c\u5e76\u4e3a\u8be5\u8282\u70b9\u7ec4\u914d\u7f6e Egress IP \u6c60\u3002Egress IP \u53ef\u5728\u6b64\u7ec4\u8282\u70b9\u5185\u6d6e\u52a8\u3002\u96c6\u7fa4\u7ea7\u8d44\u6e90\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\nname: \"eg1\"\nspec:\nippools:                      # (1)\nipv4:                       # (2)\n- \"10.6.1.55\"\n- \"10.6.1.60-10.6.1.65\"\n- \"10.6.1.70/28\"\nipv6:                       # (3)\n- \"\"\nipv4DefaultEIP: \"\"          # (4)\nipv6DefaultEIP: \"\"          # (5)\nnodeSelector:                 # (6)\nselector:                   # (7)\nmatchLabels:\negress: \"true\"\npolicy: \"doing\"             # (8)\nclusterDefault: false         # (9)\nstatus:                         nodeList:                     # (10)\n- name: \"node1\"             # (11)\nstatus: \"Ready\"           # (12)\nepis:                     # (13)\n- ipv4: \"10.6.1.55\"     # (14)\nipv6: \"fd00::55\"      # (15)\npolicies:             # (16)\n- name: \"app\"         # (17)\nnamespace: \"default\"  # (18)\n</code></pre> <ol> <li>\u8bbe\u7f6e EgressGateway \u53ef\u4f7f\u7528\u7684 Egress IP \u6c60\u7684\u8303\u56f4\uff1b</li> <li>Egress IPv4 \u6c60\uff0c\u652f\u6301\u4e09\u79cd\u65b9\u6cd5\uff1a\u5355\u4e2a IP <code>10.6.0.1</code>\u3001\u8303\u56f4 <code>10.6.0.1-10.6.0.10</code> \u548c CIDR <code>10.6.0.1/26</code>\uff1b</li> <li>Egress IPv6 \u6c60\uff0c\u5982\u679c\u542f\u7528\u4e86\u53cc\u6808\u8981\u6c42\uff0c\u5219 IPv4 \u548c IPv6 \u7684\u6570\u91cf\u5fc5\u987b\u4e00\u81f4\uff0c\u683c\u5f0f\u4e0e IPv4 \u76f8\u540c\uff1b</li> <li>\u8981\u4f7f\u7528\u7684\u9ed8\u8ba4 IPv4 EIP\u3002\u5982\u679c EgressPolicy \u6ca1\u6709\u6307\u5b9a EIP\uff0c\u4e14 EIP \u5206\u914d\u7b56\u7565\u4e3a <code>default</code>\uff0c\u5219\u5206\u914d\u7ed9\u8be5 EgressPolicy \u7684 EIP \u5c06\u662f <code>ipv4DefaultEIP</code>\uff1b</li> <li>\u8981\u4f7f\u7528\u7684\u9ed8\u8ba4 IPv6 EIP\uff0c\u89c4\u5219\u4e0e <code>ipv6DefaultEIP</code> \u76f8\u540c\uff1b</li> <li>\u8bbe\u7f6e Egress \u8282\u70b9\u7684\u5339\u914d\u6761\u4ef6\u548c\u7b56\u7565\uff1b</li> <li>\u901a\u8fc7 Selector \u9009\u62e9\u4e00\u7ec4\u8282\u70b9\u4f5c\u4e3a Egress \u8282\u70b9\uff0cEgress IP \u53ef\u5728\u6b64\u8303\u56f4\u5185\u6d6e\u52a8\uff1b</li> <li>EgressGateway \u9009\u62e9 Egress \u8282\u70b9\u7684\u7b56\u7565\uff0c\u76ee\u524d\u4ec5\u652f\u6301\u5e73\u5747\u9009\u62e9\uff1b</li> <li>\u9ed8\u8ba4\u4e3a <code>false</code>\uff0c\u5f53\u4e3a <code>true</code> \u65f6\uff0c\u4f5c\u4e3a\u5168\u5c40\u552f\u4e00\u7684\u9ed8\u8ba4 egw\u3002</li> <li>\u8282\u70b9\u9009\u62e9\u5668\u9009\u62e9\u7684 Egress \u8282\u70b9\uff0c\u4ee5\u53ca\u8282\u70b9\u4e0a\u6709\u6548\u7684 Egress IP\uff0c\u4ee5\u53ca\u4f7f\u7528\u8be5 Egress IP \u7684 EgressPolicy\uff1b</li> <li>Egress \u8282\u70b9\u7684\u540d\u79f0\uff1b</li> <li>Egress \u8282\u70b9\u5bf9\u5e94\u7684 EgressTunnel \u5bf9\u8c61\u7684\u72b6\u6001\uff1b</li> <li>\u6b64 Egress \u8282\u70b9\u4e0a\u6709\u6548\u7684 EIP \u4fe1\u606f\uff1b</li> <li>Egress IPv4\uff0c\u5982\u679c EgressPolicy \u548c EgressClusterPolicy \u4f7f\u7528\u8282\u70b9 IP\uff0c\u5219\u6b64\u5b57\u6bb5\u4e3a\u7a7a\uff1b</li> <li>Egress IPv6\uff0c\u5728\u53cc\u6808\u60c5\u51b5\u4e0b\uff0cIPv4 \u548c IPv6 \u4e00\u4e00\u5bf9\u5e94\uff1b</li> <li>\u54ea\u4e9b\u7b56\u7565\u4f7f\u7528\u6b64\u8282\u70b9\u4e0a\u7684\u6709\u6548 Egress IP\uff1b</li> <li>\u4f7f\u7528 Egress IP \u7684\u7b56\u7565\u540d\u79f0\uff1b</li> <li>\u4f7f\u7528 Egress IP \u7684\u7b56\u7565\u7684\u547d\u540d\u7a7a\u95f4\u3002</li> </ol>"},{"location":"zh/reference/EgressGateway/#_1","title":"\u5b9a\u4e49","text":""},{"location":"zh/reference/EgressGateway/#metadata","title":"metadata","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 name \u8fd9\u4e2a EgressGateway \u8d44\u6e90\u7684\u540d\u79f0 string \u5fc5\u586b"},{"location":"zh/reference/EgressGateway/#spec","title":"spec","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c ippools EgressGateway \u7684 IP \u6c60 ippools \u53ef\u9009 nodeSelector \u901a\u8fc7\u6807\u7b7e\u5339\u914d\u51fa\u53e3\u8282\u70b9 nodeSelector \u5fc5\u586b clusterDefault \u96c6\u7fa4\u7684\u9ed8\u8ba4 EgressGateway bool \u53ef\u9009 true/false false"},{"location":"zh/reference/EgressGateway/#ippools","title":"ippools","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c ipv4 IPv4 \u6c60 []string \u53ef\u9009 <code>10.6.0.1</code> <code>10.6.0.1-10.6.0.10</code> <code>10.6.0.1/26</code> ipv6 IPv6 \u6c60 []string \u53ef\u9009 <code>fd::01</code> <code>fd01::01-fd01:0a</code> <code>fd10:01/64</code> ipv4DefaultEIP \u9ed8\u8ba4\u51fa\u53e3 IPv4 string \u53ef\u9009 ipv6DefaultEIP \u9ed8\u8ba4\u51fa\u53e3 IPv6 string \u53ef\u9009"},{"location":"zh/reference/EgressGateway/#nodeselector","title":"nodeSelector","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c selector.matchLabels \u8282\u70b9\u5339\u914d\u6807\u7b7e map[string]string \u53ef\u9009"},{"location":"zh/reference/EgressGateway/#status","title":"status\uff08\u5b50\u8d44\u6e90\uff09","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c nodeList \u5339\u914d\u7684\u8282\u70b9\u5217\u8868 nodeList \u53ef\u9009"},{"location":"zh/reference/EgressGateway/#nodelist","title":"nodeList","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c name \u8282\u70b9\u7684\u540d\u79f0 string \u53ef\u9009 status \u8282\u70b9\u7684\u5f53\u524d\u72b6\u6001 string \u53ef\u9009 <code>Ready</code>, <code>NotReady</code> epis \u8282\u70b9\u7684\u7aef\u70b9 IP \u5217\u8868 epis \u53ef\u9009"},{"location":"zh/reference/EgressGateway/#epis","title":"epis","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c ipv4 \u8282\u70b9\u7684 IPv4 \u5730\u5740 string \u53ef\u9009 ipv6 \u8282\u70b9\u7684 IPv6 \u5730\u5740 string \u53ef\u9009 policies \u8282\u70b9\u7684\u7b56\u7565\u5217\u8868 policies \u53ef\u9009"},{"location":"zh/reference/EgressGateway/#policies","title":"policies","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c name \u4f7f\u7528 Egress IP \u7684\u7b56\u7565\u540d\u79f0 string \u53ef\u9009 namespace \u4f7f\u7528 Egress IP \u7684\u7b56\u7565\u7684\u547d\u540d\u7a7a\u95f4 string \u53ef\u9009"},{"location":"zh/reference/EgressPolicy/","title":"CRD EgressPolicy","text":"<p>EgressPolicy CRD \u7528\u4e8e\u6307\u5b9a\u54ea\u4e9b Pod \u8bbf\u95ee\u54ea\u4e9b\u76ee\u6807 CIDR \u65f6\u8d70 Egress \u7b56\u7565\uff0c\u4ee5\u53ca Egress \u6240\u4f7f\u7528\u7684 IP \u5730\u5740\u3002\u79df\u6237\u7ea7\u8d44\u6e90\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nnamespace: \"default\"\nname: \"policy-test\"\nspec:\negressGatewayName: \"eg1\"    egressIP:                   ipv4: \"\"                            ipv6: \"\"\nuseNodeIP: false          allocatorPolicy: default  appliedTo:                podSelector:             matchLabels:    app: \"shopping\"\npodSubnet:                - \"172.29.16.0/24\"\n- 'fd00:1/126'\ndestSubnet:                - \"10.6.1.92/32\"\n- \"fd00::92/128\"\npriority: 100              status:\neip:                        ipv4: 172.18.1.2\nipv6: fc00:f853:ccd::9\nnode: egressgateway-worker  </code></pre>"},{"location":"zh/reference/EgressPolicy/#_1","title":"\u5b9a\u4e49","text":""},{"location":"zh/reference/EgressPolicy/#metadata","title":"metadata","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 namespace EgressPolicy \u8d44\u6e90\u7684\u547d\u540d\u7a7a\u95f4 \u5b57\u7b26\u4e32 \u5fc5\u586b name EgressPolicy \u8d44\u6e90\u7684\u540d\u79f0 \u5b57\u7b26\u4e32 \u5fc5\u586b"},{"location":"zh/reference/EgressPolicy/#spec","title":"spec","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c egressGatewayName \u4f7f\u7528\u7684 EgressGateway \u7684\u5f15\u7528 \u5b57\u7b26\u4e32 \u5fc5\u586b egressIP \u51fa\u53e3 IP \u8bbe\u7f6e\u7684\u914d\u7f6e egressIP \u53ef\u9009 appliedTo \u5e94\u5c06 EgressPolicy \u5e94\u7528\u4e8e\u54ea\u4e9b Pods \u7684\u9009\u62e9\u5668 appliedTo \u5fc5\u586b destSubnet \u8bbf\u95ee\u8be5\u5217\u8868\u7684\u5b50\u7f51\u65f6\u4f7f\u7528 Egress IP\uff0c\u5982\u679c\u5b89\u88c5\u65f6\u5f00\u542f\u4e86 <code>feature.clusterCIDR.autoDetect</code>\uff0cdestSubnet \u6ca1\u8bbe\u7f6e\u65f6\uff0c\u5219\u8bbf\u95ee\u96c6\u7fa4\u5916\u7f51\u7edc\u81ea\u52a8\u4f7f\u7528 Egress IP\u3002 \u5b57\u7b26\u4e32\u6570\u7ec4 \u53ef\u9009 CIDR \u8868\u793a\u6cd5 priority \u7b56\u7565\u7684\u4f18\u5148\u7ea7 \u6574\u6570 \u53ef\u9009"},{"location":"zh/reference/EgressPolicy/#egressip","title":"egressIP","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c ipv4 \u5982\u679c\u5b9a\u4e49\uff0c\u5219\u4f7f\u7528\u7279\u5b9a\u7684 IPv4 \u5730\u5740 string \u53ef\u9009 \u6709\u6548\u7684 IPv4 ipv6 \u5982\u679c\u5b9a\u4e49\uff0c\u5219\u4f7f\u7528\u7279\u5b9a\u7684 IPv6 \u5730\u5740 string \u53ef\u9009 \u6709\u6548\u7684 IPv6 useNodeIP \u5f53\u6ca1\u6709\u5b9a\u4e49\u7279\u5b9a\u7684 IP \u5730\u5740\u65f6\uff0c\u662f\u5426\u4f7f\u7528\u8282\u70b9 IP \u4f5c\u4e3a\u51fa\u53e3 IP \u7684\u6807\u5fd7 bool \u53ef\u9009 true/false false"},{"location":"zh/reference/EgressPolicy/#appliedto","title":"appliedTo","text":"\u5b57\u6bb5 \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u9a8c\u8bc1 \u53ef\u9009\u503c \u9ed8\u8ba4\u503c podSelector \u901a\u8fc7 Selector \u5339\u914d\u5b9e\u65bd Egress \u7b56\u7565 Pod map[string]string \u53ef\u9009 podSubnet \u901a\u8fc7 Subnet \u5339\u914d\u5b9e\u65bd Egress \u7b56\u7565 Pod\uff08\u672a\u5b9e\u73b0\uff09 []string \u53ef\u9009 CIDR"},{"location":"zh/reference/EgressTunnel/","title":"CRD EgressTunnel","text":"<p>EgressTunnel CRD \u7528\u4e8e\u8bb0\u5f55\u8de8\u8282\u70b9\u901a\u4fe1\u7684\u96a7\u9053\u7f51\u5361\u4fe1\u606f\u3002\u8fd9\u662f\u4e00\u4e2a\u96c6\u7fa4\u7ea7\u8d44\u6e90\uff0c\u5b83\u4e0e Kubernetes Node \u8d44\u6e90\u540d\u79f0\u4e00\u4e00\u5bf9\u5e94\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressTunnel\nmetadata:\nname: \"node1\"\nstatus:\ntunnel:\nipv4: \"192.200.222.157\"  # (1)\nipv6: \"fd01::f2\"         # (2)        \nmac: \"66:50:85:cb:b2:bf\" # (3)\nparent:\nname: \"ens160\"        # (4)\nipv4: \"10.6.1.21/16\"  # (5)\nipv6: \"fd00::21/112\"  # (6)\nphase: \"Ready\"              # (7)\nmark: \"0x26000000\"          # (8)\n</code></pre> <ol> <li>\u96a7\u9053 IPv4 \u5730\u5740</li> <li>\u96a7\u9053 IPv6 \u5730\u5740</li> <li>\u96a7\u9053 MAC \u5730\u5740</li> <li>\u96a7\u9053\u7236\u7f51\u5361</li> <li>\u96a7\u9053\u7236\u7f51\u5361 IPv4 \u5730\u5740</li> <li>\u96a7\u9053\u7236\u7f51\u5361 IPv6 \u5730\u5740</li> <li>\u5f53\u524d\u96a7\u9053\u72b6\u6001<ul> <li><code>Pending</code>\uff1a\u7b49\u5f85\u5206\u914d IP</li> <li><code>Init</code>\uff1a\u5206\u914d\u96a7\u9053 IP \u6210\u529f</li> <li><code>Ready</code>\uff1a\u96a7\u9053 IP \u5df2\u5206\u914d\uff0c\u4e14\u96a7\u9053\u5df2\u5efa\u6210</li> <li><code>Failed</code>\uff1a\u96a7\u9053 IP \u5206\u914d\u5931\u8d25</li> <li><code>HeartbeatTimeout</code> Agent \u5fc3\u8df3\u8d85\u65f6</li> <li><code>NodeNotReady</code> Node \u72b6\u6001\u5904\u4e8e NotReady</li> </ul> </li> <li>\u6570\u636e\u5305 mark \u503c\uff0c\u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u4e00\u4e2a\u3002\u4f8b\u5982\u8282\u70b9 A \u6709 Egress \u6d41\u91cf\u9700\u8981\u8f6c\u53d1\u5230\u7f51\u5173\u8282\u70b9 B\uff0c\u4f1a\u5bf9 A \u8282\u70b9\u7684\u6d41\u91cf\u6253 mark \u8fdb\u884c\u6807\u8bb0\u3002</li> </ol>"},{"location":"zh/reference/egctl/","title":"egctl \u547d\u4ee4\u884c\u5de5\u5177\u8bf4\u660e","text":"<p><code>egctl</code> \u662f\u4e00\u4e2a\u547d\u4ee4\u884c\u5de5\u5177\uff0c\u7528\u4e8e\u7ba1\u7406 EgressGateway \u76f8\u5173\u8d44\u6e90\u3002</p>"},{"location":"zh/reference/egctl/#_1","title":"\u547d\u4ee4\u6982\u8ff0","text":""},{"location":"zh/reference/egctl/#vip-move","title":"vip move","text":"<p>\u79fb\u52a8 VIP \u5230\u6307\u5b9a\u7684\u8282\u70b9\u3002</p> <ul> <li><code>--egressGatewayName</code>: \u6307\u5b9a EgressGateway \u7684\u540d\u79f0\u3002</li> <li><code>--vip</code>: \u60a8\u60f3\u8981\u79fb\u52a8\u7684 Egress IP \u5730\u5740\u3002</li> <li><code>--targetNode</code>: Egress IP \u5c06\u751f\u6548\u7684\u76ee\u6807 EgressGateway \u8282\u70b9\u7684\u540d\u79f0\u3002</li> </ul> <pre><code>egctl vip move --egressGatewayName &lt;egress-gateway-name&gt; --vip &lt;vip-address&gt; --targetNode &lt;node-name&gt;\n</code></pre>"},{"location":"zh/reference/metrics/","title":"metrics","text":"<p>\u672c\u7ae0\u8282\u5168\u9762\u4ecb\u7ecd\u4e86 EgressGateway \u5bfc\u51fa\u7684\u6240\u6709\u6307\u6807\uff0c\u5e76\u6839\u636e\u6307\u6807\u7c7b\u578b\u548c\u63cf\u8ff0\u89e3\u91ca\u4e86\u6bcf\u4e2a\u6307\u6807\u7684\u542b\u4e49\u3002</p>"},{"location":"zh/reference/metrics/#controller-metrics","title":"Controller metrics","text":"Name Type Description <code>certwatcher_read_certificate_errors_total</code> counter \u8bc1\u4e66\u8bfb\u53d6\u9519\u8bef\u603b\u6570 <code>certwatcher_read_certificate_total</code> counter \u8bc1\u4e66\u8bfb\u53d6\u603b\u6570 <code>controller_runtime_active_workers</code> gauge \u6bcf\u4e2a controller \u5f53\u524d\u4f7f\u7528\u7684\u5de5\u4f5c\u7ebf\u7a0b\u6570 <code>controller_runtime_max_concurrent_reconciles</code> gauge \u6bcf\u4e2a controller \u7684\u6700\u5927\u5e76\u53d1 reconcile \u6570\u91cf <code>controller_runtime_reconcile_errors_total</code> counter \u6bcf\u4e2a controller \u7684 reconcile \u9519\u8bef\u603b\u6570 <code>controller_runtime_reconcile_time_seconds</code> histogram \u6bcf\u4e2a controller \u7684\u5bf9\u8d26\u65f6\u95f4\u957f\u5ea6 <code>controller_runtime_reconcile_total</code> counter \u6bcf\u4e2a controller \u7684\u5bf9\u8d26\u603b\u6570 <code>controller_runtime_webhook_latency_seconds</code> histogram \u5904\u7406\u51c6\u5165\u8bf7\u6c42\u7684\u5ef6\u8fdf\u7684\u76f4\u65b9\u56fe <code>controller_runtime_webhook_requests_in_flight</code> gauge \u5f53\u524d\u6b63\u5728\u5904\u7406\u7684\u51c6\u5165\u8bf7\u6c42\u6570\u91cf <code>controller_runtime_webhook_requests_total</code> counter \u6309 HTTP \u72b6\u6001\u7801\u5206\u7c7b\u7684\u51c6\u5165\u8bf7\u6c42\u603b\u6570 <code>egress_ip_allocate_next_restore_calls</code> counter \u7528\u4e8e\u6062\u590d\u64cd\u4f5c\u7684IP\u5206\u914d\uff08allocate next\uff09\u8c03\u7528\u603b\u6570 <code>egress_ip_allocate_release_calls</code> counter IP\u91ca\u653e\uff08release\uff09\u8c03\u7528\u603b\u6570 <code>egress_mark_allocate_next_calls</code> counter \u6807\u8bb0\u5206\u914d\uff08mark allocate next\uff09\u8ba1\u6570\u8c03\u7528\u603b\u6570 <code>egress_mark_release_calls</code> counter \u6807\u8bb0\u91ca\u653e\uff08mark release\uff09\u8c03\u7528\u603b\u6570 <code>go_gc_duration_seconds</code> summary \u5783\u573e\u6536\u96c6\u5468\u671f\u6682\u505c\u65f6\u95f4\u7684\u603b\u7ed3 <code>go_goroutines</code> gauge \u5f53\u524d\u5b58\u5728\u7684goroutines\u6570\u91cf <code>go_info</code> gauge Go \u73af\u5883\u7684\u4fe1\u606f <code>go_memstats_alloc_bytes</code> gauge \u5df2\u5206\u914d\u4e14\u4ecd\u5728\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_alloc_bytes_total</code> counter \u603b\u5171\u5206\u914d\u7684\u5b57\u8282\u6570\uff0c\u5373\u4f7f\u5df2\u91ca\u653e <code>go_memstats_buck_hash_sys_bytes</code> gauge \u7531\u5206\u6790\u6876\u54c8\u5e0c\u8868\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_frees_total</code> counter \u603b\u91ca\u653e\u6b21\u6570 <code>go_memstats_gc_sys_bytes</code> gauge \u7528\u4e8e\u5783\u573e\u6536\u96c6\u7cfb\u7edf\u5143\u6570\u636e\u7684\u5b57\u8282\u6570 <code>go_memstats_heap_alloc_bytes</code> gauge \u5806\u4e0a\u5df2\u5206\u914d\u4e14\u4ecd\u5728\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_heap_idle_bytes</code> gauge \u7b49\u5f85\u4f7f\u7528\u7684\u5806\u5b57\u8282\u6570 <code>go_memstats_heap_inuse_bytes</code> gauge \u6b63\u5728\u4f7f\u7528\u7684\u5806\u5b57\u8282\u6570 <code>go_memstats_heap_objects</code> gauge \u5df2\u5206\u914d\u5bf9\u8c61\u7684\u6570\u91cf <code>go_memstats_heap_released_bytes</code> gauge \u91ca\u653e\u7ed9\u64cd\u4f5c\u7cfb\u7edf\u7684\u5806\u5b57\u8282\u6570 <code>go_memstats_heap_sys_bytes</code> gauge \u4ece\u7cfb\u7edf\u83b7\u5f97\u7684\u5806\u5b57\u8282\u6570 <code>go_memstats_last_gc_time_seconds</code> gauge \u4e0a\u6b21\u5783\u573e\u6536\u96c6\u4ee5\u6765\u7684\u79d2\u6570\uff08\u81ea 1970 \u5e74\u8d77\uff09 <code>go_memstats_lookups_total</code> counter \u6307\u9488\u67e5\u627e\u7684\u603b\u6570 <code>go_memstats_mallocs_total</code> counter mallocs \u7684\u603b\u6570 <code>go_memstats_mcache_inuse_bytes</code> gauge mcache \u7ed3\u6784\u6b63\u5728\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_mcache_sys_bytes</code> gauge \u4ece\u7cfb\u7edf\u83b7\u53d6\u7684\u7528\u4e8e mcache \u7ed3\u6784\u7684\u5b57\u8282\u6570 <code>go_memstats_mspan_inuse_bytes</code> gauge mspan \u7ed3\u6784\u6b63\u5728\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_mspan_sys_bytes</code> gauge \u4ece\u7cfb\u7edf\u83b7\u53d6\u7684\u7528\u4e8e mspan \u7ed3\u6784\u7684\u5b57\u8282\u6570 <code>go_memstats_next_gc_bytes</code> gauge \u4e0b\u6b21\u5783\u573e\u6536\u96c6\u5c06\u53d1\u751f\u65f6\u7684\u5806\u5b57\u8282\u6570 <code>go_memstats_other_sys_bytes</code> gauge \u7528\u4e8e\u5176\u4ed6\u7cfb\u7edf\u5206\u914d\u7684\u5b57\u8282\u6570 <code>go_memstats_stack_inuse_bytes</code> gauge \u6808\u5206\u914d\u5668\u6b63\u5728\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_stack_sys_bytes</code> gauge \u4ece\u7cfb\u7edf\u83b7\u5f97\u7684\u7528\u4e8e\u6808\u5206\u914d\u5668\u7684\u5b57\u8282\u6570 <code>go_memstats_sys_bytes</code> gauge \u4ece\u7cfb\u7edf\u83b7\u5f97\u7684\u5b57\u8282\u6570 <code>go_threads</code> gauge \u521b\u5efa\u7684\u64cd\u4f5c\u7cfb\u7edf\u7ebf\u7a0b\u6570 <code>leader_election_master_status</code> gauge \u62a5\u544a\u7cfb\u7edf\u662f\u5426\u4e3a\u591a\u526f\u672c\u9009\u4e3e\u4e3b\u8282\u70b9\uff0c0 \u8868\u793a\u5907\u4efd\uff0c1 \u8868\u793a <code>process_cpu_seconds_total</code> counter \u5728\u79d2\u5185\u6d88\u8017\u7684\u603b\u7528\u6237\u548c\u7cfb\u7edf CPU \u65f6\u95f4 <code>process_max_fds</code> gauge \u6700\u5927\u6253\u5f00\u6587\u4ef6\u63cf\u8ff0\u7b26\u6570\u91cf <code>process_open_fds</code> gauge \u6253\u5f00\u7684\u6587\u4ef6\u63cf\u8ff0\u7b26\u6570\u91cf <code>process_resident_memory_bytes</code> gauge \u5e38\u9a7b\u5185\u5b58\u5927\u5c0f\uff08\u5b57\u8282\uff09 <code>process_start_time_seconds</code> gauge \u8fdb\u7a0b\u81ea Unix \u7eaa\u5143\u4ee5\u6765\u7684\u542f\u52a8\u65f6\u95f4\uff08\u79d2\uff09 <code>process_virtual_memory_bytes</code> gauge \u865a\u62df\u5185\u5b58\u5927\u5c0f\uff08\u5b57\u8282\uff09 <code>process_virtual_memory_max_bytes</code> gauge \u53ef\u7528\u7684\u6700\u5927\u865a\u62df\u5185\u5b58\u91cf\uff08\u5b57\u8282\uff09 <code>rest_client_requests_total</code> counter \u6309\u72b6\u6001\u7801\u3001\u65b9\u6cd5\u548c\u4e3b\u673a\u5212\u5206\u7684 HTTP \u8bf7\u6c42\u6570\u91cf <code>workqueue_adds_total</code> counter \u7531\u5de5\u4f5c\u961f\u5217\u5904\u7406\u7684\u6dfb\u52a0\u64cd\u4f5c\u603b\u6570 <code>workqueue_depth</code> gauge \u5de5\u4f5c\u961f\u5217\u7684\u5f53\u524d\u6df1\u5ea6 <code>workqueue_longest_running_processor_seconds</code> gauge \u5de5\u4f5c\u961f\u5217\u4e2d\u6700\u957f\u8fd0\u884c\u5904\u7406\u5668\u8fd0\u884c\u7684\u79d2\u6570 <code>workqueue_queue_duration_seconds</code> histogram \u5de5\u4f5c\u961f\u5217\u4e2d\u7684\u5bf9\u8c61\u5728\u88ab\u8bf7\u6c42\u4e4b\u524d\u505c\u7559\u7684\u79d2\u6570 <code>workqueue_retries_total</code> counter \u7531\u5de5\u4f5c\u961f\u5217\u5904\u7406\u7684\u91cd\u8bd5\u603b\u6570 <code>workqueue_unfinished_work_seconds</code> gauge \u6b63\u5728\u8fdb\u884c\u4e14\u672a\u88ab work_duration \u89c2\u5bdf\u5230\u7684\u5de5\u4f5c\u79d2\u6570 <code>workqueue_work_duration_seconds</code> histogram \u4ece\u5de5\u4f5c\u961f\u5217\u5904\u7406\u4e00\u4e2a\u5bf9\u8c61\u6240\u9700\u7684\u79d2\u6570"},{"location":"zh/reference/metrics/#agent-metrics","title":"Agent metrics","text":"Name Type Description <code>certwatcher_read_certificate_errors_total</code> counter \u8bc1\u4e66\u8bfb\u53d6\u9519\u8bef\u603b\u6570 <code>certwatcher_read_certificate_total</code> counter \u8bc1\u4e66\u8bfb\u53d6\u603b\u6570 <code>controller_runtime_active_workers</code> gauge \u6bcf\u4e2a controller \u5f53\u524d\u4f7f\u7528\u7684\u5de5\u4f5c\u8005\u6570 <code>controller_runtime_max_concurrent_reconciles</code> gauge \u6bcf\u4e2a controller \u5141\u8bb8\u7684\u6700\u5927\u5e76\u53d1\u534f\u8c03\u6570 <code>controller_runtime_reconcile_errors_total</code> counter \u6bcf\u4e2a controller \u7684\u534f\u8c03\u9519\u8bef\u603b\u6570 <code>controller_runtime_reconcile_time_seconds</code> histogram \u6bcf\u4e2a controller \u6bcf\u6b21\u534f\u8c03\u7684\u65f6\u95f4\u957f\u5ea6 <code>controller_runtime_reconcile_total</code> counter \u6bcf\u4e2a controller \u7684\u534f\u8c03\u603b\u6570 <code>go_gc_duration_seconds</code> summary \u5783\u573e\u56de\u6536\u5468\u671f\u6682\u505c\u6301\u7eed\u65f6\u95f4\u7684\u6458\u8981 <code>go_goroutines</code> gauge \u5f53\u524d\u5b58\u5728\u7684 goroutine \u6570\u91cf <code>go_info</code> gauge Go \u73af\u5883\u4fe1\u606f <code>go_memstats_alloc_bytes</code> gauge \u5206\u914d\u4e14\u4ecd\u5728\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_alloc_bytes_total</code> counter \u5206\u914d\u7684\u603b\u5b57\u8282\u6570\uff0c\u5373\u4f7f\u5df2\u91ca\u653e <code>go_memstats_buck_hash_sys_bytes</code> gauge \u5206\u6790\u6876\u54c8\u5e0c\u8868\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_frees_total</code> counter \u91ca\u653e\u7684\u603b\u6b21\u6570 <code>go_memstats_gc_sys_bytes</code> gauge \u7528\u4e8e\u5783\u573e\u56de\u6536\u7cfb\u7edf\u5143\u6570\u636e\u7684\u5b57\u8282\u6570 <code>go_memstats_heap_alloc_bytes</code> gauge \u5806\u5206\u914d\u4e14\u4ecd\u5728\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_heap_idle_bytes</code> gauge \u7b49\u5f85\u4f7f\u7528\u7684\u5806\u5b57\u8282\u6570 <code>go_memstats_heap_inuse_bytes</code> gauge \u6b63\u5728\u4f7f\u7528\u7684\u5806\u5b57\u8282\u6570 <code>go_memstats_heap_objects</code> gauge \u5206\u914d\u7684\u5bf9\u8c61\u6570\u91cf <code>go_memstats_heap_released_bytes</code> gauge \u91ca\u653e\u7ed9\u64cd\u4f5c\u7cfb\u7edf\u7684\u5806\u5b57\u8282\u6570 <code>go_memstats_heap_sys_bytes</code> gauge \u4ece\u7cfb\u7edf\u83b7\u5f97\u7684\u5806\u5b57\u8282\u6570 <code>go_memstats_last_gc_time_seconds</code> gauge \u4e0a\u6b21\u5783\u573e\u56de\u6536\u4ee5\u6765\u7684\u79d2\u6570\uff08\u81ea1970\u5e74\u8d77\uff09 <code>go_memstats_lookups_total</code> counter \u6307\u9488\u67e5\u627e\u603b\u6570 <code>go_memstats_mallocs_total</code> counter malloc \u7684\u603b\u6b21\u6570 <code>go_memstats_mcache_inuse_bytes</code> gauge mcache \u7ed3\u6784\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_mcache_sys_bytes</code> gauge \u4ece\u7cfb\u7edf\u83b7\u5f97\u7684\u7528\u4e8e mcache \u7ed3\u6784\u7684\u5b57\u8282\u6570 <code>go_memstats_mspan_inuse_bytes</code> gauge mspan\u7ed3\u6784\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_mspan_sys_bytes</code> gauge \u4ece\u7cfb\u7edf\u83b7\u5f97\u7684\u7528\u4e8e mspan \u7ed3\u6784\u7684\u5b57\u8282\u6570 <code>go_memstats_next_gc_bytes</code> gauge \u4e0b\u4e00\u6b21\u5783\u573e\u56de\u6536\u5c06\u53d1\u751f\u65f6\u7684\u5806\u5b57\u8282\u6570 <code>go_memstats_other_sys_bytes</code> gauge \u7528\u4e8e\u5176\u4ed6\u7cfb\u7edf\u5206\u914d\u7684\u5b57\u8282\u6570 <code>go_memstats_stack_inuse_bytes</code> gauge \u5806\u6808\u5206\u914d\u5668\u4f7f\u7528\u7684\u5b57\u8282\u6570 <code>go_memstats_stack_sys_bytes</code> gauge \u4ece\u7cfb\u7edf\u4e3a\u5806\u6808\u5206\u914d\u5668\u83b7\u5f97\u7684\u5b57\u8282\u6570 <code>go_memstats_sys_bytes</code> gauge \u4ece\u7cfb\u7edf\u83b7\u5f97\u7684\u5b57\u8282\u6570 <code>go_threads</code> gauge \u521b\u5efa\u7684\u64cd\u4f5c\u7cfb\u7edf\u7ebf\u7a0b\u6570 <code>iptables_chains</code> gauge \u6d3b\u52a8\u7684 iptables \u94fe\u6570 <code>iptables_lines_executed</code> counter \u6267\u884c\u7684 iptables \u89c4\u5219\u66f4\u65b0\u6b21\u6570 <code>iptables_lock_acquire_secs</code> summary \u83b7\u53d6 iptables \u9501\u6240\u9700\u7684\u65f6\u95f4\uff08\u79d2\uff09 <code>iptables_lock_retries</code> counter iptables \u9501\u88ab\u4ed6\u4eba\u6301\u6709\u4e14\u9700\u8981\u91cd\u8bd5\u7684\u6b21\u6570 <code>iptables_restore_calls</code> counter iptables-restore \u8c03\u7528\u6b21\u6570 <code>iptables_restore_errors</code> counter iptables-restore \u9519\u8bef\u6570 <code>iptables_rules</code> gauge \u6d3b\u52a8\u7684 iptables \u89c4\u5219\u6570 <code>iptables_save_calls</code> counter iptables-save \u8c03\u7528\u6b21\u6570 <code>iptables_save_errors</code> counter iptables-save \u9519\u8bef\u6570 <code>process_cpu_seconds_total</code> counter \u7528\u6237\u548c\u7cfb\u7edf CPU \u65f6\u95f4\u603b\u8ba1\uff08\u79d2\uff09 <code>process_max_fds</code> gauge \u6700\u5927\u6253\u5f00\u6587\u4ef6\u63cf\u8ff0\u7b26\u6570 <code>process_open_fds</code> gauge \u6253\u5f00\u7684\u6587\u4ef6\u63cf\u8ff0\u7b26\u6570 <code>process_resident_memory_bytes</code> gauge \u5e38\u9a7b\u5185\u5b58\u5927\u5c0f\uff08\u5b57\u8282\uff09 <code>process_start_time_seconds</code> gauge \u8fdb\u7a0b\u81eaUnix\u7eaa\u5143\u8d77\u7684\u542f\u52a8\u65f6\u95f4\uff08\u79d2\uff09 <code>process_virtual_memory_bytes</code> gauge \u865a\u62df\u5185\u5b58\u5927\u5c0f\uff08\u5b57\u8282\uff09 <code>process_virtual_memory_max_bytes</code> gauge \u53ef\u7528\u7684\u6700\u5927\u865a\u62df\u5185\u5b58\u91cf\uff08\u5b57\u8282\uff09 <code>rest_client_requests_total</code> counter \u6309\u72b6\u6001\u7801\u3001\u65b9\u6cd5\u548c\u4e3b\u673a\u5212\u5206\u7684HTTP\u8bf7\u6c42\u603b\u6570 <code>workqueue_adds_total</code> counter workqueue \u5904\u7406\u7684\u6dfb\u52a0\u603b\u6570 <code>workqueue_depth</code> gauge workqueue \u7684\u5f53\u524d\u6df1\u5ea6 <code>workqueue_longest_running_processor_seconds</code> gauge workqueue \u4e2d\u8fd0\u884c\u65f6\u95f4\u6700\u957f\u7684\u5904\u7406\u5668\u5df2\u8fd0\u884c\u7684\u79d2\u6570 <code>workqueue_queue_duration_seconds</code> histogram \u5bf9\u8c61\u5728 workqueue \u4e2d\u505c\u7559\u540e\u88ab\u8bf7\u6c42\u7684\u79d2\u6570 <code>workqueue_retries_total</code> counter workqueue \u5904\u7406\u7684\u91cd\u8bd5\u603b\u6570 <code>workqueue_unfinished_work_seconds</code> gauge workqueue \u6b63\u5728\u8fdb\u884c\u7684\u5de5\u4f5c\u5df2\u8fdb\u884c\u7684\u79d2\u6570\uff0c\u4f46\u5c1a\u672a\u7531 work_duration \u89c2\u5bdf\u5230 <code>workqueue_work_duration_seconds</code> histogram \u4ece workqueue \u5904\u7406\u4e00\u4e2a\u5bf9\u8c61\u6240\u9700\u7684\u65f6\u95f4\uff08\u79d2\uff09"},{"location":"zh/usage/Aliyun/","title":"\u5728\u963f\u91cc\u4e91\u4e2d\u4f7f\u7528 EgressGateway","text":"<p>\u672c\u6587\u8bf4\u660e\u5982\u4f55\u5728\u963f\u91cc\u4e91\u4e2d\u4f7f\u7528 EgressGateway\u3002\u5728\u963f\u91cc\u4e91\u4e2d\uff0c\u7531\u4e8e\u963f\u91cc\u4e91\u7684 IP\uff08\u5305\u62ec\u5f39\u6027\u516c\u6709 IP\uff09\u548c\u8282\u70b9\u4e00\u4e00\u7ed1\u5b9a\uff0c\u65e0\u6cd5\u5b9e\u73b0 Egress IP \u5728\u8282\u70b9\u95f4\u6f02\u79fb\u7684\u529f\u80fd\u3002\u6211\u4eec\u5728\u4e0b\u6587\u4e2d\u4f7f\u7528\u8282\u70b9 IP \uff08\u975e\u6307\u5b9a ippool \u7684\u65b9\u5f0f\uff09\u4f5c\u4e3a Egress IP\uff0c\u4f7f\u7528\u8282\u70b9 IP \u4f5c\u4e3a Egress IP \u65f6\uff0c\u5982\u679c\u9009\u62e9\u591a\u4e2a\u8282\u70b9\u4f5c\u4e3a Egress \u7f51\u5173\u4ee5\u5b9e\u73b0 HA \u9ad8\u53ef\u7528\u65f6\uff0c\u82e5\u4e00\u4e2a\u8282\u70b9\u6302\u6389\u7684\u65f6\u5019\uff0cEgress IP \u5c06\u4f1a\u5207\u6362\u6210\u53e6\u4e00\u4e2a\u8282\u70b9\u7684 IP\u3002</p> <p>\u4f7f\u7528\u6848\u4f8b\u5982\u4e0b\uff1a</p> <ul> <li>\u5728 VPC \u7f51\u7edc\u7684\u4e1c\u897f\u5411\u8bbf\u95ee\u4e2d\uff0c\u6709 A \u548c B \u96c6\u7fa4\uff0c\u96c6\u7fa4 B \u8981\u6c42\u8bbf\u95ee\u8005\u7684\u7f51\u7edc IP \u5728\u767d\u540d\u5355\u5217\u8868\uff0c\u56e0\u6b64\u5728\u96c6\u7fa4 A \u90e8\u7f72 EgressGateway\uff0c\u4f7f\u8bbf\u95ee B \u96c6\u7fa4\u7684\u7f51\u7edc\u90fd\u662f\u7528 Egress IP\uff0c\u7528\u6b64 IP \u7684\u6d41\u91cf\u4f1a\u5728\u5916\u90e8\u5e94\u7528\u7279\u6b8a\u7684\u7b56\u7565\u3002</li> <li>\u5728 VPC \u7f51\u7edc\u5357\u5317\u5411\u7f51\u7edc\u8bbf\u95ee\u573a\u666f\u4e2d\uff0c\u96c6\u7fa4\u4e1a\u52a1\u8282\u6709\u9700\u8981\u8bbf\u95ee\u4e92\u8054\u7f51\uff0c\u4f46\u4e1a\u52a1\u8282\u70b9\u4e0d\u8d2d\u4e70\u516c\u6709 IP\uff0c\u9700\u8981\u8bbf\u95ee\u5916\u90e8\u7f51\u7edc\u7684 Pod \u53ef\u901a\u8fc7\u96c6\u7fa4\u5185\u7684 Egress \u8282\u70b9\u7684\u7ed1\u5b9a\u7684\u516c\u7f51 IP \u5b9e\u73b0\u8fde\u63a5\u5916\u90e8\u7f51\u7edc\u3002</li> </ul>"},{"location":"zh/usage/Aliyun/#_1","title":"\u8981\u6c42","text":"<ul> <li>Kubernetes \u96c6\u7fa4\u81f3\u5c11 2 \u4e2a\u8282\u70b9</li> <li>\u5df2\u7ecf\u5b89\u88c5 Calico \u7f51\u7edc\u7ec4\u4ef6</li> </ul>"},{"location":"zh/usage/Aliyun/#egressgateway_1","title":"\u5b89\u88c5 EgressGateway","text":"<p>\u5b89\u88c5\u524d\u8bbe\u7f6e Calico \u7684 iptables \u6a21\u5f0f\u4e3a Append\u3002</p> <p>\u5982\u679c\u60a8\u662f\u901a\u8fc7 YAML \u5b89\u88c5\u7684 Calico\uff0c\u5219\u5e94\u8be5\u6267\u884c\u4e0b\u9762\u547d\u4ee4\uff1a <pre><code>kubectl set env daemonset -n calico-system calico-node FELIX_CHAININSERTMODE=Append\n</code></pre></p> <p>\u5982\u679c\u60a8\u662f\u901a\u8fc7 Calico Operator \u7ba1\u7406 Calico \u5219\u5e94\u8be5\u6267\u884c\u4e0b\u9762\u547d\u4ee4\uff1a <pre><code>kubectl patch felixconfigurations  default --type='merge' -p '{\"spec\":{\"chainInsertMode\":\"Append\"}}'\n</code></pre></p> <p>\u6dfb\u52a0 Helm \u4ed3\u5e93\u3002</p> <pre><code>helm repo add egressgateway https://spidernet-io.github.io/egressgateway/\nhelm repo update\n</code></pre> <p>\u901a\u8fc7 helm \u5b89\u88c5 EgressGateway\u3002</p> <pre><code>helm install egress --wait --debug egressgateway/egressgateway\n</code></pre> <p>\u68c0\u67e5\u6240\u6709 Pod \u662f\u5426\u5904\u4e8e Running \u72b6\u6001\u3002</p> <pre><code>root@node1:~# kubectl get pods -A | grep egressgateway\ndefault    egressgateway-agent-lkglz                  1/1     Running   0    86m\ndefault    egressgateway-agent-s5xwk                  1/1     Running   0    86m\ndefault    egressgateway-controller-6cd86df57-xm2d4   1/1     Running   0    86m\n</code></pre>"},{"location":"zh/usage/Aliyun/#_2","title":"\u90e8\u7f72\u6d4b\u8bd5\u670d\u52a1","text":"<p>\u6211\u4eec\u65b0\u521b\u5efa\u4e00\u53f0\u673a\u5668\uff0c\u4f5c\u4e3a VPC \u7f51\u7edc\u4e1c\u897f\u5411\u7684\u670d\u52a1\u5668\uff0c\u5728\u8fd9\u91cc\u6211\u542f\u52a8\u7684\u673a\u5668 IP \u4e3a <code>172.17.81.29</code>\u3002</p> <p></p> <p>\u8fd0\u884c\u4e0b\u9762\u547d\u4ee4\u542f\u52a8\u6d4b\u8bd5\u670d\u52a1\u5668\uff0c\u4ed6\u7684\u529f\u80fd\u662f <code>curl ip:8080</code>\uff0c\u5b83\u4f1a\u8fd4\u56de\u5ba2\u6237\u7aef\u7684 IP \u5730\u5740\uff0c\u53ef\u4ee5\u4f9b\u6211\u4eec\u68c0\u67e5 Egress IP \u8fd0\u4f5c\u662f\u5426\u6b63\u5e38\u3002</p> <pre><code>docker run -d --net=host ghcr.io/spidernet-io/egressgateway-nettools:latest /usr/bin/nettools-server -protocol web -webPort 8080\n</code></pre>"},{"location":"zh/usage/Aliyun/#pod","title":"\u521b\u5efa\u6d4b\u8bd5 Pod","text":"<p>\u67e5\u770b\u6211\u4eec\u5f53\u524d\u96c6\u7fa4\u7684\u8282\u70b9\u3002</p> <pre><code>$ kubectl get nodes\nNAME    STATUS   ROLES           AGE   VERSION\nnode1   Ready    control-plane   66m   v1.30.0\nnode2   Ready    &lt;none&gt;          66m   v1.30.0\n</code></pre> <p>\u5728\u8fd9\u91cc\u6211\u4eec\u5c06 Pod\uff0c\u90e8\u7f72\u5230 node1 \u8282\u70b9\uff0c\u7a0d\u540e\u6211\u4eec\u5c06 EgressGateway \u7684\u80fd\u529b\u5b9e\u73b0\uff0cnode1 \u7684 Pod \u8df3\u5230 node2 \u8282\u70b9\uff0c\u5e76\u4f7f\u7528 node2 \u7684 IP \u8bbf\u95ee\u5916\u90e8\u7f51\u7edc\u3002</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: nginx\nlabels:\napp: nginx\nspec:\ncontainers:\n- image: nginx\nimagePullPolicy: IfNotPresent\nname: nginx\nresources: {}\nnodeName: node1\n</code></pre> <p>\u67e5\u770b Pod \u662f\u5426\u5904\u4e8e Running \u72b6\u6001\u3002</p> <pre><code>root@node1:~# kubectl get pods -o wide | grep nginx\nnginx  1/1  Running  0  77m  10.200.166.133  node1  &lt;none&gt;  &lt;none&gt;\n</code></pre>"},{"location":"zh/usage/Aliyun/#egressgateway-cr","title":"\u521b\u5efa EgressGateway CR","text":"<p>EgressGateway \u7684 CR \u7684\u4f5c\u7528\u662f\u53ef\u4ee5\u9009\u62e9\u96c6\u7fa4\u7684\u4e00\u7ec4\u8282\u70b9\u4f5c\u4e3a Egress \u51fa\u53e3\u7f51\u5173\u3002\u5728\u4e0b\u9762\u7684\u5b9a\u4e49\u4e2d\uff0c<code>nodeSelector</code> \u5c06\u5339\u914d node2 \u4f5c\u4e3a Egress \u7f51\u5173\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\n  name: \"egressgateway\"\nspec:\n  nodeSelector:\n    selector:\n      matchLabels:\n        egress: \"true\"\n</code></pre>"},{"location":"zh/usage/Aliyun/#egress","title":"\u9009\u62e9\u4e00\u4e2a\u8282\u70b9\u4f5c\u4e3a Egress \u51fa\u53e3","text":"<p>\u67e5\u770b\u6211\u4eec\u5f53\u524d\u96c6\u7fa4\u7684\u8282\u70b9\u3002\u6211\u7684 node2 \u7684 Public IP \u662f <code>8.217.200.161</code>\u3002</p> <pre><code>$ kubectl get nodes\nNAME    STATUS   ROLES           AGE   VERSION\nnode1   Ready    control-plane   66m   v1.30.0\nnode2   Ready    &lt;none&gt;          66m   v1.30.0\n</code></pre> <p>\u5728\u8fd9\u91cc\u6211\u4eec node2 \u6253\u6807\u7b7e\uff0c\u4ee5\u4f7f\u5176\u88ab\u6211\u4eec\u4e0a\u9762\u7684 EgressGateway \u5339\u914d\u4e2d\u3002</p> <pre><code>kubectl label node node2 egress=true\n</code></pre> <p>\u5f53\u4f7f\u7528 <code>kubectl label</code> \u7ed9\u8282\u70b9\u6253\u6807\u7b7e\u540e\uff0c\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u547d\u4ee4\u83b7\u53d6 EgressGateway CR \u67e5\u770b <code>status.nodeList</code> \u5217\u8868 \u662f\u5426\u5b58\u5728\u521a\u624d\u6807\u8bb0\u7684 node2 \u7684\u8282\u70b9\u3002</p> <pre><code>$ kubectl get egw egressgateway -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\n  name: egressgateway\nspec:\n  nodeSelector:\n    selector:\n      matchLabels:\n        egress: \"true\"\nstatus:\n  nodeList:\n  - name: node2\n    status: Ready\n</code></pre>"},{"location":"zh/usage/Aliyun/#egresspolicy","title":"\u521b\u5efa EgressPolicy","text":"<p>EgressPolicy CR \u7684\u4f5c\u7528\u662f\u5339\u914d Pod\uff0c\u88ab\u5339\u914d\u4e2d\u7684 Pod \u7684\u6d41\u91cf\uff0c\u4f1a\u901a\u8fc7 Egress \u7f51\u5173\u79bb\u5f00\u96c6\u7fa4\u3002 \u5728\u4e0b\u9762 EgressPolicy \u7684\u5b9a\u4e49\u4e2d\uff0c<code>34.117.186.192</code> \u662f <code>ipinfo.io</code> \u7684\u5730\u5740\uff0c\u53ef\u4ee5\u901a\u8fc7 <code>dig ipinfo.io</code> \u83b7\u5f97\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nname: nginx-egress-policy\nspec:\negressGatewayName: egressgateway\negressIP:\nuseNodeIP: true\nappliedTo:\npodSelector:\nmatchLabels:\napp: nginx\ndestSubnet:\n- 172.17.81.29/32   # \u4e1c\u897f\u5411\u6d4b\u8bd5\u670d\u52a1\u7684 IP\n- 34.117.186.192/32 # ipinfo.io \u7684\u5730\u5740\uff0c\u7528\u4e8e\u96c6\u7fa4\u5357\u5317\u5411\u7f51\u7edc\u8bbf\u95ee\u7684\u6d4b\u8bd5\n</code></pre>"},{"location":"zh/usage/Aliyun/#_3","title":"\u4e1c\u897f\u5411\u7f51\u7edc\u8bbf\u95ee\u6d4b\u8bd5","text":"<p>\u6b64\u65f6\uff0c\u6211\u4eec\u4f7f\u7528 kubectl exec \u547d\u4ee4\u8fdb\u5165 nginx Pod \u8fdb\u884c\u6d4b\u8bd5\u3002</p> <pre><code>$ curl 172.17.81.29:8080\nRemote IP: 172.17.81.28:59022\n</code></pre> <p>\u6211\u4eec\u770b\u5230\u8fd4\u56de\u7ed3\u679c\u662f\u524d\u9762\u8bbe\u7f6e\u7684 IP <code>172.17.81.28</code>\uff0c\u5230\u8fd9\u91cc IP \u4f5c\u4e3a Egress \u7684\u5b9e\u9a8c\u5c31\u7ed3\u675f\u4e86\u3002</p>"},{"location":"zh/usage/Aliyun/#_4","title":"\u5357\u5317\u5411\u7f51\u7edc\u8bbf\u95ee\u6d4b\u8bd5","text":"<p>\u6d4b\u8bd5 Pod \u8bbf\u95ee\u5357\u5317\u5411\u7f51\u7edc\u7684\u670d\u52a1\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230 node1 \u7684 Pod \u4f7f\u7528 node2 \u7684\u8282\u70b9\u7ed1\u5b9a\u7684\u516c\u7f51 IP \u5b8c\u6210\u4e86\u4e92\u8054\u7f51\u8bbf\u95ee\u3002</p> <pre><code>$ curl ipinfo.io\n{\n\"ip\": \"8.217.200.161\",\n  \"city\": \"Hong Kong\",\n  \"region\": \"Hong Kong\",\n  \"country\": \"HK\",\n  \"loc\": \"22.2783,114.1747\",\n  \"org\": \"AS45102 Alibaba (US) Technology Co., Ltd.\",\n  \"timezone\": \"Asia/Hong_Kong\",\n  \"readme\": \"https://ipinfo.io/missingauth\"\n}\n</code></pre>"},{"location":"zh/usage/ClusterDefaultEgressGateway/","title":"\u96c6\u7fa4\u7ea7\u9ed8\u8ba4 EgressGateway","text":""},{"location":"zh/usage/ClusterDefaultEgressGateway/#_1","title":"\u4ecb\u7ecd","text":"<p>\u4e3a\u6574\u4e2a\u96c6\u7fa4\u8bbe\u7f6e\u9ed8\u8ba4 EgressGateway\uff0c\u53ef\u4ee5\u7b80\u5316\u5728\u79df\u6237\u4e0b\u4f7f\u7528 EgressPolicy \u6216\u5728\u96c6\u7fa4\u7ea7\u4f7f\u7528 EgressClusterPolicy \u65f6\uff0c\u6bcf\u6b21\u6307\u5b9a EgressGateway \u540d\u79f0\u7684\u6b65\u9aa4\u3002\u6ce8\u610f\u96c6\u7fa4\u9ed8\u8ba4 EgressGateway \u53ea\u80fd\u8bbe\u7f6e\u4e00\u4e2a\u3002</p>"},{"location":"zh/usage/ClusterDefaultEgressGateway/#_2","title":"\u5b9e\u65bd\u8981\u6c42","text":"<ul> <li>\u5df2\u5b89\u88c5 EgressGateway \u7ec4\u4ef6</li> </ul>"},{"location":"zh/usage/ClusterDefaultEgressGateway/#_3","title":"\u6b65\u9aa4","text":"<ol> <li> <p>\u521b\u5efa EgressGateway \u65f6\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e <code>spec.clusterDefault</code> \u4e3a <code>true</code>\uff0c\u5c06\u5176\u6307\u5b9a\u4e3a\u96c6\u7fa4\u7684\u9ed8\u8ba4 EgressGateway\uff0c\u5728 EgressClusterPolicy \u6ca1\u6709\u6307\u5b9a <code>spec.egressGatewayName</code> \u65f6\uff0c\u4ee5\u53ca EgressPolicy \u6ca1\u6709\u6307\u5b9a <code>spec.egressGatewayName</code> \u4e14\u79df\u6237\u6ca1\u6709\u914d\u7f6e\u9ed8\u8ba4 EgressGateway \u65f6\uff0c\u81ea\u52a8\u4f7f\u7528\u96c6\u7fa4\u9ed8\u8ba4\u7684 EgressGateway\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\nname: default\nspec:\nclusterDefault: true\nippools:\nipv4:\n- 10.6.1.55\n- 10.6.1.56\nipv4DefaultEIP: 10.6.1.55\nipv6:\n- fd00::55\n- fd00::56\nipv6DefaultEIP: fd00::56\nnodeSelector:\nselector:\nmatchLabels:\negress: \"true\"    </code></pre> </li> <li> <p>\u4f7f\u7528\u4ee5\u4e0b\u5b9a\u4e49\u521b\u5efa EgressPolicy\uff0c\u5ffd\u7565 <code>spec.egressGatewayName</code> \u5b57\u6bb5\u7684\u5b9a\u4e49\uff1a</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nname: mock-app\nspec:\nappliedTo:\npodSelector:\nmatchLabels:\napp: mock-app\ndestSubnet:\n- 10.6.1.92/32\n</code></pre> </li> <li> <p>\u518d\u6b21\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\uff0c\u786e\u8ba4 EgressPolicy \u5df2\u88ab\u8bbe\u7f6e\u4e3a\u9ed8\u8ba4\u7684 EgressGateway\uff1a</p> <pre><code>$ kubectl get egresspolicies mock-app -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\n  creationTimestamp: \"2023-08-09T11:54:34Z\"\ngeneration: 1\nname: mock-app\n  namespace: default\n  resourceVersion: \"6233341\"\nuid: 5692c5e6-a72b-41bd-a611-1106abd41bc2\nspec:\n  appliedTo:\n    podSelector:\n      matchLabels:\n        app: mock-app\n  destSubnet:\n  - 10.6.1.92/32\n  - fd00::92/128\n  - 172.30.40.0/21\n  egressGatewayName: default\n</code></pre> </li> </ol>"},{"location":"zh/usage/EgressGatewayFailover/#controller-failover","title":"Controller Failover","text":"<p>EgressGateway \u7684\u63a7\u5236\u9762\u6545\u969c\u8f6c\u79fb\uff0c\u53ef\u4ee5\u901a\u8fc7\u5728\u5b89\u88c5\u65f6\u6307\u5b9a <code>controller.replicas</code> \u53c2\u6570\u6765\u63a7\u5236 Controller \u7684\u526f\u672c\u6570\u91cf\u3002 \u5728\u591a\u4e2a Controller \u526f\u672c\u4e2d\u7684\u4e00\u4e2a\u53d1\u751f\u6545\u969c\u65f6\uff0c\u7cfb\u7edf\u4f1a\u81ea\u52a8\u9009\u62e9\u53e6\u4e00\u4e2a\u526f\u672c\u4f5c\u4e3a\u4e3b\u8981\u63a7\u5236\u5668\uff0c\u4ee5\u786e\u4fdd\u670d\u52a1\u7684\u6301\u7eed\u63d0\u4f9b\u3002</p>"},{"location":"zh/usage/EgressGatewayFailover/#datapath-failover","title":"Datapath Failover","text":"<p>\u5728\u5904\u7406\u6570\u636e\u9762\u6545\u969c\u8f6c\u79fb\u65f6\uff0c\u521b\u5efa EgressGateway \u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 <code>nodeSelector</code> \u6765\u9009\u62e9\u4e00\u7ec4\u8282\u70b9\u4f5c\u4e3a Egress Node\u3002Egress IP \u5c06\u4f1a\u7ed1\u5b9a\u5230\u5176\u4e2d\u7684\u4e00\u4e2a\u8282\u70b9\u4e0a\u3002\u5f53\u67d0\u4e2a\u8282\u70b9\u53d1\u751f\u6545\u969c\u6216\u8005\u8282\u70b9\u4e0a\u7684 Egress Agent \u6545\u969c\u65f6\uff0cEgress IP \u5c06\u4f1a\u81ea\u52a8\u8f6c\u79fb\u5230\u53e6\u4e00\u4e2a\u53ef\u7528\u8282\u70b9\u4e0a\uff0c\u4ece\u800c\u4fdd\u8bc1\u670d\u52a1\u7684\u8fde\u7eed\u6027\u548c\u53ef\u9760\u6027\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\nname: egw1\nspec:\nclusterDefault: true\nippools:\nipv4:\n- 10.6.1.55\n- 10.6.1.56\nipv4DefaultEIP: 10.6.1.56\nipv6:\n- fd00::55\n- fd00::56\nipv6DefaultEIP: fd00::55\nnodeSelector:\nselector:\nmatchLabels:\negress: \"true\"\nstatus:\nnodeList:\n- name: node1\nstatus: Ready\neips:\n- ipv4: 10.6.1.56\nipv6: fd00::55\npolicies:\n- name: policy1\nnamespace: default\n- name: node2\nstatus: Ready\n</code></pre> <p>\u5728\u4e0a\u8ff0 EgressGateway \u7684\u5b9a\u4e49\u4e2d\uff0c\u901a\u8fc7\u8bbe\u7f6e <code>egress: \"true\"</code>\uff0c\u5c06\u4e24\u4e2a\u8282\u70b9 node1 \u548c node2 \u4f5c\u4e3a Egress Node\u3002node1 \u4e3a\u88ab\u9009\u4e3a\u4e86\u751f\u6548\u7684\u8282\u70b9\uff0c\u5176\u6709\u6548 Egress IP \u53ef\u5728 status \u4e2d\u67e5\u770b\u3002\u5982\u679c node1 \u9047\u5230\u6545\u969c\uff0c\u90a3\u4e48 node2 \u5c06\u4f5c\u4e3a\u6545\u969c\u5207\u6362\u7684\u8282\u70b9\u3002</p> <p></p> <p>\u901a\u8fc7 Helm \u7684 values \u914d\u7f6e\uff0c\u53ef\u4ee5\u8c03\u6574\u72b6\u6001\u68c0\u6d4b\u548c Egress IP \u8f6c\u79fb\u7684\u65f6\u95f4\u3002</p> <ul> <li><code>feature.tunnelMonitorPeriod</code>\uff1aEgress Controller \u4ee5\u79d2\u4e3a\u5355\u4f4d\u8bbe\u7f6e\u7684\u95f4\u9694\u68c0\u67e5 EgressTunnel \u7684\u6700\u540e\u66f4\u65b0\u72b6\u6001\uff0c\u9ed8\u8ba4\u4e3a <code>5</code>\u3002</li> <li><code>feature.tunnelUpdatePeriod</code>\uff1aEgress Agent \u4ee5\u79d2\u4e3a\u5355\u4f4d\u8bbe\u7f6e\u7684\u95f4\u9694\u66f4\u65b0 EgressTunnel \u72b6\u6001\uff0c\u9ed8\u8ba4\u4e3a <code>5</code>\u3002</li> <li><code>feature.eipEvictionTimeout</code>\uff1a\u5982\u679c EgressTunnel \u7684\u6700\u540e\u66f4\u65b0\u65f6\u95f4\u8d85\u8fc7\u6b64\u65f6\u95f4\uff0c\u5219\u5c06\u8282\u70b9\u7684 Egress IP \u79fb\u52a8\u5230\u53e6\u4e00\u4e2a\u53ef\u7528\u8282\u70b9\uff0c\u5355\u4f4d\u4e3a\u79d2\uff0c\u9ed8\u8ba4\u4e3a <code>5</code>\u3002</li> </ul> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressTunnel\nmetadata:\nname: workstation1\nspec: {}\nstatus:\nlastHeartbeatTime: \"2023-11-27T12:04:56Z\"\nmark: \"0x26d9b723\"\nphase: Ready\n</code></pre> <p>EgressGateway Agent \u4f1a\u901a\u8fc7 <code>feature.tunnelUpdatePeriod</code> \u95f4\u9694\u5b9a\u65f6\u66f4\u65b0 <code>status.lastHeartbeatTime</code> \u5b57\u6bb5\uff0cEgressGateway Controller \u5219\u4f1a\u901a\u8fc7 <code>feature.tunnelMonitorPeriod</code> \u5b9a\u65f6\u5217\u51fa\u6240\u6709 EgressTunnel\uff0c\u5206\u522b\u68c0\u67e5 <code>status.lastHeartbeatTime</code> \u4e0e <code>feature.eipEvictionTimeout</code> \u7684\u548c\u662f\u5426\u8d85\u8fc7\u5f53\u524d\u65f6\u95f4\u3002 </p> <p></p> <p>Datapath Failover \u95ee\u9898\u6392\u67e5\u6b65\u9aa4\uff1a</p> <ol> <li>\u9996\u5148\uff0c\u67e5\u770b EgressGateway \u5e94\u7528\u7684\u5b89\u88c5\u914d\u7f6e\u6587\u4ef6 <code>values.yaml</code>\uff0c\u786e\u8ba4\u4e0e Datapath Failover \u76f8\u5173\u7684\u914d\u7f6e\u662f\u5426\u8bbe\u7f6e\u5408\u7406\uff0c\u7279\u522b\u662f\u786e\u4fdd <code>eipEvictionTimeout</code> \u7684\u503c\u5927\u4e8e <code>tunnelMonitorPeriod</code> \u52a0\u4e0a <code>tunnelUpdatePeriod</code> \u7684\u603b\u548c\uff1b</li> <li>\u6267\u884c <code>kubectl get egt -w</code> \u547d\u4ee4\uff0c\u68c0\u67e5 <code>EgressTunnel</code> \u7684\u72b6\u6001\u3002\u68c0\u67e5\u9009\u4e2d\u7684 Node \u662f\u5426\u5904\u4e8e <code>HeartbeatTimeout</code> \u72b6\u6001\uff0c\u5e76\u4e14\u662f\u5426\u5b58\u5728\u5176\u4ed6\u5904\u4e8e <code>Ready</code> \u72b6\u6001\u7684 <code>EgressTunnel</code>\uff1b     <pre><code>kubectl get egt -w\nNAME    TUNNELMAC           TUNNELIPV4        TUNNELIPV6   MARK         PHASE\nnode1   66:50:85:cb:b2:bf   192.200.229.11    fd01::c486   0x26d9b723   Ready\nnode2   66:d4:65:85:e2:c7   192.200.128.75    fd01::6676   0x26abf380   HeartbeatTimeout\nnode3   66:c4:da:a7:58:25   192.200.101.153   fd01::edb5   0x26c4ce84   Ready\n</code></pre></li> <li>\u5982\u679c\u60f3\u67e5\u8be2\u662f\u5426\u51fa\u73b0\u8fc7 HeartbeatTimeout \u5bfc\u81f4\u7684 IP \u5207\u6362\uff0c\u53ef\u4ee5\u5728 controller \u5bb9\u5668\u68c0\u7d22 <code>update tunnel status to HeartbeatTimeout</code> \u76f8\u5173\u7684\u65e5\u5fd7\u3002</li> </ol>"},{"location":"zh/usage/Install/","title":"\u81ea\u5efa\u96c6\u7fa4\u5b89\u88c5 EgressGateway","text":""},{"location":"zh/usage/Install/#_1","title":"\u4ecb\u7ecd","text":"<p>\u672c\u6587\u5c06\u6f14\u793a\u5728\u4e00\u4e2a\u81ea\u5efa\u96c6\u7fa4\u4e0a\u5feb\u901f\u5b89\u88c5 EgressGateway\u3002</p>"},{"location":"zh/usage/Install/#_2","title":"\u8981\u6c42","text":"<ol> <li> <p>\u5df2\u7ecf\u5177\u5907\u4e00\u4e2a\u81ea\u5efa\u597d\u7684 Kubernetes \u96c6\u7fa4\uff0c\u81f3\u5c11\u6709 2 \u4e2a\u8282\u70b9\u3002</p> </li> <li> <p>\u96c6\u7fa4\u51c6\u5907\u597d helm \u5de5\u5177\u3002</p> </li> <li> <p>\u76ee\u524d EgressGateway \u652f\u6301\u5982\u4e0b CNI\u3002</p> </li> </ol> CalicoFlannelWeaveSpiderpool <p>\u5982\u679c\u60a8\u7684\u96c6\u7fa4\u4f7f\u7528 Calico CNI\uff0c\u8bf7\u6267\u884c\u5982\u4e0b\u547d\u4ee4\uff0c\u8be5\u547d\u4ee4\u786e\u4fdd EgressGateway \u7684 iptables \u89c4\u5219\u4e0d\u4f1a\u88ab Calico \u89c4\u5219\u8986\u76d6\uff0c\u5426\u5219 EgressGateway \u5c06\u4e0d\u80fd\u5de5\u4f5c\u3002</p> <pre><code># set chainInsertMode\n$ kubectl patch felixconfigurations  default --type='merge' -p '{\"spec\":{\"chainInsertMode\":\"Append\"}}'\n# check status\n$ kubectl get FelixConfiguration default -o yaml\n  apiVersion: crd.projectcalico.org/v1\n    kind: FelixConfiguration\n    metadata:\n      generation: 2\nname: default\n      resourceVersion: \"873\"\nuid: 0548a2a5-f771-455b-86f7-27e07fb8223d\n      spec:\n      chainInsertMode: Append\n      ......\n</code></pre> <p><code>spec.chainInsertMode</code> \u7684\u610f\u4e49\u53ef\u53c2\u8003 Calico \u6587\u6863</p> <p>Flannel CNI \u4e0d\u9700\u8981\u4efb\u4f55\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u8df3\u8fc7\u6b64\u6b65\u9aa4\u3002</p> <p>Weave CNI \u4e0d\u9700\u8981\u4efb\u4f55\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u8df3\u8fc7\u6b64\u6b65\u9aa4\u3002</p> <p>\u5982\u679c\u60a8\u7684\u96c6\u7fa4\u4f7f\u7528 Spiderpool \u642d\u914d\u5176\u4ed6 CNI\uff0c\u9700\u8981\u8fdb\u884c\u5982\u4e0b\u64cd\u4f5c\u3002</p> <p>\u5c06\u96c6\u7fa4\u5916\u7684\u670d\u52a1\u5730\u5740\u6dfb\u52a0\u5230 spiderpool.spidercoordinators \u7684 'default' \u5bf9\u8c61\u7684 'hijackCIDR' \u4e2d\uff0c\u4f7f Pod \u8bbf\u95ee\u8fd9\u4e9b\u5916\u90e8\u670d\u52a1\u65f6\uff0c\u6d41\u91cf\u5148\u7ecf\u8fc7 Pod \u6240\u5728\u7684\u4e3b\u673a\uff0c\u4ece\u800c\u88ab EgressGateway \u89c4\u5219\u5339\u914d\u3002</p> <pre><code># \"1.1.1.1/32\", \"2.2.2.2/32\" \u4e3a\u5916\u90e8\u670d\u52a1\u5730\u5740\u3002\u5bf9\u4e8e\u5df2\u7ecf\u8fd0\u884c\u7684 Pod\uff0c\u9700\u8981\u91cd\u542f Pod\uff0c\u8fd9\u4e9b\u8def\u7531\u89c4\u5219\u624d\u4f1a\u5728 Pod \u4e2d\u751f\u6548\u3002\nkubectl patch spidercoordinators default  --type='merge' -p '{\"spec\": {\"hijackCIDR\": [\"1.1.1.1/32\", \"2.2.2.2/32\"]}}'\n</code></pre>"},{"location":"zh/usage/Install/#egressgateway_1","title":"\u5b89\u88c5 EgressGateway","text":""},{"location":"zh/usage/Install/#egressgateway_2","title":"\u6dfb\u52a0 EgressGateway \u4ed3\u5e93","text":"<pre><code>helm repo add egressgateway https://spidernet-io.github.io/egressgateway/\nhelm repo update\n</code></pre>"},{"location":"zh/usage/Install/#egressgateway_3","title":"\u5b89\u88c5 EgressGateway","text":"<ol> <li> <p>\u53ef\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u5feb\u901f\u5b89\u88c5 EgressGateway</p> <pre><code>helm install egressgateway egressgateway/egressgateway \\\n-n kube-system \\\n--set feature.tunnelIpv4Subnet=\"192.200.0.1/16\" \\\n--wait --debug\n</code></pre> <p>\u5728\u5b89\u88c5\u547d\u4ee4\u4e2d\uff0c\u6709\u5982\u4e0b\u6ce8\u610f\u70b9\uff1a</p> <ul> <li>\u5b89\u88c5\u547d\u4ee4\u4e2d\uff0c\u9700\u8981\u63d0\u4f9b\u7528\u4e8e EgressGateway \u96a7\u9053\u8282\u70b9\u7684 IPv4 \u548c IPv6 \u7f51\u6bb5\uff0c\u8981\u6c42\u8be5\u7f51\u6bb5\u548c\u96c6\u7fa4\u5185\u7684\u5176\u4ed6\u5730\u5740\u4e0d\u51b2\u7a81\u3002</li> <li>\u53ef\u4f7f\u7528\u9009\u9879 <code>--set feature.tunnelDetectMethod=\"interface=eth0\"</code> \u6765\u5b9a\u5236 EgressGateway \u96a7\u9053\u7684\u627f\u8f7d\u7f51\u5361\uff0c\u5426\u5219\uff0c\u9ed8\u8ba4\u4f7f\u7528\u9ed8\u8ba4\u8def\u7531\u7684\u7f51\u5361\u3002</li> <li>\u5982\u679c\u5e0c\u671b\u4f7f\u7528 IPv6 \uff0c\u53ef\u4f7f\u7528\u9009\u9879 <code>--set feature.enableIPv6=true</code> \u5f00\u542f\uff0c\u5e76\u8bbe\u7f6e <code>feature.tunnelIpv6Subnet</code>\u3002</li> <li>EgressGateway Controller \u652f\u6301\u9ad8\u53ef\u7528\uff0c\u53ef\u901a\u8fc7 <code>--set controller.replicas=2</code> \u8bbe\u7f6e\u3002</li> <li>\u5f00\u542f\u7f51\u5173\u8282\u70b9\u4e0a\u7684\u8fd4\u56de\u8def\u7531\u89c4\u5219\uff0c\u53ef\u901a\u8fc7\u8bbe\u7f6e <code>--set feature.enableGatewayReplyRoute=true</code> \u5f00\u542f\uff0c\u5982\u679c\u8981\u642d\u914d Spiderpool \u652f\u6301 underlay CNI\uff0c\u5219\u5fc5\u987b\u5f00\u542f\u8be5\u9009\u9879\u3002</li> </ul> </li> <li> <p>\u786e\u8ba4\u6240\u6709\u7684 EgressGateway Pod \u8fd0\u884c\u6b63\u5e38\u3002</p> <pre><code>$ kubectl get pod -n kube-system | grep egressgateway\negressgateway-agent-29lt5                  1/1     Running   0          9h\negressgateway-agent-94n8k                  1/1     Running   0          9h\negressgateway-agent-klkhf                  1/1     Running   0          9h\negressgateway-controller-5754f6658-7pn4z   1/1     Running   0          9h\n</code></pre> </li> <li> <p>\u4efb\u4f55\u529f\u80fd\u914d\u7f6e\uff0c\u53ef\u901a\u8fc7\u8c03\u6574 EgressGateway \u5e94\u7528\u7684 Helm Values \u6765\u5b9e\u73b0\u3002</p> </li> </ol>"},{"location":"zh/usage/Install/#egressgateway_4","title":"\u521b\u5efa EgressGateway \u5b9e\u4f8b","text":"<ol> <li> <p>EgressGateway \u5b9a\u4e49\u4e86\u4e00\u7ec4\u8282\u70b9\u4f5c\u4e3a\u96c6\u7fa4\u7684\u51fa\u53e3\u7f51\u5173\uff0c\u96c6\u7fa4\u5185\u7684 egress \u6d41\u91cf\u5c06\u4f1a\u901a\u8fc7\u8fd9\u7ec4\u8282\u70b9\u8f6c\u53d1\u800c\u51fa\u96c6\u7fa4\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u9884\u5148\u5b9a\u4e49\u4e00\u7ec4 EgressGateway\uff0c\u4f8b\u5b50\u5982\u4e0b\uff1a</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\n  name: default\nspec:\n  ippools:\n    ipv4:\n    - \"172.22.0.100-172.22.0.110\"\n  nodeSelector:\n    selector:\n      matchLabels:\n        egressgateway: \"true\"\nEOF\n</code></pre> <p>\u521b\u5efa\u547d\u4ee4\u4e2d\uff1a</p> <ul> <li>\u5982\u4e0a YAML \u4f8b\u5b50\u4e2d\uff0c<code>spec.ippools.ipv4</code> \u5b9a\u4e49\u4e86\u4e00\u7ec4 egress \u7684 \u51fa\u53e3 IP \u5730\u5740\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u73af\u5883\u7684\u5b9e\u9645\u60c5\u51b5\u8c03\u6574\u3002</li> <li>\u5176\u4e2d\uff0c<code>spec.ippools.ipv4</code> \u7684 CIDR \u5e94\u8be5\u662f\u4e0e\u7f51\u5173\u8282\u70b9\u4e0a\u7684\u51fa\u53e3\u7f51\u5361\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\u662f\u9ed8\u8ba4\u8def\u7531\u7684\u7f51\u5361\uff09\u7684\u5b50\u7f51\u76f8\u540c\uff0c\u5426\u5219\uff0c\u6781\u6709\u53ef\u80fd\u5bfc\u81f4 egress \u8bbf\u95ee\u4e0d\u901a\u3002</li> <li>\u901a\u8fc7 EgressGateway \u7684 <code>spec.nodeSelector</code> \u6765 select \u4e00\u7ec4\u8282\u70b9\u4f5c\u4e3a\u51fa\u53e3\u7f51\u5173\uff0c\u5b83\u652f\u6301 select \u591a\u4e2a\u8282\u70b9\u6765\u5b9e\u73b0\u9ad8\u53ef\u7528\u3002</li> </ul> </li> <li> <p>\u7ed9\u51fa\u53e3\u7f51\u5173\u8282\u70b9\u6253\u4e0a label\uff0c\u53ef\u4ee5\u7ed9\u591a\u4e2a node \u6253\u4e0a label\uff0c\u4f5c\u4e3a\u751f\u4ea7\u73af\u5883\uff0c\u5efa\u8bae 2 \u4e2a\u8282\u70b9\uff0c\u4f5c\u4e3a POC \u73af\u5883\uff0c \u5efa\u8bae 1 \u4e2a\u8282\u70b9\u5373\u53ef</p> <pre><code>kubectl get node\nkubectl label node $NodeName egressgateway=\"true\"\n</code></pre> </li> <li> <p>\u67e5\u770b\u72b6\u6001\u5982\u4e0b</p> <pre><code>$ kubectl get EgressGateway default -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\n  name: default\n  uid: 7ce835e2-2075-4d26-ba63-eacd841aadfe\nspec:\n  ippools:\n    ipv4:\n    - 172.22.0.100-172.22.0.110\n    ipv4DefaultEIP: 172.22.0.110\n  nodeSelector:\n    selector:\n      matchLabels:\n        egressgateway: \"true\"\nstatus:\n  nodeList:\n  - name: egressgateway-worker1\n    status: Ready\n  - name: egressgateway-worker2\n    status: Ready\n</code></pre> <p>\u5728\u5982\u4e0a\u8f93\u51fa\u4e2d\uff1a</p> <ul> <li><code>status.nodeList</code> \u5b57\u6bb5\u5df2\u7ecf\u8bc6\u522b\u5230\u4e86\u7b26\u5408 <code>spec.nodeSelector</code> \u7684\u8282\u70b9\u53ca\u8be5\u8282\u70b9\u5bf9\u5e94\u7684 EgressTunnel \u5bf9\u8c61\u7684\u72b6\u6001</li> <li><code>spec.ippools.ipv4DefaultEIP</code> \u5b57\u6bb5\u4f1a\u4ece <code>spec.ippools.ipv4</code> \u4e2d\u968f\u673a\u9009\u62e9\u4e00\u4e2a IP \u5730\u5740\u4f5c\u4e3a\u8be5\u7ec4 EgressGateway \u7684\u9ed8\u8ba4 VIP\uff0c\u5b83\u7684\u4f5c\u7528\u662f\uff1a\u5f53\u4e3a\u5e94\u7528\u521b\u5efa EgressPolicy \u5bf9\u8c61\u65f6\uff0c\u5982\u679c\u672a\u6307\u5b9a VIP \u5730\u5740\uff0c\u5219\u9ed8\u8ba4\u5206\u914d\u4f7f\u7528\u8be5\u9ed8\u8ba4 VIP</li> </ul> </li> </ol>"},{"location":"zh/usage/Install/#_3","title":"\u521b\u5efa\u5e94\u7528\u548c\u51fa\u53e3\u7b56\u7565","text":"<ol> <li> <p>\u521b\u5efa\u4e00\u4e2a\u5e94\u7528\uff0c\u5b83\u5c06\u7528\u4e8e\u6d4b\u8bd5 Pod \u8bbf\u95ee\u96c6\u7fa4\u5916\u90e8\u7528\u9014\uff0c\u5e76\u7ed9\u5b83\u6253\u4e0a label\u3002</p> <pre><code>kubectl create deployment visitor --image nginx\n</code></pre> </li> <li> <p>\u4e3a\u5e94\u7528\u521b\u5efa EgressPolicy CR \u5bf9\u8c61\u3002</p> <p>EgressPolicy \u5b9e\u4f8b\u7528\u4e8e\u5b9a\u4e49\u54ea\u4e9b Pod \u7684\u51fa\u53e3\u6d41\u91cf\u8981\u7ecf\u8fc7 EgressGateway \u8282\u70b9\u8f6c\u53d1\uff0c\u4ee5\u53ca\u5176\u5b83\u7684\u914d\u7f6e\u7ec6\u8282\u3002 \u53ef\u521b\u5efa\u5982\u4e0b\u4f8b\u5b50\uff0c\u5f53\u5339\u914d\u7684 Pod \u8bbf\u95ee\u4efb\u610f\u96c6\u7fa4\u5916\u90e8\u7684\u5730\u5740\uff08\u4efb\u610f\u4e0d\u662f Node IP\u3001CNI Pod CIDR\u3001ClusterIP \u7684\u5730\u5740\uff09\u65f6\uff0c\u90fd\u4f1a\u88ab EgressGateway Node \u8f6c\u53d1\u3002\u6ce8\u610f\u7684\u662f\uff0c EgressPolicy \u5bf9\u8c61\u662f\u79df\u6237\u7ea7\u522b\u7684\uff0c\u56e0\u6b64\uff0c\u5b83\u52a1\u5fc5\u521b\u5efa\u5728 selected \u5e94\u7528\u7684\u79df\u6237\u4e0b</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\n name: test\n namespace: default\nspec:\n egressGatewayName: default\n appliedTo:\n  podSelector:\n   matchLabels:\n    app: \"visitor\"\nEOF\n</code></pre> <p>\u5982\u4e0a\u521b\u5efa\u547d\u4ee4\u4e2d\uff1a</p> <ul> <li><code>spec.egressGatewayName</code> \u6307\u5b9a\u4e86\u4f7f\u7528\u54ea\u4e00\u7ec4 EgressGateway \u7684\u540d\u5b57\u3002</li> <li><code>spec.appliedTo.podSelector</code> \u6307\u5b9a\u4e86\u672c\u7b56\u7565\u751f\u6548\u5728\u96c6\u7fa4\u5185\u7684\u54ea\u4e9b Pod\u3002</li> <li>\u96c6\u7fa4\u7684 egress \u6d41\u91cf\u7684\u6e90 IP \u5730\u5740\u6709\u4e24\u79cd\u9009\u62e9\uff1a<ul> <li>\u53ef\u4f7f\u7528\u7f51\u5173\u8282\u70b9\u7684 IP\u3002\u5b83\u53ef\u9002\u7528\u4e8e\u516c\u6709\u4e91\u548c\u4f20\u7edf\u7f51\u7edc\u7b49\u73af\u5883\uff0c\u7f3a\u70b9\u662f\uff0c\u968f\u7740\u7f51\u5173\u8282\u70b9\u7684\u6545\u969c\uff0c\u51fa\u53e3\u6e90 IP \u53ef\u80fd\u4f1a\u53d1\u751f\u53d8\u5316\u3002\u53ef\u8bbe\u7f6e <code>spec.egressIP.useNodeIP=true</code> \u6765\u751f\u6548\u3002</li> <li>\u53ef\u4f7f\u7528\u72ec\u7acb\u7684 VIP\uff0c\u56e0\u4e3a EgressGateway \u662f\u57fa\u4e8e ARP \u539f\u7406\u751f\u6548 VIP\uff0c\u6240\u4ee5\u5b83\u9002\u7528\u4e8e\u4f20\u7edf\u7f51\u7edc\uff0c\u800c\u4e0d\u9002\u7528\u4e8e\u516c\u6709\u4e91\u7b49\u73af\u5883\uff0c\u5b83\u7684\u4f18\u70b9\u662f\uff0c\u51fa\u53e3\u6e90 IP \u6c38\u4e45\u662f\u56fa\u5b9a\u7684\u3002\u5728 EgressPolicy \u4e2d\u4e0d\u505a\u4efb\u4f55\u8bbe\u7f6e\uff0c\u5219\u9ed8\u8ba4\u4f7f\u7528 egressGatewayName \u7684\u7f3a\u7701 VIP\uff0c\u6216\u8005\u53ef\u5355\u72ec\u624b\u52a8\u6307\u5b9a <code>spec.egressIP.ipv4</code> \uff0c\u5176 IP \u503c\u52a1\u5fc5\u662f\u7b26\u5408 EgressGateway \u4e2d\u7684 IP \u6c60\u3002</li> </ul> </li> </ul> </li> <li> <p>\u67e5\u770b EgressPolicy \u7684\u72b6\u6001</p> <pre><code>$ kubectl get EgressPolicy -A\nNAMESPACE   NAME   GATEWAY   IPV4           IPV6   EGRESSTUNNEL\ndefault     test   default   172.22.0.110          egressgateway-worker2\n\n$ kubectl get EgressPolicy test -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\n  name: test\nnamespace: default\nspec:\n  appliedTo:\n    podSelector:\n      matchLabels:\n        app: visitor\n  egressIP:\n    allocatorPolicy: default\n    useNodeIP: false\nstatus:\n  eip:\n    ipv4: 172.22.0.110\n  node: egressgateway-worker2\n</code></pre> <p>\u5982\u4e0a\u8f93\u51fa\u4e2d\uff1a</p> <ul> <li><code>status.eip</code> \u5c55\u793a\u4e86\u8be5\u7ec4\u5e94\u7528\u51fa\u96c6\u7fa4\u65f6\u4f7f\u7528\u7684\u51fa\u53e3 IP \u5730\u5740\u3002</li> <li><code>status.node</code> \u5c55\u793a\u4e86\u54ea\u4e00\u4e2a EgressGateway \u7684\u8282\u70b9\u5728\u5b9e\u65f6\u7684\u8d1f\u8d23\u51fa\u53e3\u6d41\u91cf\u7684\u8f6c\u53d1\u3002\u6ce8\uff1aEgressGateway \u8282\u70b9\u652f\u6301\u9ad8\u53ef\u7528\uff0c\u5f53\u5b58\u5728\u591a\u4e2a EgressGateway \u8282\u70b9\u65f6\uff0c\u6240\u6709\u7684 EgressPolicy \u4f1a\u5747\u644a\u5230\u4e0d\u540c\u7684 EgressGateway \u8282\u70b9\u4e0a\u5b9e\u65bd\u3002</li> </ul> </li> <li> <p>\u67e5\u770b EgressEndpointSlices \u7684\u72b6\u6001</p> <p>\u6bcf\u4e2a EgressPolicy \u5bf9\u8c61\uff0c\u90fd\u6709\u4e00\u4e2a\u5bf9\u5e94\u7684 EgressEndpointSlices \u5bf9\u8c61\uff0c\u5176\u4e2d\u5b58\u50a8\u4e86 EgressPolicy select \u7684 Pod \u7684 IP \u5730\u5740\u96c6\u5408\u3002\u5f53\u5e94\u7528\u65e0\u6cd5\u51fa\u53e3\u8bbf\u95ee\u65f6\uff0c\u53ef\u6392\u67e5\u8be5\u5bf9\u8c61\u4e2d\u7684 IP \u5730\u5740\u662f\u5426\u6b63\u5e38\u3002</p> <pre><code>$ kubectl get egressendpointslices -A\nNAMESPACE   NAME         AGE\ndefault     test-kvlp6   18s\n\n$ kubectl get egressendpointslices test-kvlp6 -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nendpoints:\n- ipv4:\n  - 172.40.14.195\n  node: egressgateway-worker\n  ns: default\n  pod: visitor-6764bb48cc-29vq9\nkind: EgressEndpointSlice\nmetadata:\n  name: test-kvlp6\n  namespace: default\n</code></pre> </li> </ol>"},{"location":"zh/usage/Install/#_4","title":"\u6d4b\u8bd5\u6548\u679c","text":"<ol> <li> <p>\u53ef\u5728\u96c6\u7fa4\u5916\u90e8\u7f72\u5e94\u7528 nettools\uff0c\u7528\u4e8e\u6a21\u62df\u4e00\u4e2a\u96c6\u7fa4\u5916\u90e8\u7684\u670d\u52a1\uff0cnettools \u4f1a\u5728 http \u56de\u590d\u4e2d\u8fd4\u56de\u8bf7\u6c42\u8005\u7684\u6e90 IP \u5730\u5740\u3002</p> <pre><code>docker run -d --net=host ghcr.io/spidernet-io/egressgateway-nettools:latest /usr/bin/nettools-server -protocol web -webPort 8080\n</code></pre> </li> <li> <p>\u5728\u96c6\u7fa4\u5185\u90e8\u7684 visitor Pod \u4e2d\uff0c\u9a8c\u8bc1\u51fa\u53e3\u6d41\u91cf\u7684\u6548\u679c\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230 visitor \u8bbf\u95ee\u5916\u90e8\u670d\u52a1\uff0cnettools \u8fd4\u56de\u7684\u6e90 IP \u7b26\u5408\u4e86 EgressPolicy <code>.status.eip</code> \u7684\u6548\u679c\u3002     <pre><code>$ kubectl get pod\nNAME                       READY   STATUS    RESTARTS   AGE\nvisitor-6764bb48cc-29vq9   1/1     Running   0          15m\n\n$ kubectl exec -it visitor-6764bb48cc-29vq9 bash\n$ curl 10.6.1.92:8080\nRemote IP: 172.22.0.110\n</code></pre></p> </li> </ol>"},{"location":"zh/usage/MoveIP/","title":"\u51fa\u53e3\u7f51\u5173\u8282\u70b9\u95f4\u8fc1\u79fb Egress IP","text":""},{"location":"zh/usage/MoveIP/#_1","title":"\u4f7f\u7528\u573a\u666f","text":"<ul> <li>\u6211\u4eec\u901a\u8fc7 EgressGateway \u53ef\u4ee5\u9009\u62e9\u591a\u4e2a Node \u4f5c\u4e3a EgressNode\uff0c\u5f53 Node \u9700\u8981\u7ef4\u62a4\u65f6\uff0c \u53ef\u4ee5\u901a\u8fc7 cli \u547d\u4ee4\u624b\u52a8\u8fc1\u79fb\u8be5 Node \u7684 vip \u5230\u53e6\u5916\u4e00\u4e2a Node\u3002</li> <li>\u5176\u4ed6\u539f\u56e0\uff0c\u9700\u8981\u624b\u52a8\u5c06\u67d0\u4e2a Node \u7684 VIP \u5230\u53e6\u5916\u4e00\u4e2a Node \u65f6\u3002</li> </ul>"},{"location":"zh/usage/MoveIP/#_2","title":"\u4f7f\u7528\u6b65\u9aa4","text":"<p>\u6211\u4eec\u6267\u884c <code>kubectl get egw egressgateway -o yaml</code> \u67e5\u770b\u7684 EgressGateway \u5b9a\u4e49\u3002</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressGateway\nmetadata:\nfinalizers:\n- egressgateway.spidernet.io/egressgateway\nname: egressgateway\nspec:\nippools:\nipv4:\n- 10.6.91.1-10.6.93.125\nipv4DefaultEIP: 10.6.92.222\nnodeSelector:\nselector:\nmatchLabels:\negress: \"true\"\nstatus:\nipUsage:\nipv4Free: 37\nipv4Total: 637\nipv6Free: 0\nipv6Total: 0\nnodeList:\n- name: workstation2\nstatus: Ready\n- name: workstation3\nstatus: Ready\neips:\n- ipv4: 10.6.92.209\npolicies:\n- name: policy-1\nnamespace: default\n</code></pre> <p>\u5728\u8fc1\u79fb\u524d\uff0cEgress IP \u5728 workstation2 \u8282\u70b9\u3002</p> <pre><code>node@workstation:~$ kubecti get egp\nNAME       GATEWAY          IPW4          IPV6       EGRESSNODE\npolicy-1   egressgateway    10.6.92.209              workstation3\n</code></pre> <p>\u6211\u4eec\u901a\u8fc7\u6267\u884c\u4e0b\u9762\u547d\u4ee4\u5c06 <code>workstation3</code> \u7684 Egress IP \u8fc1\u79fb\u5230  <code>workstation2</code> Node\u3002</p> <pre><code>node@workstation:~$ kubectl exec -it egressgateway-controller-86c84f4858-b6dz4 bash\negctl vip move --egressGatewayName egressgateway --vip 10.6.92.209 --targetNode workstation2\nMoving VIP 10.6.92.209 to node workstation2...\nSuccessfully moved VIP 10.6.92.209 to node workstation2\n</code></pre> <p>\u8fc1\u79fb\u540e Egress IP \u8282\u70b9\u5df2\u7ecf\u8f6c\u79fb\u5230 workstation2 \u8282\u70b9\u3002</p> <pre><code>node@workstation:~$ kubecti get egp\nNAME       GATEWAY          IPW4          IPV6       EGRESSNODE\npolicy-1   egressgateway    10.6.92.209              workstation2\n</code></pre>"},{"location":"zh/usage/NamespaceDefaultEgressGateway/","title":"\u79df\u6237\u7ea7\u9ed8\u8ba4 EgressGateway","text":""},{"location":"zh/usage/NamespaceDefaultEgressGateway/#_1","title":"\u4ecb\u7ecd","text":"<p>\u4e3a\u79df\u6237\u8bbe\u7f6e\u9ed8\u8ba4 EgressGateway \u53ef\u4ee5\u7b80\u5316\u5728\u79df\u6237\u4e0b\u4f7f\u7528 EgressPolicy \u65f6\u6bcf\u6b21\u6307\u5b9a EgressGateway \u540d\u79f0\u7684\u6b65\u9aa4\u3002\u79df\u6237\u7ea7\u9ed8\u8ba4 EgressGateway \u7684\u4f18\u5148\u7ea7\u5927\u4e8e\u96c6\u7fa4\u9ed8\u8ba4 EgressGateway\uff0c\u6362\u53e5\u8bdd\u8bf4\uff0c\u5f53\u6307\u5b9a\u4e86\u79df\u6237\u7ea7\u7684\u9ed8\u8ba4\u7f51\u5173\uff0c\u4f1a\u4f18\u5148\u4f7f\u7528\u79df\u6237\u9ed8\u8ba4\u8bbe\u7f6e\uff0c\u5982\u679c\u79df\u6237\u6ca1\u6709\u8bbe\u7f6e\u9ed8\u8ba4\u7f51\u5173\uff0c\u5219\u4f1a\u4f7f\u7528\u96c6\u7fa4\u9ed8\u8ba4\u8bbe\u7f6e\u3002</p>"},{"location":"zh/usage/NamespaceDefaultEgressGateway/#_2","title":"\u5b9e\u65bd\u8981\u6c42","text":"<ul> <li>\u5df2\u5b89\u88c5 EgressGateway \u7ec4\u4ef6</li> <li>\u5df2\u521b\u5efa\u4e00\u4e2a EgressGateway CR</li> </ul>"},{"location":"zh/usage/NamespaceDefaultEgressGateway/#_3","title":"\u6b65\u9aa4","text":"<ol> <li> <p>\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u4e3a\u79df\u6237\u6307\u5b9a\u9ed8\u8ba4\u7684 EgressGateway \u540d\u79f0\uff1a</p> <pre><code>kubectl label ns default spidernet.io/egressgateway-default=egressgateway\n</code></pre> </li> <li> <p>\u4f7f\u7528\u4ee5\u4e0b\u5b9a\u4e49\u521b\u5efa EgressPolicy\uff0c\u5ffd\u7565 <code>spec.egressGatewayName</code> \u5b57\u6bb5\u7684\u5b9a\u4e49\uff1a</p> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nname: mock-app\nspec:\nappliedTo:\npodSelector:\nmatchLabels:\napp: mock-app\ndestSubnet:\n- 10.6.1.92/32\n</code></pre> </li> <li> <p>\u518d\u6b21\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\uff0c\u786e\u8ba4 EgressPolicy \u5df2\u88ab\u8bbe\u7f6e\u4e3a\u9ed8\u8ba4\u7684 EgressGateway\uff1a</p> <pre><code>$ kubectl get egresspolicies mock-app -o yaml\napiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\n  creationTimestamp: \"2023-08-09T10:54:34Z\"\ngeneration: 1\nname: mock-app\n  namespace: default\n  resourceVersion: \"6233341\"\nuid: 5692c5e6-a71b-41bd-a611-1106abd41ba3\nspec:\n  appliedTo:\n    podSelector:\n      matchLabels:\n        app: mock-app\n  destSubnet:\n  - 10.6.1.92/32\n  - fd00::92/128\n  - 172.30.40.0/21\n  egressGatewayName: egressgateway\n</code></pre> </li> </ol>"},{"location":"zh/usage/Uninstall/","title":"Uninstall","text":"<p>\u4e3a\u4e86\u786e\u4fdd\u5728\u5378\u8f7d EgressGateway \u4e4b\u524d\u4e0d\u5f71\u54cd\u6b63\u5728\u4f7f\u7528\u7684\u4e1a\u52a1\u5e94\u7528\uff0c\u5efa\u8bae\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ol> <li> <p>\u68c0\u67e5\u4e0e EgressGateway \u76f8\u5173\u7684\u8d44\u6e90\u6570\u91cf\u662f\u5426\u4e3a 0\u3002\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a</p> <pre><code>kubectl get egressclusterpolicies.egressgateway.spidernet.io -o name | wc -l\nkubectl get egresspolicies.egressgateway.spidernet.io -o name | wc -l\nkubectl get egressgateways.egressgateway.spidernet.io -o name | wc -l\n</code></pre> <p>\u8fd9\u4e9b\u547d\u4ee4\u5c06\u8f93\u51fa\u4e0e EgressGateway \u76f8\u5173\u7684 EgressClusterPolicy\u3001EgressPolicy \u548c EgressGateway \u8d44\u6e90\u7684\u6570\u91cf\u3002\u5982\u679c\u8f93\u51fa\u7ed3\u679c\u4e3a 0\uff0c\u5219\u8868\u793a\u6ca1\u6709\u4e0e EgressGateway \u76f8\u5173\u8054\u7684\u8d44\u6e90\u3002\u5982\u679c\u8f93\u51fa\u7ed3\u679c\u4e0d\u4e3a 0\uff0c\u5219\u9700\u8981\u8fdb\u4e00\u6b65\u5904\u7406\uff0c\u4ee5\u786e\u4fdd\u5378\u8f7d\u64cd\u4f5c\u4e0d\u4f1a\u5f71\u54cd\u6b63\u5728\u4f7f\u7528\u7684\u4e1a\u52a1\u5e94\u7528\u3002</p> <p>\u5982\u679c\u8f93\u51fa\u4e0d\u4e3a 0\uff0c\u4f60\u5e94\u8be5\u7ee7\u7eed\u4e0b\u9762\u547d\u4ee4\u68c0\u67e5\uff0c\u5426\u5219\u8df3\u8f6c\u5230\u5230\u6b65\u9aa4 2\u3002</p> <pre><code>kubectl get egressclusterpolicies.egressgateway.spidernet.io\nkubectl get egresspolicies.egressgateway.spidernet.io -o wide\nkubectl get egressgateways.egressgateway.spidernet.io\n</code></pre> <p>\u4f8b\u5982\u4f60\u53d1\u73b0 EgressPolicies \u8fd8\u6709\u672a\u5220\u9664\u8d44\u6e90\u65f6\uff0c\u5e94\u8be5\u67e5\u770b\u8d44\u6e90\u8be6\u60c5</p> <pre><code>kubectl get egresspolicies &lt;resource-name&gt; --namespace &lt;resource-namespace&gt; -o yaml\n</code></pre> <pre><code>apiVersion: egressgateway.spidernet.io/v1beta1\nkind: EgressPolicy\nmetadata:\nname: ns-policy\nnamespace: default\nspec:\nappliedTo:\npodSelector:\nmatchLabels:\napp: mock-app\negressGatewayName: egressgateway\nstatus:\neip:\nipv4: 10.6.1.55\nipv6: fd00::55\nnode: workstation2\n</code></pre> <p>\u901a\u8fc7\u68c0\u7d22 <code>appliedTo.podSelector</code> \u5339\u914d\u5230\u7684 Pod \u786e\u4fdd\u5220\u9664\u4e0d\u4f1a\u5f71\u54cd\u4e1a\u52a1\u5e94\u7528\u65f6\uff0c\u5728\u6267\u884c\u5982\u4e0b\u547d\u4ee4\u8fdb\u884c\u5220\u9664\u3002</p> <pre><code>kubectl delete egresspolicies &lt;resource-name&gt; --namespace &lt;resource-namespace&gt;\n</code></pre> </li> <li> <p>\u67e5\u8be2\u5f53\u524d\u96c6\u7fa4\u5b89\u88c5\u7684 EgressGateway\u3002\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a</p> <pre><code>helm ls -A | grep -i egress\n</code></pre> <p>\u8fd9\u5c06\u8f93\u51fa\u5f53\u524d\u96c6\u7fa4\u4e2d\u5b89\u88c5\u7684 EgressGateway \u7684\u540d\u79f0\u3001\u547d\u540d\u7a7a\u95f4\u3001\u7248\u672c\u7b49\u4fe1\u606f\u3002</p> </li> <li> <p>\u5378\u8f7d EgressGateway\u3002\u5982\u679c\u60a8\u786e\u5b9a\u8981\u5378\u8f7d EgressGateway\uff0c\u53ef\u4ee5\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a</p> <pre><code>helm uninstall &lt;egressgateway-name&gt; --namespace &lt;egressgateway-namespace&gt;\n</code></pre> <p>\u5c06 <code>&lt;egressgateway-name&gt;</code> \u66ff\u6362\u4e3a\u8981\u5378\u8f7d\u7684 EgressGateway \u7684\u540d\u79f0\uff0c\u5c06 <code>&lt;egressgateway-namespace&gt;</code> \u66ff\u6362\u4e3a EgressGateway \u6240\u5728\u7684\u547d\u540d\u7a7a\u95f4\u3002</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u5378\u8f7d EgressGateway \u4e4b\u524d\uff0c\u5efa\u8bae\u5148\u5907\u4efd\u76f8\u5173\u6570\u636e\uff0c\u5e76\u786e\u4fdd\u5378\u8f7d\u64cd\u4f5c\u4e0d\u4f1a\u5f71\u54cd\u6b63\u5728\u4f7f\u7528\u7684\u4e1a\u52a1\u5e94\u7528\u3002</p> </li> <li> <p>\u5728\u5378\u8f7d\u8fc7\u7a0b\u4e2d\uff0c\u6709\u65f6\u5019\u4f1a\u9047\u5230 EgressGateway \u7684 EgressTunnels CRD \u4e00\u76f4\u5904\u4e8e\u7b49\u5f85\u5220\u9664\u7684\u60c5\u51b5\u3002\u5982\u679c\u60a8\u9047\u5230\u4e86\u8fd9\u79cd\u60c5\u51b5\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528\u4e0b\u9762\u7684\u547d\u4ee4\u89e3\u51b3\u95ee\u9898\uff1a</p> <pre><code>kubectl patch crd egresstunnels.egressgateway.spidernet.io -p '{\"metadata\":{\"finalizers\": []}}' --type=merge\n</code></pre> <p>\u8fd9\u4e2a\u547d\u4ee4\u7684\u4f5c\u7528\u662f\u5220\u9664 EgressGateway CRD \u4e2d\u7684 finalizer\uff0c\u4ece\u800c\u5141\u8bb8 Kubernetes \u5220\u9664\u8fd9\u4e2a CRD\u3002\u6b64\u95ee\u9898\u662f\u7531 controller-manager \u5f15\u8d77\u7684\uff0c\u6211\u4eec\u6b63\u5728\u5173\u6ce8 Kubernetes \u56e2\u961f\u5bf9\u6b64\u95ee\u9898\u7684\u4fee\u590d\u60c5\u51b5\u3002</p> </li> </ol>"},{"location":"zh/usage/Upgrade/","title":"Upgrade","text":"<p>\u672c\u6587\u6863\u5c06\u6307\u5bfc\u4f60\u5982\u4f55\u4f7f\u7528 <code>helm upgrade</code> \u547d\u4ee4\u5b8c\u6210 EgressGateway \u7684\u5347\u7ea7\u3002</p>"},{"location":"zh/usage/Upgrade/#_1","title":"\u57fa\u672c\u547d\u4ee4\u683c\u5f0f","text":"<pre><code>helm upgrade [RELEASE] [CHART] [flags]\n</code></pre> <p>\u5176\u4e2d\uff0c<code>[RELEASE]</code> \u4ee3\u8868\u5b89\u88c5\u65f6\u8bbe\u7f6e\u7684\u5e94\u7528\u540d\u79f0\uff0c<code>[CHART]</code> \u6307\u7684\u662f\u56fe\u8868\uff0c\u800c <code>[flags]</code> \u53ef\u4ee5\u6307\u5b9a\u989d\u5916\u7684\u53c2\u6570\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\u6709\u5173 <code>helm upgrade</code> \u7684\u53c2\u6570\uff0c\u8bf7\u53c2\u9605 helm upgrade \u9875\u9762\u3002</p>"},{"location":"zh/usage/Upgrade/#_2","title":"\u7248\u672c\u5347\u7ea7","text":"<p>\u6309\u7167\u4ee5\u4e0b\u6b65\u9aa4\u6267\u884c\u7248\u672c\u5347\u7ea7\uff1a</p> <ol> <li> <p>\u5728\u5347\u7ea7\u4e4b\u524d\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u5c06\u672c\u5730 Chart \u5347\u7ea7\u81f3\u6700\u65b0\u7248\u672c\uff1a</p> <pre><code>helm repo update\n</code></pre> </li> <li> <p>\u67e5\u770b\u6700\u65b0\u7684\u7248\u672c\uff1a</p> <pre><code>helm search repo egressgateway\n</code></pre> </li> <li> <p>\u6267\u884c\u5347\u7ea7\u547d\u4ee4\uff1a</p> <pre><code>helm upgrade \\\negress \\\negressgateway/egressgateway \\\n--reuse-values \\\n--version [version]\n</code></pre> </li> </ol> <p>\u5c06 <code>[version]</code> \u66ff\u6362\u4e3a\u4f60\u5e0c\u671b\u66f4\u65b0\u7684\u7248\u672c\u3002</p>"},{"location":"zh/usage/Upgrade/#_3","title":"\u914d\u7f6e\u5347\u7ea7","text":"<p>\u6309\u7167\u4ee5\u4e0b\u6b65\u9aa4\u6267\u884c\u914d\u7f6e\u5347\u7ea7\uff1a</p> <ol> <li> <p>\u67e5\u770b\u53ef\u7528\u7684 values \u53c2\u6570\uff0c\u8bf7\u8bbf\u95ee values \u8bf4\u660e\u6587\u6863\u3002</p> </li> <li> <p>\u4f7f\u7528 <code>--set</code> flags \u66f4\u65b0\u914d\u7f6e\u3002\u4ee5\u4e0b\u793a\u4f8b\u5c55\u793a\u4e86\u5982\u4f55\u5c06 egress agent \u65e5\u5fd7\u7b49\u7ea7\u66f4\u6539\u4e3a debug \u7ea7\u522b\u3002\u901a\u8fc7 <code>--reuse-values</code> \u53c2\u6570\uff0c\u4f60\u53ef\u4ee5\u5728\u5347\u7ea7\u65f6\u91cd\u7528\u4e0a\u4e00\u4e2a release \u7684\u503c\u5e76\u5408\u5e76\u6765\u81ea\u547d\u4ee4\u884c\u7684\u4efb\u4f55\u8986\u76d6\u3002</p> <pre><code>helm upgrade \\\negress \\\negressgateway/egressgateway \\\n--set agent.debug.logLevel=debug \\\n--reuse-values\n</code></pre> </li> </ol>"}]}